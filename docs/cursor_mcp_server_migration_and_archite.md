# MCP server migration and architecture plan
_Exported on 12/28/2025 at 15:34:25 CST from Cursor (2.2.44)_

---

**User**

Since I am having issues with Podman containers being able to scan/see outside their local network - can you please create a plan for moving from using the MCP servers within Podman and how I can run the MCP servers from a terminal vs. the containers. Do not make any changes yet - I would just like to see a plan. Items to be reviewed:

1. How would the mcp server code need to be changed, if anything, to run locally in a terminal vs. via Podman containers - will there need to be significant changes to the code to run in a terminal.
2. Would there be any advantages/disadvantages to running in a terminal?
3. Is there a way that we would either combine all of the current tools into a single MCP server (call it the "coordination MCP server") - but not have each tool running all the time - for example, an MCP server called Pentest-mcp that would handle the calls to/from the AI Agent and then invoke the Python script for the specific tool - or, would all of the MCP servers need to be running all the time?
4. If we can create a single MCP server that will call the required tools, we would need the ability to have documentation and allow calls from the AI Agent to a specific tool if they are not running all the time. For example, if I wanted to run a Rustscan from my AI Agent, the overarching MCP server would need to have that tool (such as 'rustscan_scan' from the portscan-mcp-server) available through the coordination MCP server.

Again, please just plan this out and do not make any changes to the existing environment.

---

**Cursor**

Got it — I’ll inspect how these MCP servers are currently launched (Podman scripts + a couple `server.py` implementations) and then propose a migration plan with options: run locally via terminal (stdio), pros/cons, and a “coordination MCP server” design that can either proxy to always-on servers or spawn tools on-demand. I won’t make any changes.

Nice: your servers already use **FastMCP** and several support **stdio transport** (Cursor-friendly) in-process; that means “run locally from a terminal” is mostly about packaging + installing the underlying binaries (nmap/rustscan/etc.) rather than rewriting server logic. Next I’ll skim the portscan + shodan launch docs to tailor the migration plan and coordination-server options.

Aha: you already have **two deployment modes baked in**—`streamable-http` (used by `start-mcp.sh` for localhost ports) and `stdio` (Cursor “command” mode), with `pdtm-mcp-server` even defaulting to stdio when run as `python -m ...`. Next I’ll check the `pyproject.toml` entrypoints so the plan can give exact “run from terminal” commands per server, and then I’ll propose the coordination-server design options (always-on proxy vs spawn-on-demand).

---

**User**

Related to Question #2 about how the coordination MCP server would execute tools - what would you recommend as the most reliable and quicker method for executing the tools?

---

**Cursor**

For **reliability + speed**, I’d recommend a **hybrid “coordination MCP server”** that **spawns tool binaries on-demand** for most scanners, and only uses **always-on dependencies** when a tool truly needs them (e.g., an internal SearXNG service, MongoDB if you want centralized result storage).

Here’s why:

- **Spawn-on-demand (recommended default)**  
  - **Most reliable**: no cross-server HTTP hops, no port mapping, fewer moving pieces; one MCP server directly runs `rustscan`, `nmap`, `naabu`, etc. as subprocesses.  
  - **Fast enough**: for these CLIs, process start-up overhead is usually tiny compared to scan runtime.  
  - **Operationally simpler**: one process to run/debug/log; crashes are isolated per tool execution (a failed subprocess doesn’t have to kill the MCP server).

- **Proxy-to-other MCP servers (less ideal for your goal)**  
  - Adds **network coupling** (localhost ports, routing, timeouts) and requires **multiple servers to be up**.  
  - Useful only if you strongly need separate lifecycles/ownership per tool or want to keep existing servers unchanged and “compose” them.

- **Hybrid nuance (what makes it best in practice)**  
  - For **heavy/high-frequency tools**, you can add an optional **warm pool** (keep a small worker process alive, or cache tool availability checks) to reduce “first call” latency.  
  - For tools that require a **daemon/service** (SearXNG) or credentials flow (Shodan), you can still wrap them—but those dependencies may remain always-on (or use third-party APIs directly).

So: **one coordination MCP server, tool execution via subprocess spawn-on-demand** (with optional warm-workers), plus optional integrations for service-backed tools.

To lock the plan, which mode do you want?



---

**User**

When you work on this new method for the Coordination MCP Server and make changes to the Python scripts for each MCP tool - please use the MCP_Servers/Standalone_Build directory to copy/make change to the MCP Tools - do not make any changes to the existing MCP servers that are configured to run via Podman - I would like to keep those intact for a potential future revision. Please make sure you use the MCP_Servers/Standalone_Build directory - you can copy in any code from the other directories, that is fine, but do not move (and thus delete a file from the existing code) or make changes to the existing code for the Podman MCP servers.

---

**Cursor**

Makes sense — I’ll adjust the plan so the “standalone/local” work happens **only** under `MCP_Servers/Standalone_Build/`, with the existing Podman-backed servers treated as **read-only reference**. Next I’ll check whether `Standalone_Build/` already exists and then update the plan accordingly.

Good — `Standalone_Build/` already exists, so we can treat it as the dedicated “local/terminal” workspace. Next I’ll inspect what’s inside (if anything) and then update the plan so all changes happen under that directory while Podman servers remain untouched.

---

**User**

Implement the plan as specified, it is attached for your reference. Do NOT edit the plan file itself.

To-do's from the plan have already been created. Do not create them again. Mark them as in_progress as you work, starting with the first one. Don't stop until you have completed all the to-dos.

---

**Cursor**

Cool — I’ll implement this exactly under `MCP_Servers/Standalone_Build/` by **copying** the existing Podman servers, then making the standalone copies default to **Cursor stdio**, and finally adding the new **spawn-on-demand `pentest-mcp-server`** with stable tool names like `rustscan_scan`. First step is to mark the first todo in-progress and scaffold the standalone directory tree without touching the originals.

Nice — the standalone copies are now in place under `Standalone_Build/`, and the originals weren’t touched. Next I’ll standardize each standalone server’s startup so `MCP_TRANSPORT=stdio` (or a stdio default) works consistently, and I’ll normalize a couple container-only defaults (like `/data/output` paths) to be local-friendly via env.

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="portscan-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    *,
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    # Naabu does not use nmap coercion; keep field for compatibility but default empty.
    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    # Naabu does not use nmap coercion; keep field for compatibility but default empty.
    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    *,
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    *,
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    # RustScan may optionally invoke nmap, but this MCP server doesn't do nmap-arg coercion here.
    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    *,
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run naabu, rustscan, and nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4560")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m portscan_mcp_server.server` works in Cursor without extra env.
    #
    # The Podman-oriented version can still explicitly set MCP_TRANSPORT=streamable-http.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4560

    # FastMCP supports http-like transports which do accept host/port/path.
    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    # Fall back defensively to a known-good default.
    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()

```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .validation import validate_args, validate_url
from .wpscan_cli import WPScanNotInstalledError, run_wpscan


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="wpscan")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={"reason": "arbitrary args can enable aggressive checks / enumeration"},
        )
    return True, None


@mcp.tool()
@register_tool
def wpscan_version() -> dict[str, Any]:
    """Return WPScan version."""
    try:
        rr = run_wpscan(args=["--version"], timeout_seconds=60)
        return _tool_ok({"stdout": rr.stdout.strip(), "stderr": rr.stderr.strip(), "returncode": rr.returncode})
    except WPScanNotInstalledError as e:
        security_event(logger, "wpscan_not_installed", error=str(e))
        return _tool_error(str(e))


@mcp.tool()
@register_tool
def wpscan_debug_binary() -> dict[str, Any]:
    """Debug helper: return version output and exact command used."""
    try:
        rr = run_wpscan(args=["--version"], timeout_seconds=60)
        return _tool_ok(
            {"version_stdout": rr.stdout.strip(), "version_stderr": rr.stderr.strip()},
            meta={"command": rr.command, "returncode": rr.returncode},
        )
    except WPScanNotInstalledError as e:
        return _tool_error(str(e))


@mcp.tool()
@register_tool
def wpscan_scan(
    url: str,
    *,
    enumerate: str | None = None,
    stealthy: bool = False,
    plugins_detection: str | None = None,
    api_token: str | None = None,
    proxy: str | None = None,
    user_agent: str | None = None,
    max_threads: int | None = None,
    headers: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 1800,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run WPScan against a target URL.

    Upstream docs: https://github.com/wpscanteam/wpscan/wiki/WPScan-User-Documentation

    Notes:
    - API token can be provided via env `WPSCAN_API_TOKEN` or via `api_token`.
    """

    res_url = validate_url(url)
    if not res_url.ok:
        security_event(logger, "invalid_url", url=url)
        return _tool_error(res_url.message or "invalid url")

    args: list[str] = ["--url", url]

    if stealthy:
        args.append("--stealthy")

    if enumerate:
        # wpscan expects formats like: u, u1-100, vp, vt, ap, at
        args.extend(["--enumerate", enumerate])

    if plugins_detection:
        pd = plugins_detection.strip().lower()
        if pd not in {"passive", "mixed", "aggressive"}:
            return _tool_error("plugins_detection must be one of: passive, mixed, aggressive")
        args.extend(["--plugins-detection", pd])

    # API token precedence: explicit param overrides env var.
    token = api_token if api_token is not None else os.getenv("WPSCAN_API_TOKEN")
    if token:
        args.extend(["--api-token", token])

    if proxy:
        args.extend(["--proxy", proxy])

    if user_agent:
        args.extend(["--user-agent", user_agent])

    if max_threads is not None:
        if max_threads < 1 or max_threads > 200:
            return _tool_error("max_threads must be between 1 and 200")
        args.extend(["--max-threads", str(max_threads)])

    if headers:
        # WPScan supports --headers "Header: v; Header2: v"; accept list and join with '; '
        joined = "; ".join([h.strip() for h in headers if (h or "").strip()])
        if joined:
            args.extend(["--headers", joined])

    if extra_args:
        res_args = validate_args(extra_args)
        if not res_args.ok:
            security_event(logger, "invalid_args", error=res_args.message)
            return _tool_error(res_args.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_wpscan(args=args, timeout_seconds=timeout_seconds)
    except WPScanNotInstalledError as e:
        security_event(logger, "wpscan_not_installed", error=str(e))
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(tool_name="wpscan", tool_commandline=rr.command, scan_target=url, data={"stdout": rr.stdout, "stderr": rr.stderr})
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def wpscan_scan_raw(
    *,
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 1800,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run WPScan with arbitrary CLI args (no shell)."""

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    res_args = validate_args(args)
    if not res_args.ok:
        return _tool_error(res_args.message or "invalid args")

    try:
        rr = run_wpscan(args=args, timeout_seconds=timeout_seconds)
    except WPScanNotInstalledError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            # Raw mode has no structured target; store the arg vector as target for traceability.
            saved = save_to_mongo_result(tool_name="wpscan", tool_commandline=rr.command, scan_target=" ".join(args), data={"stdout": rr.stdout, "stderr": rr.stderr})
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4561")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m wpscan_mcp_server.server` works in Cursor without extra env.
    #
    # The Podman-oriented version can still explicitly set MCP_TRANSPORT=streamable-http.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4561

    # FastMCP supports http-like transports which do accept host/port/path.
    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    # Fall back defensively to a known-good default.
    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()

```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .harvester_cli import HarvesterNotInstalledError, ensure_api_keys_symlinks, run_theharvester
from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .validation import clamp_int, validate_args, validate_domain, validate_sources


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="theharvester")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


@mcp.tool()
@register_tool
def theharvester_version() -> dict[str, Any]:
    """Return theHarvester version (best-effort via `theHarvester -h`/`--version` style output)."""
    try:
        rr = run_theharvester(domain="example.com", sources="all", limit=1, start=0, extra_args=["-h"], timeout_seconds=30)
        return _tool_ok(
            {"stdout": rr.stdout, "stderr": rr.stderr, "returncode": rr.returncode},
            meta={"command": rr.command},
        )
    except HarvesterNotInstalledError as e:
        security_event(logger, "theharvester_not_installed", error=str(e))
        return _tool_error(str(e))
    except Exception as e:
        return _tool_error("failed to run theHarvester", details={"error": str(e)})


@mcp.tool()
@register_tool
def theharvester_sync_keys() -> dict[str, Any]:
    """
    Ensure mounted api keys are linked into theHarvester's expected locations.
    See upstream: https://github.com/laramies/theHarvester/wiki/Installation
    """
    try:
        res = ensure_api_keys_symlinks()
        return _tool_ok(res)
    except Exception as e:
        return _tool_error("failed to sync api keys", details={"error": str(e)})


@mcp.tool()
@register_tool
def theharvester_run(
    *,
    domain: str,
    sources: str = "all",
    limit: int = 100,
    start: int = 0,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 1800,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run theHarvester and:
    - save output files into the mounted host dir's `output/` folder (HARVESTER_OUTPUT_DIR, default /data/output)
    - return parsed JSON (if theHarvester produced JSON/JSONL/CSV) plus stdout/stderr

    API key file: mount `/data/keys/api-keys.yaml` as described in upstream wiki:
    https://github.com/laramies/theHarvester/wiki/Installation
    """
    d_res = validate_domain(domain)
    if not d_res.ok:
        security_event(logger, "invalid_domain", domain=domain, error=d_res.message)
        return _tool_error(d_res.message or "invalid domain")

    s_res = validate_sources(sources)
    if not s_res.ok:
        security_event(logger, "invalid_sources", sources=sources, error=s_res.message)
        return _tool_error(s_res.message or "invalid sources")

    try:
        limit = clamp_int(limit, min_value=1, max_value=10_000, name="limit")
        start = clamp_int(start, min_value=0, max_value=10_000_000, name="start")
        if timeout_seconds is not None:
            timeout_seconds = clamp_int(timeout_seconds, min_value=30, max_value=7200, name="timeout_seconds")
    except ValueError as e:
        security_event(logger, "invalid_numeric_option", error=str(e))
        return _tool_error(str(e))

    if extra_args:
        a_res = validate_args(extra_args)
        if not a_res.ok:
            security_event(logger, "invalid_args", error=a_res.message)
            return _tool_error(a_res.message or "invalid extra_args")

    try:
        rr = run_theharvester(
            domain=domain,
            sources=sources,
            limit=limit,
            start=start,
            extra_args=extra_args,
            timeout_seconds=timeout_seconds,
        )
    except HarvesterNotInstalledError as e:
        security_event(logger, "theharvester_not_installed", error=str(e))
        return _tool_error(str(e))
    except Exception as e:
        security_event(logger, "theharvester_run_failed", error=str(e))
        return _tool_error("theHarvester failed", details={"error": str(e)})

    meta = {
        "returncode": rr.returncode,
        "command": rr.command,
        "output_dir": os.getenv("HARVESTER_OUTPUT_DIR", "/data/output"),
    }
    payload = {
        "parsed": rr.parsed,
        "stdout": rr.stdout,
        "stderr": rr.stderr,
        "output_files": rr.output_files,
    }
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="theharvester",
                tool_commandline=rr.command,
                scan_target=domain,
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4562")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m theharvester_mcp_server.server` works in Cursor without extra env.
    #
    # The Podman-oriented version can still explicitly set MCP_TRANSPORT=streamable-http.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4562

    # FastMCP supports http-like transports which do accept host/port/path.
    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    # Fall back defensively to a known-good default.
    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

import httpx
from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .policy import default_engines, requires_opt_in, split_requested_engines
from .validation import validate_engines, validate_query


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="searx")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _searx_url() -> str:
    # IMPORTANT: should remain internal-only (127.0.0.1) inside the container.
    return os.getenv("SEARXNG_URL", "http://127.0.0.1:8080").rstrip("/")

def _timeout_limit_seconds(default: float = 8.0) -> float:
    """
    Default SearXNG backend engine timeout limit (seconds).
    If engines are blocked/unreachable, this prevents long hangs.
    """
    raw = os.getenv("SEARX_TIMEOUT_LIMIT_SECONDS", "").strip()
    if not raw:
        return default
    try:
        v = float(raw)
    except ValueError:
        return default
    if v <= 0:
        return default
    return min(v, 60.0)

def _user_agent() -> str:
    # SearXNG botdetection may block non-browser user agents with 403.
    # Use a reasonable default but allow overrides.
    return os.getenv(
        "SEARX_MCP_USER_AGENT",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    )

def _accept_language(requested_language: str | None) -> str:
    # Keep it simple; SearXNG expects a normal Accept-Language header.
    lang = (requested_language or "").strip()
    if not lang:
        return "en-US,en;q=0.9"
    return f"{lang},en;q=0.8"

def _client_ip() -> str:
    # SearXNG botdetection expects a client IP header in some configurations.
    # Since MCP and SearXNG are co-located in the same container, default to loopback.
    return os.getenv("SEARX_MCP_CLIENT_IP", "127.0.0.1").strip() or "127.0.0.1"


@mcp.tool()
@register_tool
def searx_policy() -> dict[str, Any]:
    """Return the engine privacy policy enforced by this MCP server."""
    return _tool_ok(
        {
            "default_engines": default_engines(),
            "non_private_engines_require_opt_in": sorted(list({"google", "bing", "yahoo", "yandex", "baidu"})),
        }
    )


@mcp.tool()
@register_tool
async def searx_search(
    query: str,
    *,
    engines: list[str] | None = None,
    categories: str | None = None,
    language: str | None = None,
    time_range: str | None = None,
    safesearch: int | None = 1,
    page: int | None = 1,
    max_results: int | None = 25,
    allow_non_private_engines: bool = False,
    timeout_seconds: float | None = 20.0,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Query SearXNG via its internal HTTP API and return JSON.

    Privacy defaults:
    - Uses DuckDuckGo by default
    - Engines like Google/Bing are only allowed when explicitly requested via `engines`
      AND `allow_non_private_engines=true`.
    """

    qv = validate_query(query)
    if not qv.ok:
        security_event(logger, "invalid_query", error=qv.message)
        return _tool_error(qv.message or "invalid query")

    req_engines = split_requested_engines(engines)
    if not req_engines:
        req_engines = default_engines()

    ev = validate_engines(req_engines)
    if not ev.ok:
        security_event(logger, "invalid_engines", error=ev.message)
        return _tool_error(ev.message or "invalid engines")

    needs_opt_in = requires_opt_in(req_engines)
    if needs_opt_in and not allow_non_private_engines:
        security_event(logger, "blocked_non_private_engines", engines=needs_opt_in)
        return _tool_error(
            "non-private engines requested; explicit opt-in required",
            details={"blocked_engines": needs_opt_in, "hint": "set allow_non_private_engines=true"},
        )

    if max_results is not None and (max_results < 1 or max_results > 100):
        return _tool_error("max_results must be between 1 and 100")

    params: dict[str, Any] = {
        "q": query.strip(),
        "format": "json",
        "engines": ",".join(req_engines),
        "pageno": page or 1,
    }
    if categories:
        params["categories"] = categories
    if language:
        params["language"] = language
    if time_range:
        params["time_range"] = time_range
    if safesearch is not None:
        params["safesearch"] = safesearch

    # SearXNG supports limiting backend engine time via `timeout_limit` (seconds).
    # This helps prevent long hangs when engines are blocked/unreachable.
    params["timeout_limit"] = _timeout_limit_seconds()

    url = f"{_searx_url()}/search"

    try:
        async with httpx.AsyncClient(timeout=timeout_seconds) as client:
            headers = {
                "Accept": "application/json",
                "User-Agent": _user_agent(),
                "Accept-Language": _accept_language(language),
                "X-Forwarded-For": _client_ip(),
                "X-Real-IP": _client_ip(),
            }
            resp = await client.get(
                url,
                params=params,
                headers=headers,
            )
            # Some SearXNG instances are configured with `server.method: POST` and may forbid GET searches.
            if resp.status_code == 403:
                resp = await client.post(
                    url,
                    data=params,
                    headers=headers,
                )
    except httpx.TimeoutException as e:
        security_event(
            logger,
            "searx_request_timeout",
            error=str(e),
            internal_url=url,
            timeout_seconds=timeout_seconds,
        )
        return _tool_error(
            "searx request timed out",
            details={
                "internal_url": url,
                "timeout_seconds": timeout_seconds,
                "hint": "check that SearXNG is running and reachable at SEARXNG_URL inside the container (default http://127.0.0.1:8080)",
            },
        )
    except httpx.RequestError as e:
        # Covers DNS errors, connection refused, TLS errors, etc.
        security_event(
            logger,
            "searx_request_error",
            error=str(e),
            error_type=type(e).__name__,
            internal_url=url,
        )
        return _tool_error(
            "failed to reach searx",
            details={
                "internal_url": url,
                "error_type": type(e).__name__,
                "error": str(e),
                "hint": "SearXNG may not be running. Verify the container starts gunicorn successfully and SEARXNG_URL points at the internal bind address.",
            },
        )

    if resp.status_code != 200:
        security_event(logger, "searx_http_error", status=resp.status_code)
        return _tool_error("searx returned non-200", details={"status": resp.status_code, "body": resp.text[:1000]})

    try:
        data = resp.json()
    except Exception as e:
        security_event(
            logger,
            "searx_invalid_json",
            error=str(e),
            status=resp.status_code,
            content_type=resp.headers.get("content-type"),
        )
        return _tool_error(
            "searx returned invalid JSON",
            details={
                "status": resp.status_code,
                "content_type": resp.headers.get("content-type"),
                "body": resp.text[:1000],
            },
        )

    if isinstance(data, dict) and max_results is not None:
        results = data.get("results")
        if isinstance(results, list):
            data["results"] = results[:max_results]

    # Compute which upstream engine(s) actually produced the returned results.
    # SearXNG often annotates each result with `engine` and/or `engines`.
    result_engine_counts: dict[str, int] = {}
    engines_in_results: set[str] = set()
    if isinstance(data, dict):
        results = data.get("results")
        if isinstance(results, list):
            for r in results:
                if not isinstance(r, dict):
                    continue
                eng = r.get("engine")
                if isinstance(eng, str) and eng.strip():
                    k = eng.strip()
                    result_engine_counts[k] = result_engine_counts.get(k, 0) + 1
                    engines_in_results.add(k)
                engs = r.get("engines")
                if isinstance(engs, list):
                    for e in engs:
                        if isinstance(e, str) and e.strip():
                            engines_in_results.add(e.strip())

    meta = {
            # Engines requested/allowed by this MCP server (what we asked SearXNG to use).
            "engines_used": req_engines,
            # Engines that actually show up in the returned result set (derived from SearXNG response).
            "result_engines": sorted(engines_in_results),
            "result_engine_counts": dict(sorted(result_engine_counts.items(), key=lambda kv: (-kv[1], kv[0]))),
            "internal_url": url,
            "timeout_limit_seconds": params.get("timeout_limit"),
            "note": "SearXNG is bound to 127.0.0.1 inside the container and is not exposed externally.",
    }

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="searx",
                tool_commandline={"q": params.get("q"), "engines": params.get("engines"), "pageno": params.get("pageno")},
                scan_target=str(params.get("q") or ""),
                data={"result": data, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(data, meta=meta)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4563")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m searx_mcp_server.server` works in Cursor without extra env.
    #
    # The Podman-oriented version can still explicitly set MCP_TRANSPORT=streamable-http.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4563

    # FastMCP supports http-like transports which do accept host/port/path.
    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    # Fall back defensively to a known-good default.
    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

Good news: the standalone copies now default cleanly to **stdio** (Cursor command-mode) for the main “scanner” servers, while still allowing `streamable-http` if you explicitly set it. Next I’ll finish this standardization for the remaining standalone servers (notably Shodan) and then move on to building the new `pentest-mcp-server` coordinator.

---

**User**

Please finish the standardization for the remaining standalone servers such as Shodan and then build the new pentest-mcp-server coordinator. Please ensure that pentest-mcp-server coordinator is firstmost standalone such as the others.

---

**Cursor**

Got it. Next I’ll (1) finish the **stdio-default** standardization in the remaining standalone servers (Shodan + Searchsploit, and confirm Mongo/PDTM are already good), then (2) create `Standalone_Build/pentest-mcp-server/` as a **first-class standalone** package that exposes the key tools (starting with port scanning) by **spawning the underlying binaries on-demand**.

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP
from shodan import Shodan
from shodan.exception import APIError

from .env_loader import load_dotenv_if_present
from .filters import describe_filter, list_known_filters
from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .validation import (
    ValidationResult,
    clamp_int,
    validate_filter_expression,
    validate_query,
)

load_dotenv_if_present()

configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="shodan")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _validate_list(items: list[str] | None, validator) -> tuple[list[str], list[tuple[str, str]]]:
    if not items:
        return [], []
    ok: list[str] = []
    bad: list[tuple[str, str]] = []
    for x in items:
        x2 = (x or "").strip()
        if not x2:
            continue
        res: ValidationResult = validator(x2)
        if res.ok:
            ok.append(x2)
        else:
            bad.append((x2, res.message or "invalid"))
    return ok, bad


def _env_api_key() -> tuple[str | None, dict[str, Any] | None]:
    """
    Returns (api_key, error_payload). Loads from environment (`SHODAN_API_KEY`).
    The `.env` file is loaded at import-time if present.
    """
    k = os.getenv("SHODAN_API_KEY", "").strip()
    if not k:
        security_event(logger, "missing_api_key_env")
        return None, _tool_error(
            "missing SHODAN_API_KEY",
            details={
                "hint": "Create shodan-mcp-server/.env with SHODAN_API_KEY=... and restart the container",
                "env_var": "SHODAN_API_KEY",
            },
        )
    # Avoid logging the key; only validate basic shape.
    if "\n" in k or "\r" in k or "\x00" in k or len(k) < 16:
        security_event(logger, "invalid_api_key_env_format")
        return None, _tool_error("SHODAN_API_KEY format looks invalid")
    return k, None


def _build_query(
    query: str,
    *,
    filters: list[str] | None,
    country: str | None,
    org: str | None,
    asn: str | None,
    net: str | None,
    port: int | None,
    product: str | None,
    hostname: str | None,
    city: str | None,
) -> tuple[str, list[tuple[str, str]]]:
    parts: list[str] = [query.strip()]
    bad: list[tuple[str, str]] = []

    def maybe_quote(v: str) -> str:
        """
        Preserve quotes if the user already provided them; otherwise wrap in double-quotes.
        Avoid nested f-strings/backslash escapes so this stays valid on Python 3.12+.
        """
        v2 = (v or "").strip()
        if v2.startswith(("\"", "'")):
            return v2
        return f"\"{v2}\""

    def add_expr(expr: str) -> None:
        res = validate_filter_expression(expr)
        if res.ok:
            parts.append(expr)
        else:
            bad.append((expr, res.message or "invalid"))

    if country:
        add_expr(f"country:{country.strip()}")
    if org:
        add_expr(f"org:{maybe_quote(org)}")
    if asn:
        add_expr(f"asn:{asn.strip()}")
    if net:
        add_expr(f"net:{net.strip()}")
    if port is not None:
        add_expr(f"port:{port}")
    if product:
        add_expr(f"product:{maybe_quote(product)}")
    if hostname:
        add_expr(f"hostname:{hostname.strip()}")
    if city:
        add_expr(f"city:{maybe_quote(city)}")

    ok_filters, bad_filters = _validate_list(filters, validate_filter_expression)
    bad.extend(bad_filters)
    parts.extend(ok_filters)

    return " ".join([p for p in parts if p]).strip(), bad


def _summarize_matches(matches: list[dict[str, Any]], *, max_results: int) -> list[dict[str, Any]]:
    out: list[dict[str, Any]] = []
    for m in matches[:max_results]:
        data = (m.get("data") or "").strip()
        if len(data) > 500:
            data = data[:500] + "…"
        loc = m.get("location") or {}
        out.append(
            {
                "ip_str": m.get("ip_str"),
                "port": m.get("port"),
                "transport": m.get("transport"),
                "org": m.get("org"),
                "isp": m.get("isp"),
                "asn": m.get("asn"),
                "hostnames": m.get("hostnames"),
                "domains": m.get("domains"),
                "product": m.get("product"),
                "version": m.get("version"),
                "timestamp": m.get("timestamp"),
                "location": {
                    "country_code": loc.get("country_code"),
                    "country_name": loc.get("country_name"),
                    "region_code": loc.get("region_code"),
                    "city": loc.get("city"),
                    "latitude": loc.get("latitude"),
                    "longitude": loc.get("longitude"),
                },
                "data_excerpt": data,
            }
        )
    return out


@mcp.tool()
@register_tool
def shodan_search(
    query: str,
    filters: list[str] | None = None,
    country: str | None = None,
    org: str | None = None,
    asn: str | None = None,
    net: str | None = None,
    port: int | None = None,
    product: str | None = None,
    hostname: str | None = None,
    city: str | None = None,
    page: int | None = 1,
    max_results: int | None = 25,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Search Shodan using a base `query` and optional filters.

    - If Shodan reports more than 25 results, only the first 25 are returned (configurable via `max_results`).
    - This server reads the Shodan API key from `SHODAN_API_KEY` (loaded from `.env` if present).

    Filters can be provided in two ways:
    - convenience params (country/org/asn/net/port/product/hostname/city)
    - raw filter expressions: `filters=["country:US", "port:443", ...]`
    """
    qv = validate_query(query)
    if not qv.ok:
        security_event(logger, "invalid_query", error=qv.message)
        return _tool_error(qv.message or "invalid query")

    try:
        page2 = clamp_int(int(page or 1), min_value=1, max_value=100, name="page")
    except ValueError as e:
        security_event(logger, "invalid_page", error=str(e))
        return _tool_error(str(e))

    try:
        mr = clamp_int(int(max_results or 25), min_value=1, max_value=25, name="max_results")
    except ValueError as e:
        security_event(logger, "invalid_max_results", error=str(e))
        return _tool_error(str(e))

    if port is not None:
        try:
            port = clamp_int(int(port), min_value=1, max_value=65535, name="port")
        except ValueError as e:
            security_event(logger, "invalid_port", error=str(e))
            return _tool_error(str(e))

    api_key2, err = _env_api_key()
    if err:
        return err

    full_query, bad_filters = _build_query(
        query,
        filters=filters,
        country=country,
        org=org,
        asn=asn,
        net=net,
        port=port,
        product=product,
        hostname=hostname,
        city=city,
    )
    if bad_filters:
        security_event(logger, "invalid_filters", count=len(bad_filters), examples=bad_filters[:5])
        return _tool_error("invalid filter(s) provided", details={"invalid": bad_filters[:50]})

    api = Shodan(api_key2)  # type: ignore[arg-type]

    try:
        res = api.search(full_query, page=page2)
    except APIError as e:
        security_event(logger, "shodan_api_error", error=str(e))
        return _tool_error("Shodan API error", details={"message": str(e)})
    except Exception as e:
        security_event(logger, "shodan_search_error", error=str(e))
        return _tool_error("Shodan search failed", details={"message": str(e)})

    total = int(res.get("total") or 0)
    matches = res.get("matches") or []
    if not isinstance(matches, list):
        matches = []

    summarized = _summarize_matches(matches, max_results=mr)

    meta = {
        "query": full_query,
        "page": page2,
        "total": total,
        "returned_by_shodan_on_this_page": len(matches),
        "shown": len(summarized),
        "note": "If total is larger than shown, paginate with `page=` to view more results.",
    }
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="shodan",
                tool_commandline={"query": full_query, "page": page2, "max_results": mr},
                scan_target=full_query,
                data={"result": summarized, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        summarized,
        meta=meta,
    )


@mcp.tool()
@register_tool
def shodan_filters(name: str | None = None) -> dict[str, Any]:
    """
    List known Shodan filters, or describe one filter by name.

    - `shodan_filters()` returns a list of filters (name/syntax/description).
    - `shodan_filters(name="country")` returns detailed info for a single filter.
    """
    if not name:
        return _tool_ok(list_known_filters(), meta={"count": len(list_known_filters())})

    info = describe_filter(name)
    if not info:
        return _tool_error(
            "unknown filter",
            details={
                "name": (name or "").strip(),
                "hint": "Use shodan_filters() to list known filters; you can still use arbitrary filters via shodan_search(filters=[...]).",
            },
        )
    return _tool_ok(info)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4565")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m shodan_mcp_server.server` works in Cursor without extra env.
    #
    # The Podman-oriented version can still explicitly set MCP_TRANSPORT=streamable-http.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport in {"stdio"}:
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4565

    # FastMCP supports http-like transports which do accept host/port/path.
    if transport in {"http", "sse", "streamable-http"}:
        logger.info(
            "Starting MCP server",
            extra={"transport": transport, "host": host, "port": port, "path": path or ""},
        )
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    # Fall back defensively to a known-good default.
    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info(
        "Starting MCP server with fallback transport",
        extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""},
    )
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

```python
from __future__ import annotations

import inspect
import json
import os
from pathlib import Path
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .paths import exploitdb_dir
from .searchsploit_cli import run_searchsploit, update_exploitdb


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="searchsploit")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


@mcp.tool()
@register_tool
def searchsploit_search(
    terms: list[str],
    *,
    case_insensitive: bool = True,
    max_results_hint: int | None = None,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run Searchsploit against the local ExploitDB clone.
    """
    cleaned = [t.strip() for t in (terms or []) if (t or "").strip()]
    if not cleaned:
        return _tool_error("terms must not be empty")

    flags: list[str] = []
    if case_insensitive:
        flags.append("-i")

    # Searchsploit output is text; we return raw stdout.
    rr = run_searchsploit(cleaned, flags=flags)
    meta = {"returncode": rr.returncode, "command": rr.command, "max_results_hint": max_results_hint}
    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="searchsploit",
                tool_commandline=rr.command,
                scan_target=" ".join(cleaned),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}
    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def searchsploit_read_exploit(relative_path: str, *, max_bytes: int = 200_000) -> dict[str, Any]:
    """
    Read an exploit file from the local ExploitDB clone (for source inspection).
    """
    rel = (relative_path or "").lstrip("/").strip()
    if not rel:
        return _tool_error("relative_path is required")

    base = exploitdb_dir().resolve()
    target = (base / rel).resolve()
    if not str(target).startswith(str(base) + os.sep):
        security_event(logger, "path_traversal_blocked", relative_path=relative_path)
        return _tool_error("path is outside exploitdb directory")
    if not target.exists() or not target.is_file():
        return _tool_error("file not found", details={"path": str(target)})

    data = target.read_bytes()
    if len(data) > max_bytes:
        data = data[:max_bytes]
    try:
        text = data.decode("utf-8", errors="replace")
    except Exception:
        text = repr(data[:2000])
    return _tool_ok({"path": str(target), "content": text, "truncated": target.stat().st_size > max_bytes})


@mcp.tool()
@register_tool
def searchsploit_scan_source(
    pattern: str,
    *,
    max_matches: int = 200,
) -> dict[str, Any]:
    """
    Simple source scanning over the exploitdb tree (grep-like).
    Returns file paths containing the pattern (case-insensitive).
    """
    pat = (pattern or "").strip()
    if not pat:
        return _tool_error("pattern is required")
    if len(pat) > 200:
        return _tool_error("pattern too long")

    base = exploitdb_dir()
    matches: list[str] = []
    # naive scan to avoid requiring rg in image; keep bounded
    for p in base.rglob("*"):
        if not p.is_file():
            continue
        try:
            b = p.read_bytes()
        except Exception:
            continue
        if pat.lower().encode() in b.lower():
            matches.append(str(p))
            if len(matches) >= max_matches:
                break

    return _tool_ok({"pattern": pat, "matches": matches, "max_matches": max_matches})


@mcp.tool()
@register_tool
def searchsploit_update() -> dict[str, Any]:
    """
    Update ExploitDB repos inside the running container (git pull).
    """
    return _tool_ok(update_exploitdb())


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4564")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m searchsploit_mcp_server.server` works in Cursor without extra env.
    #
    # The Podman-oriented version can still explicitly set MCP_TRANSPORT=streamable-http.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4564

    # FastMCP supports http-like transports which do accept host/port/path.
    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    # Fall back defensively to a known-good default.
    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

```plaintext
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "pentest-mcp-server"
version = "0.1.0"
description = "Standalone FastMCP coordination server (spawn-on-demand) for pentest tooling"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
  "fastmcp>=2.0.0",
  "pymongo>=4.7.0",
]

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]


```

```markdown
# pentest-mcp-server (Standalone coordinator, stdio-first)

This is a **standalone** MCP server (Python + FastMCP) intended to be run locally via **stdio** (Cursor command servers).

It exposes a **spawn-on-demand** port scanning toolset (RustScan / Nmap / Naabu) by invoking the underlying binaries as subprocesses (no shell).

## Transport

- Default: `MCP_TRANSPORT=stdio` (Cursor-friendly)
- Optional: `MCP_TRANSPORT=streamable-http` for HTTP clients (set `MCP_HOST`, `MCP_PORT`)

## Required host binaries

- `rustscan` (or set `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or set `NMAP_BIN=/path/to/nmap`)
- `naabu` (or set `NAABU_BIN=/path/to/naabu`)

## Local run (stdio)

From this directory (in a venv):

```bash
python -m pentest_mcp_server.server
```

## Tools

- `naabu_scan`, `naabu_scan_raw`
- `rustscan_scan`, `rustscan_scan_raw`
- `nmap_scan`, `nmap_scan_raw`
- `portscan_all`
- `list_tools`, `describe_tool`


```

```python
__all__ = ["__version__"]

__version__ = "0.1.0"


```

```python
from __future__ import annotations

import json
import logging
import os
from typing import Any


def configure_logging() -> None:
    level_name = os.getenv("LOG_LEVEL", "INFO").upper().strip()
    level = getattr(logging, level_name, logging.INFO)
    logging.basicConfig(
        level=level,
        format="%(asctime)s %(levelname)s %(name)s %(message)s",
    )


def get_logger(name: str) -> logging.Logger:
    return logging.getLogger(name)


def security_event(logger: logging.Logger, event: str, **fields: Any) -> None:
    payload = {"event": event, **fields}
    logger.warning("SECURITY_EVENT %s", json.dumps(payload, sort_keys=True, default=str))


```

```python
from __future__ import annotations

import ipaddress
import os
import re
from dataclasses import dataclass
from typing import Iterable
from urllib.parse import urlparse


_CONTROL_CHARS_RE = re.compile(r"[\x00-\x1f\x7f]")
_PORT_RANGE_RE = re.compile(r"^\s*(\d{1,5})\s*-\s*(\d{1,5})\s*$")
_PORT_LIST_RE = re.compile(r"^\s*\d{1,5}(\s*,\s*\d{1,5})*\s*$")

_HOSTNAME_RE = re.compile(
    r"^(?=.{1,253}$)(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?)(?:\.(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?))*\.?$"
)


@dataclass(frozen=True)
class ValidationResult:
    ok: bool
    message: str | None = None


def reject_injection(s: str) -> ValidationResult:
    if _CONTROL_CHARS_RE.search(s):
        return ValidationResult(False, "control characters are not allowed")
    if "\n" in s or "\r" in s:
        return ValidationResult(False, "newlines are not allowed")
    return ValidationResult(True)


def validate_target(target: str) -> ValidationResult:
    base = reject_injection(target)
    if not base.ok:
        return base

    t = target.strip()
    if not t:
        return ValidationResult(False, "target is empty")
    if len(t) > 2048:
        return ValidationResult(False, "target too long")

    # Accept URLs by extracting host
    if "://" in t:
        u = urlparse(t)
        if u.scheme not in ("http", "https"):
            return ValidationResult(False, "only http/https URLs are allowed")
        if u.username or u.password:
            return ValidationResult(False, "URLs with embedded credentials are not allowed")
        if not u.hostname:
            return ValidationResult(False, "URL must include a host")
        t = u.hostname

    # CIDR
    if "/" in t:
        try:
            ipaddress.ip_network(t, strict=False)
            return ValidationResult(True)
        except Exception:
            return ValidationResult(False, "invalid CIDR")

    # IP
    try:
        ipaddress.ip_address(t.strip("[]"))
        return ValidationResult(True)
    except Exception:
        pass

    # host:port
    if ":" in t:
        host, port = t.rsplit(":", 1)
        if not host:
            return ValidationResult(False, "invalid host:port")
        try:
            p = int(port)
            if p < 1 or p > 65535:
                return ValidationResult(False, "port out of range")
        except Exception:
            return ValidationResult(False, "invalid port")
        if _HOSTNAME_RE.match(host):
            return ValidationResult(True)
        try:
            ipaddress.ip_address(host.strip("[]"))
            return ValidationResult(True)
        except Exception:
            return ValidationResult(False, "invalid host")

    if _HOSTNAME_RE.match(t):
        return ValidationResult(True)

    return ValidationResult(False, "invalid target")


def validate_targets(targets: Iterable[str], *, max_targets: int = 2000) -> tuple[list[str], list[tuple[str, str]]]:
    ok: list[str] = []
    bad: list[tuple[str, str]] = []
    for x in targets:
        x2 = (x or "").strip()
        if not x2:
            continue
        res = validate_target(x2)
        if res.ok:
            ok.append(x2)
        else:
            bad.append((x2, res.message or "invalid"))
        if len(ok) >= max_targets:
            break
    return ok, bad


def validate_args(args: list[str], *, max_args: int = 200, max_total_len: int = 8000) -> ValidationResult:
    if len(args) > max_args:
        return ValidationResult(False, f"too many args (>{max_args})")
    total = 0
    for a in args:
        if a is None:
            return ValidationResult(False, "arg is None")
        if _CONTROL_CHARS_RE.search(a) or "\n" in a or "\r" in a:
            return ValidationResult(False, "args contain control characters")
        total += len(a)
    if total > max_total_len:
        return ValidationResult(False, f"args too long (>{max_total_len} chars)")
    return ValidationResult(True)


def normalize_rustscan_ports(ports: str, *, max_ports_list: int = 4096) -> tuple[ValidationResult, list[str]]:
    """
    Normalize the `ports` input used by this MCP server's RustScan wrapper.

    Supported formats:
    - "1-1024" => ["-r", "1-1024"]   (RustScan range flag)
    - "80,443" => ["-p", "80,443"]   (RustScan ports-list flag)
    """
    base = reject_injection(ports)
    if not base.ok:
        return base, []

    s = (ports or "").strip()
    if not s:
        return ValidationResult(False, "ports is empty"), []
    if len(s) > 4096:
        return ValidationResult(False, "ports is too long"), []

    m = _PORT_RANGE_RE.match(s)
    if m:
        try:
            start = int(m.group(1))
            end = int(m.group(2))
        except Exception:
            return ValidationResult(False, "invalid port range"), []
        if start < 1 or start > 65535 or end < 1 or end > 65535:
            return ValidationResult(False, "port out of range"), []
        if start > end:
            return ValidationResult(False, "invalid port range (start > end)"), []
        return ValidationResult(True), ["-r", f"{start}-{end}"]

    if not _PORT_LIST_RE.match(s):
        return ValidationResult(False, "invalid ports format (expected N-M or comma-separated list)"), []

    parts = [p.strip() for p in s.split(",") if p.strip()]
    if not parts:
        return ValidationResult(False, "ports is empty"), []
    if len(parts) > max_ports_list:
        return ValidationResult(False, f"too many ports (>{max_ports_list})"), []
    out: list[str] = []
    for p in parts:
        try:
            n = int(p)
        except Exception:
            return ValidationResult(False, "invalid port in list"), []
        if n < 1 or n > 65535:
            return ValidationResult(False, "port out of range"), []
        out.append(str(n))

    return ValidationResult(True), ["-p", ",".join(out)]


def clamp_int(value: int, *, min_value: int, max_value: int, name: str) -> int:
    if value < min_value:
        raise ValueError(f"{name} must be >= {min_value}")
    if value > max_value:
        raise ValueError(f"{name} must be <= {max_value}")
    return value


def env_bin(name: str, default: str) -> str:
    return os.getenv(name, default)


```

```python
from __future__ import annotations

import os
import shutil
import subprocess
from dataclasses import dataclass
from typing import Iterable

from .logging_utils import get_logger, security_event


logger = get_logger(__name__)


class BinaryNotFoundError(RuntimeError):
    pass


@dataclass(frozen=True)
class RunResult:
    command: list[str]
    stdout: str
    stderr: str
    returncode: int


def _ensure_bin(env_var: str, fallback_name: str) -> str:
    pinned = os.getenv(env_var, "").strip()
    if pinned:
        if os.path.isfile(pinned) and os.access(pinned, os.X_OK):
            return pinned
        raise BinaryNotFoundError(f"{env_var} is set but not executable: {pinned}")

    found = shutil.which(fallback_name)
    if not found:
        raise BinaryNotFoundError(f"{fallback_name} not found in PATH")
    return found


def run_cmd(
    *,
    cmd: list[str],
    stdin_lines: Iterable[str] | None = None,
    timeout_seconds: int | None = None,
) -> RunResult:
    stdin_data = None
    if stdin_lines is not None:
        stdin_data = "\n".join(list(stdin_lines)) + "\n"

    try:
        proc = subprocess.run(
            cmd,
            input=stdin_data,
            text=True,
            capture_output=True,
            check=False,
            timeout=timeout_seconds,
            env=os.environ.copy(),
        )
    except subprocess.TimeoutExpired:
        security_event(logger, "subprocess_timeout", command=cmd, timeout_seconds=timeout_seconds)
        raise
    except Exception as e:
        security_event(logger, "subprocess_failed", command=cmd, error=str(e))
        raise

    return RunResult(
        command=cmd,
        stdout=proc.stdout or "",
        stderr=proc.stderr or "",
        returncode=proc.returncode,
    )


def run_naabu(*, targets: list[str], args: list[str], timeout_seconds: int | None = None) -> RunResult:
    naabu = _ensure_bin("NAABU_BIN", "naabu")
    cmd = [naabu, *args]
    return run_cmd(cmd=cmd, stdin_lines=targets, timeout_seconds=timeout_seconds)


def run_nmap(*, targets: list[str], args: list[str], timeout_seconds: int | None = None) -> RunResult:
    nmap = _ensure_bin("NMAP_BIN", "nmap")
    cmd = [nmap, *args, *targets]
    return run_cmd(cmd=cmd, stdin_lines=None, timeout_seconds=timeout_seconds)


def run_rustscan(
    *,
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    timeout_seconds: int | None = None,
) -> RunResult:
    rustscan = _ensure_bin("RUSTSCAN_BIN", "rustscan")

    # RustScan expects addresses via -a/--addresses; we pass a comma-separated list.
    # When passing Nmap flags, RustScan uses `--` separator.
    cmd = [rustscan, "-a", ",".join(targets), *args]
    if nmap_args:
        cmd.extend(["--", *nmap_args])

    return run_cmd(cmd=cmd, stdin_lines=None, timeout_seconds=timeout_seconds)


```

```python
from __future__ import annotations

from dataclasses import dataclass


@dataclass(frozen=True)
class NormalizedOptions:
    ports: str | None = None
    top_ports: int | None = None
    min_rate: int | None = None


def _pop_flag_value(args: list[str], *names: str) -> tuple[list[str], str | None]:
    out: list[str] = []
    i = 0
    value: str | None = None
    while i < len(args):
        a = args[i]
        if a in names and i + 1 < len(args):
            value = args[i + 1]
            i += 2
            continue
        out.append(a)
        i += 1
    return out, value


def normalize_nmap_style_args(nmap_args: list[str]) -> tuple[NormalizedOptions, list[str]]:
    """Extract a small set of common options from Nmap-style args for cross-tool continuity."""

    args = nmap_args[:]
    opts = NormalizedOptions()

    # -p PORTS
    args, ports = _pop_flag_value(args, "-p", "--ports")
    if ports:
        opts = NormalizedOptions(ports=ports, top_ports=opts.top_ports, min_rate=opts.min_rate)

    # --top-ports N
    args, top_ports = _pop_flag_value(args, "--top-ports")
    if top_ports:
        try:
            tp = int(top_ports)
            opts = NormalizedOptions(ports=opts.ports, top_ports=tp, min_rate=opts.min_rate)
        except Exception:
            pass

    # --min-rate N (best-effort mapping to naabu -rate)
    args, min_rate = _pop_flag_value(args, "--min-rate")
    if min_rate:
        try:
            mr = int(min_rate)
            opts = NormalizedOptions(ports=opts.ports, top_ports=opts.top_ports, min_rate=mr)
        except Exception:
            pass

    return opts, args


RAW_SOCKET_NMAP_FLAGS = {
    # Scan techniques requiring raw sockets when unprivileged
    "-sS",
    "-sA",
    "-sN",
    "-sF",
    "-sX",
    "-sU",
    "-sY",
    "-sZ",
    "-sO",
    "-sW",
    "-sM",
    "-sI",
    # Other privileged features
    "-O",
    "--osscan-guess",
    "--traceroute",
}


def coerce_nmap_unprivileged(args: list[str]) -> tuple[list[str], list[str]]:
    """Coerce Nmap args to work without raw sockets (rootless safe)."""

    notes: list[str] = []
    out: list[str] = []

    saw_scan_type = any(a.startswith("-s") and len(a) >= 3 for a in args)
    removed_raw_scan_type = False

    for a in args:
        if a in {"--unprivileged", "--privileged"}:
            out.append(a)
            continue

        if a in RAW_SOCKET_NMAP_FLAGS:
            if a.startswith("-s"):
                removed_raw_scan_type = True
            else:
                notes.append(f"removed {a} (requires privileges/raw sockets)")
            continue

        out.append(a)

    if removed_raw_scan_type:
        notes.append("replaced raw-socket scan type with -sT (connect scan) for unprivileged compatibility")
        out = [x for x in out if not (x.startswith("-s") and len(x) >= 3)]
        out.insert(0, "-sT")
        saw_scan_type = True

    if "--unprivileged" not in out and "--privileged" not in out:
        out.insert(0, "--unprivileged")
        notes.append("added --unprivileged")

    if not saw_scan_type:
        out.insert(0, "-sT")
        notes.append("defaulted to -sT (connect scan)")

    return out, notes


```

```python
from __future__ import annotations

import json
import os
from datetime import datetime, timezone
from typing import Any

from pymongo import MongoClient


def save_to_mongo_result(*, tool_name: str, tool_commandline: Any, scan_target: str, data: Any) -> dict[str, Any]:
    uri = os.getenv("MONGO_URI", "").strip()
    if not uri:
        return {"saved": False, "error": "MONGO_URI is not set"}

    db_name = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
    coll_name = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    doc = {
        "tool_name": (tool_name or "").strip().lower(),
        "date_run": datetime.now(timezone.utc).isoformat(),
        "tool_commandline": json.dumps(tool_commandline, default=str),
        "scan_target": (scan_target or "").strip(),
        "data": data,
    }

    client = MongoClient(uri, serverSelectionTimeoutMS=3000)
    res = client[db_name][coll_name].insert_one(doc)
    return {"saved": True, "type": "mongo", "db": db_name, "collection": coll_name, "inserted_id": str(res.inserted_id)}


```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    *,
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    *,
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    *,
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    *,
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run naabu, rustscan, and nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()


```

Good catch: because this uses a `src/` layout, a plain `python -c ...` won’t see the package unless it’s installed or `PYTHONPATH` includes `src`. Next I’ll rerun a quick import check with `PYTHONPATH=src`, then proceed to wire up the coordinator docs/tool-name compatibility todo.

```python
from __future__ import annotations

import json
import os
from datetime import datetime, timezone
from typing import Any


def save_to_mongo_result(*, tool_name: str, tool_commandline: Any, scan_target: str, data: Any) -> dict[str, Any]:
    try:
        from pymongo import MongoClient  # type: ignore
    except Exception:
        return {"saved": False, "error": "pymongo is not installed (pip install pymongo)"}

    uri = os.getenv("MONGO_URI", "").strip()
    if not uri:
        return {"saved": False, "error": "MONGO_URI is not set"}

    db_name = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
    coll_name = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    doc = {
        "tool_name": (tool_name or "").strip().lower(),
        "date_run": datetime.now(timezone.utc).isoformat(),
        "tool_commandline": json.dumps(tool_commandline, default=str),
        "scan_target": (scan_target or "").strip(),
        "data": data,
    }

    client = MongoClient(uri, serverSelectionTimeoutMS=3000)
    res = client[db_name][coll_name].insert_one(doc)
    return {"saved": True, "type": "mongo", "db": db_name, "collection": coll_name, "inserted_id": str(res.inserted_id)}



```

Great — Shodan + Searchsploit are now standardized to be **stdio-first** in the standalone tree, and `Standalone_Build/pentest-mcp-server/` is created as a **true standalone coordinator** (its own package, stdio default, spawn-on-demand subprocess execution). Next I’ll (1) explicitly document the tool-name compatibility (`rustscan_scan`, etc.) in the coordinator README and (2) write the standalone “how to run + required installs” docs for the whole `Standalone_Build/` setup.

---

**User**

Ok, please perform the next steps you mentioned in the previous results around documentation, etc

---

**Cursor**

Next I’ll focus purely on **standalone documentation**: a top-level `Standalone_Build/README.md` with local install/run instructions (stdio/Cursor), plus a compatibility section in `pentest-mcp-server/README.md` that explicitly documents tool names like `rustscan_scan`. Then I’ll mark the remaining doc-related todos complete.

```markdown
# Standalone_Build (local / terminal MCP servers)

`Standalone_Build/` is the **local-first** (non-Podman) version of the MCP servers in this repo.

- The original Podman servers (e.g. `portscan-mcp-server/`) are kept intact.
- The standalone copies live here and are safe to modify.
- Default transport is **stdio** so Cursor can launch them as **command MCP servers**.

## Quickstart (recommended)

### 1) Install required host binaries (per tool)

You must install the underlying CLI tools on your host, or set `*_BIN` env vars to point at them.

**Port scanning (coordinator):**
- `rustscan` (or `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or `NMAP_BIN=/path/to/nmap`)
- `naabu` (or `NAABU_BIN=/path/to/naabu`)

Other standalone servers in this directory have their own host dependencies (WPScan, theHarvester, Searchsploit, etc.).

### 2) Create a Python venv and install the server(s)

Each server directory here is a standalone Python package with a `pyproject.toml`.

Example for the coordinator:

```bash
cd "Standalone_Build/pentest-mcp-server"
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e .
```

Repeat for any other standalone MCP servers you want to run locally (e.g. `Standalone_Build/shodan-mcp-server`, `Standalone_Build/mongo-mcp-server`, etc.).

### 3) Run (stdio)

From inside the server directory (venv active):

```bash
python -m pentest_mcp_server.server
```

## Cursor MCP configuration (stdio command server)

Cursor uses stdio “command” MCP servers. A typical `.cursor/mcp.json` entry looks like:

```json
{
  "mcpServers": {
    "pentest": {
      "command": "python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
```

Notes:
- This assumes `pentest-mcp-server` was installed into the Python environment Cursor will use to launch the command.
- If you prefer, you can set `command` to an absolute path to the venv Python (recommended for reliability).


```

```markdown
# pentest-mcp-server (Standalone coordinator, stdio-first)

This is a **standalone** MCP server (Python + FastMCP) intended to be run locally via **stdio** (Cursor command servers).

It exposes a **spawn-on-demand** port scanning toolset (RustScan / Nmap / Naabu) by invoking the underlying binaries as subprocesses (no shell).

## Compatibility (tool names)

The coordinator intentionally exports **the same tool names** as `Standalone_Build/portscan-mcp-server` so an AI agent can call them consistently:

- `naabu_scan`, `naabu_scan_raw`
- `rustscan_scan`, `rustscan_scan_raw`
- `nmap_scan`, `nmap_scan_raw`
- `portscan_all`

It also exports the standard introspection tools:

- `list_tools`
- `describe_tool`

## Transport

- Default: `MCP_TRANSPORT=stdio` (Cursor-friendly)
- Optional: `MCP_TRANSPORT=streamable-http` for HTTP clients (set `MCP_HOST`, `MCP_PORT`)

## Required host binaries

- `rustscan` (or set `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or set `NMAP_BIN=/path/to/nmap`)
- `naabu` (or set `NAABU_BIN=/path/to/naabu`)

## Local run (stdio)

From this directory (in a venv):

```bash
python -m pentest_mcp_server.server
```

## Tools

- `naabu_scan`, `naabu_scan_raw`
- `rustscan_scan`, `rustscan_scan_raw`
- `nmap_scan`, `nmap_scan_raw`
- `portscan_all`
- `list_tools`, `describe_tool`



```

### Done: documentation + compatibility notes (Standalone_Build only)

- **Standalone docs added**: `Standalone_Build/README.md` now explains:
  - What `Standalone_Build/` is (local-first, Podman originals untouched)
  - Host binary requirements (starting with RustScan/Nmap/Naabu)
  - Venv + `pip install -e .` workflow
  - Example **Cursor stdio** `.cursor/mcp.json` entry for the coordinator

- **Coordinator tool-name compatibility documented**: `Standalone_Build/pentest-mcp-server/README.md` now explicitly states it exports the same tool names as `Standalone_Build/portscan-mcp-server`:
  - `rustscan_scan`, `nmap_scan`, `naabu_scan`, `portscan_all` (+ `*_raw`)
  - plus `list_tools` / `describe_tool`

- **Todos**: all plan todos are now **completed**.

---

**User**

Can you please create me an mcp.json file for this project scope to use the coordination server and would any other MCP servers need to be added to the mcp.json?

---

**Cursor**

I’ll first check whether you already have a `.cursor/mcp.json` (so we don’t overwrite anything), then I’ll generate a **standalone** MCP config that launches `Standalone_Build/pentest-mcp-server` in **stdio**. After that I’ll note which extra servers are optional (Shodan/Searchsploit/Mongo) depending on what tools you want available.

Got it — this environment blocks writing to `.cursor/` (it’s globally ignored), so I’ll generate the config as `Standalone_Build/mcp.json`. You can then copy it to your actual `.cursor/mcp.json` locally if desired. Next I’ll write that file and include optional server entries you can enable if you want Shodan/Searchsploit/etc. available alongside the coordinator.

```jsonc
{
  "mcpServers": {
    "pentest": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pentest-mcp-server/.venv/bin/python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "NMAP_FORCE_UNPRIVILEGED": "1"
      }
    }
  }
}


```

### `mcp.json` created
I created a **project-scope** config at `Standalone_Build/mcp.json` that launches the **coordination server** (`pentest-mcp-server`) in **stdio** mode.

- File: `Standalone_Build/mcp.json`
- Server name: `pentest`
- Command: points at `Standalone_Build/pentest-mcp-server/.venv/bin/python`
  - Adjust this path if your venv is elsewhere.

### Would any other MCP servers need to be added?
- **No**, if you only need what the coordinator currently exposes (right now: **port scanning** tools like `rustscan_scan`, `nmap_scan`, `naabu_scan`, `portscan_all`).
- **Yes**, if you also want other tools **today** (since the coordinator doesn’t yet wrap them). In that case, add their **Standalone_Build** equivalents as additional `mcpServers`, e.g.:
  - `Standalone_Build/shodan-mcp-server` (Shodan tools)
  - `Standalone_Build/searchsploit-mcp-server` (Searchsploit tools)
  - `Standalone_Build/wpscan-mcp-server`, `Standalone_Build/theharvester-mcp-server`, `Standalone_Build/searx-mcp-server`, etc.
  - Optional: `Standalone_Build/mongo-mcp-server` if you want an MCP interface to query stored results in MongoDB.

If you tell me which of those you want available alongside `pentest`, I’ll extend `Standalone_Build/mcp.json` with the exact additional entries.

---

**User**

Please add those MCP servers that the Coordination MCP server does not wrap/cannot access.

---

**Cursor**

Plan: I’ll quickly scan the standalone server code to see what env vars each one expects (especially Searx/Shodan/Mongo/output dirs), then I’ll extend `Standalone_Build/mcp.json` with additional stdio command servers for every tool not yet wrapped by `pentest`.

```jsonc
{
  "mcpServers": {
    "pentest": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pentest-mcp-server/.venv/bin/python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "NMAP_FORCE_UNPRIVILEGED": "1"
      }
    },
    "pdtm": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pdtm-mcp-server/.venv/bin/python",
      "args": ["-m", "pdtm_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "OUTPUT_DIR": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/output/pdtm",
        "DOWNLOAD_DIR": "/Users/pkincaid/Downloads"
      }
    },
    "shodan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/shodan-mcp-server/.venv/bin/python",
      "args": ["-m", "shodan_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    },
    "searchsploit": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/searchsploit-mcp-server/.venv/bin/python",
      "args": ["-m", "searchsploit_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    },
    "searx": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/searx-mcp-server/.venv/bin/python",
      "args": ["-m", "searx_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "SEARXNG_URL": "http://127.0.0.1:8080"
      }
    },
    "theharvester": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/theharvester-mcp-server/.venv/bin/python",
      "args": ["-m", "theharvester_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "HARVESTER_OUTPUT_DIR": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/output/theharvester"
      }
    },
    "wpscan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/wpscan-mcp-server/.venv/bin/python",
      "args": ["-m", "wpscan_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    },
    "mongo": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mongo-mcp-server/.venv/bin/python",
      "args": ["-m", "mongo_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    }
  }
}



```

### Updated `mcp.json` (added all standalone servers not wrapped by the coordinator)
I updated `Standalone_Build/mcp.json` to include these additional MCP command servers (stdio) alongside `pentest`:

- `pdtm`
- `shodan`
- `searchsploit`
- `searx`
- `theharvester`
- `wpscan`
- `mongo`

### Notes / required config
- **You’ll need a `.venv` per server** (the `command` paths assume each standalone server was installed into its own `Standalone_Build/<server>/.venv/`). If you prefer a single shared venv, tell me and I’ll rewrite the config accordingly.
- **Secrets are not embedded**:
  - `shodan` needs `SHODAN_API_KEY` available in the environment Cursor uses to launch the server (or we can add it to the `env` block, but I won’t hardcode it).
  - `wpscan` may need `WPSCAN_API_TOKEN` similarly.
- **Searx**: set to `SEARXNG_URL="http://127.0.0.1:8080"` (adjust if your SearXNG runs elsewhere).
- **theHarvester output dir**: `HARVESTER_OUTPUT_DIR` points at `Standalone_Build/output/theharvester` (ensure the directory exists).
- **pdtm output/download**:
  - `OUTPUT_DIR` is set to `Standalone_Build/output/pdtm`
  - `DOWNLOAD_DIR` is set to `/Users/pkincaid/Downloads` (adjust if desired)

If you want, I can also generate a “single shared venv” version of this `mcp.json` so you only manage one Python environment.

---

**User**

Could you please create a shared, single .venv environment for all of the MCP servers and modify all of the MCP servers and the mcp.json file to run from that single.venv environment

---

**Cursor**

Plan: I’ll create a single shared venv at `Standalone_Build/.venv`, install all standalone MCP server packages into it (editable installs), and recreate `Standalone_Build/mcp.json` so every server uses the same `Standalone_Build/.venv/bin/python`. Then I’ll update `Standalone_Build/README.md` with the one-venv setup steps.

```jsonc
{
  "mcpServers": {
    "pentest": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "NMAP_FORCE_UNPRIVILEGED": "1"
      }
    },
    "pdtm": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "pdtm_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "OUTPUT_DIR": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/output/pdtm",
        "DOWNLOAD_DIR": "/Users/pkincaid/Downloads"
      }
    },
    "shodan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "shodan_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    },
    "searchsploit": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "searchsploit_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    },
    "searx": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "searx_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "SEARXNG_URL": "http://127.0.0.1:8080"
      }
    },
    "theharvester": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "theharvester_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1",
        "HARVESTER_OUTPUT_DIR": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/output/theharvester"
      }
    },
    "wpscan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "wpscan_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    },
    "mongo": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
      "args": ["-m", "mongo_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO",
        "PYTHONUNBUFFERED": "1"
      }
    }
  }
}


```

```markdown
# Standalone_Build (local / terminal MCP servers)

`Standalone_Build/` is the **local-first** (non-Podman) version of the MCP servers in this repo.

- The original Podman servers (e.g. `portscan-mcp-server/`) are kept intact.
- The standalone copies live here and are safe to modify.
- Default transport is **stdio** so Cursor can launch them as **command MCP servers**.

## Quickstart (recommended)

### 1) Install required host binaries (per tool)

You must install the underlying CLI tools on your host, or set `*_BIN` env vars to point at them.

**Port scanning (coordinator):**
- `rustscan` (or `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or `NMAP_BIN=/path/to/nmap`)
- `naabu` (or `NAABU_BIN=/path/to/naabu`)

Other standalone servers in this directory have their own host dependencies (WPScan, theHarvester, Searchsploit, etc.).

### 2) Create a single shared Python venv (recommended) and install all servers

Each server directory here is a standalone Python package with a `pyproject.toml`, but you can (and should) run them all from a **single shared venv** to keep Cursor config simple.

Create the shared venv at `Standalone_Build/.venv` and install all servers into it:

```bash
cd "Standalone_Build"
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e ./pentest-mcp-server \
            -e ./portscan-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### 3) Run (stdio)

From inside `Standalone_Build/` (venv active):

```bash
python -m pentest_mcp_server.server
```

## Cursor MCP configuration (stdio command server)

Cursor uses stdio “command” MCP servers. A typical `.cursor/mcp.json` entry looks like:

```json
{
  "mcpServers": {
    "pentest": {
      "command": "python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
```

Notes:
- This assumes `pentest-mcp-server` was installed into the Python environment Cursor will use to launch the command.
- If you prefer, you can set `command` to an absolute path to the venv Python (recommended for reliability).



```

### Shared single `.venv` created + config updated

- **Shared venv created**: `MCP_Servers/Standalone_Build/.venv/`
- **All standalone MCP servers installed into it** (editable installs), and verified imports.
- **`Standalone_Build/mcp.json` recreated/updated** so every server uses:

```text
/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python
```

### What you need to do in Cursor
- Copy `Standalone_Build/mcp.json` into your actual Cursor MCP config location (since writing to `.cursor/` is blocked in this environment), typically `.cursor/mcp.json`.

### Important env vars to set (not hardcoded)
- **Shodan**: `SHODAN_API_KEY`
- **WPScan**: `WPSCAN_API_TOKEN` (if you use API-backed features)
- **Mongo (optional)**: `MONGO_URI`, `MONGO_DB`, `MONGO_COLLECTION` if you want result persistence/querying

```plaintext
/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python
```

---

**User**

Can you create a .env file with the necessary environment variables and ensure the required scripts can call from the .env file in the Standalone_Build directory/.env

---

**Cursor**

Plan: I’ll check if `Standalone_Build/.env` already exists (so we don’t overwrite it), then create a new `.env` with the shared variables (paths, Mongo, Shodan/WPScan tokens), and add a small launcher script that sources this `.env` before starting each MCP server. Finally, I’ll update `Standalone_Build/mcp.json` to use that launcher so Cursor always loads the `.env`.

Good catch: the editor tooling blocks creating dotfiles like `Standalone_Build/.env` via patch (global ignore), but we can still create it safely using a terminal write. Next I’ll generate `Standalone_Build/.env`, add a `Standalone_Build/run-mcp.sh` launcher that sources it, and update `Standalone_Build/mcp.json` to use that launcher so every server loads the `.env` automatically.

```jsonc
*** Begin Patch
*** Update File: Standalone_Build/mcp.json
@@
 {
   "mcpServers": {
     "pentest": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "pentest_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["pentest_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1",
-        "NMAP_FORCE_UNPRIVILEGED": "1"
+        "MCP_TRANSPORT": "stdio"
       }
     },
     "pdtm": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "pdtm_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["pdtm_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1",
-        "OUTPUT_DIR": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/output/pdtm",
-        "DOWNLOAD_DIR": "/Users/pkincaid/Downloads"
+        "MCP_TRANSPORT": "stdio"
       }
     },
     "shodan": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "shodan_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["shodan_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1"
+        "MCP_TRANSPORT": "stdio"
       }
     },
     "searchsploit": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "searchsploit_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["searchsploit_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1"
+        "MCP_TRANSPORT": "stdio"
       }
     },
     "searx": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "searx_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["searx_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1",
-        "SEARXNG_URL": "http://127.0.0.1:8080"
+        "MCP_TRANSPORT": "stdio"
       }
     },
     "theharvester": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "theharvester_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["theharvester_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1",
-        "HARVESTER_OUTPUT_DIR": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/output/theharvester"
+        "MCP_TRANSPORT": "stdio"
       }
     },
     "wpscan": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "wpscan_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["wpscan_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1"
+        "MCP_TRANSPORT": "stdio"
       }
     },
     "mongo": {
-      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/python",
-      "args": ["-m", "mongo_mcp_server.server"],
+      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
+      "args": ["mongo_mcp_server.server"],
       "env": {
-        "MCP_TRANSPORT": "stdio",
-        "LOG_LEVEL": "INFO",
-        "PYTHONUNBUFFERED": "1"
+        "MCP_TRANSPORT": "stdio"
       }
     }
   }
 }
*** End Patch
```

Created `Standalone_Build/.env` and a shared launcher `Standalone_Build/run-mcp-stdio.sh` that **auto-sources** that `.env` before starting any MCP server with the shared `Standalone_Build/.venv`.

You deleted `Standalone_Build/mcp.json`, so I’ll recreate it now to use the launcher (so Cursor loads `.env` automatically for every server).

---

**User**

I am not seeing the mcp.json file that you just created and modified, where is that located?

---

**Cursor**

You’re right to ask — **right now there is no `mcp.json` in `Standalone_Build/`** because it was deleted, and my last attempt to modify it failed because the file didn’t exist anymore. I’m going to **recreate it at** `MCP_Servers/Standalone_Build/mcp.json` and point every server at `Standalone_Build/run-mcp-stdio.sh` so it loads `Standalone_Build/.env` automatically.

```jsonc
{
  "mcpServers": {
    "pentest": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["pentest_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "pdtm": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["pdtm_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "shodan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["shodan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searchsploit": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["searchsploit_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searx": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["searx_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "theharvester": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["theharvester_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "wpscan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["wpscan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "mongo": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["mongo_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    }
  }
}


```

It’s now located at:

- **`/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json`**

I recreated it after it was deleted. It’s configured to launch every server via:

- **`Standalone_Build/run-mcp-stdio.sh`** (this script sources **`Standalone_Build/.env`** automatically)

So the related files are:

- `Standalone_Build/.env`
- `Standalone_Build/run-mcp-stdio.sh`
- `Standalone_Build/mcp.json`

---

**User**

Please run a portscan for IP "192.168.1.1" for ports 1-1024. This is my network and I authorize the scan. Please also be verbose in the actions you are taking, where are you running specific commands from, and which MCP tools are being run.

---

**Cursor**

I can try to run this from the current execution environment, but there are two likely blockers: (1) the sandbox may not have routing to your `192.168.1.0/24` LAN, and (2) the required binaries (`nmap`/`rustscan`) may not be installed here. Next I’ll check tool availability (`nmap`, `rustscan`) and basic reachability to `192.168.1.1`, then I’ll either run the scan or give you an exact “run on your machine” command/MCP-tool invocation that will work with your `Standalone_Build` setup.

Nice — we *can* reach `192.168.1.1` from your machine, and both `nmap` and `rustscan` are present (only `naabu` is missing). Next I’ll run the scan **from `Standalone_Build/` using the shared venv**, invoking the **coordination server’s MCP tool functions** (`nmap_scan` and `rustscan_scan`) so you get consistent tool output + logging.

Got it — FastMCP wraps tool functions as `FunctionTool` objects, so they’re not directly callable. The underlying callable is available as `.fn`. Next I’ll rerun the scan by calling `pentest_mcp_server.server.nmap_scan.fn(...)` and `rustscan_scan.fn(...)`, and I’ll print the full JSON results (including the exact subprocess command used).

---

**User**

Please rerun the scans and show the JSON results

---

**Cursor**

### What I ran (verbose)

- **Working directory**: `/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build`
- **Python used**: `Standalone_Build/.venv/bin/python` (shared venv)
- **MCP tools invoked (from the coordination server code)**:
  - `pentest_mcp_server.server.nmap_scan` (called via `.fn`)
  - `pentest_mcp_server.server.rustscan_scan` (called via `.fn`)
- **Underlying binaries executed by the coordinator** (shown in `meta.command`):
  - `/opt/homebrew/bin/nmap ...`
  - `/opt/homebrew/bin/rustscan ...`

### JSON results

#### `nmap_scan` (ports 1-1024 on `192.168.1.1`)

```json
{
  "ok": true,
  "result": {
    "stdout": "Starting Nmap 7.98 ( https://nmap.org ) at 2025-12-27 14:48 -0600\nNmap scan report for 192.168.1.1\nHost is up (0.0038s latency).\nNot shown: 1021 closed tcp ports (conn-refused)\nPORT    STATE    SERVICE\n53/tcp  filtered domain\n80/tcp  open     http\n443/tcp open     https\n\nNmap done: 1 IP address (1 host up) scanned in 10.23 seconds\n",
    "stderr": ""
  },
  "meta": {
    "returncode": 0,
    "command": [
      "/opt/homebrew/bin/nmap",
      "--unprivileged",
      "-p",
      "1-1024",
      "-sT",
      "192.168.1.1"
    ],
    "invalid_targets": [],
    "nmap_notes": [
      "added --unprivileged"
    ]
  }
}
```

#### `rustscan_scan` (ports 1-1024 on `192.168.1.1`)

```json
{
  "ok": true,
  "result": {
    "stdout": "...\nOpen 192.168.1.1:53\nOpen 192.168.1.1:80\nOpen 192.168.1.1:443\n...\n",
    "stderr": ""
  },
  "meta": {
    "returncode": 0,
    "command": [
      "/opt/homebrew/bin/rustscan",
      "-a",
      "192.168.1.1",
      "-r",
      "1-1024"
    ],
    "invalid_targets": [],
    "nmap_notes": []
  }
}
```

(Your full RustScan stdout includes ANSI color codes + an embedded Nmap connect scan section; I left the JSON structure intact and only abbreviated the `stdout` display above for readability. If you want, I can reprint the entire `stdout` field verbatim.)

```json
{
  "ok": true,
  "result": {
    "stdout": "Starting Nmap 7.98 ( https://nmap.org ) at 2025-12-27 14:48 -0600\nNmap scan report for 192.168.1.1\nHost is up (0.0038s latency).\nNot shown: 1021 closed tcp ports (conn-refused)\nPORT    STATE    SERVICE\n53/tcp  filtered domain\n80/tcp  open     http\n443/tcp open     https\n\nNmap done: 1 IP address (1 host up) scanned in 10.23 seconds\n",
    "stderr": ""
  },
  "meta": {
    "returncode": 0,
    "command": [
      "/opt/homebrew/bin/nmap",
      "--unprivileged",
      "-p",
      "1-1024",
      "-sT",
      "192.168.1.1"
    ],
    "invalid_targets": [],
    "nmap_notes": [
      "added --unprivileged"
    ]
  }
}
```

```json
{
  "ok": true,
  "result": {
    "stdout": "...\nOpen 192.168.1.1:53\nOpen 192.168.1.1:80\nOpen 192.168.1.1:443\n...\n",
    "stderr": ""
  },
  "meta": {
    "returncode": 0,
    "command": [
      "/opt/homebrew/bin/rustscan",
      "-a",
      "192.168.1.1",
      "-r",
      "1-1024"
    ],
    "invalid_targets": [],
    "nmap_notes": []
  }
}
```

---

**User**

For the pdtm container - we will need to start the container with the `--cap-add CAP_NET_RAW` setting to start the container to ensure the scans can run

---

**Cursor**

Yes — **for the Podman `pdtm-mcp-server` container**, adding **`--cap-add=CAP_NET_RAW`** is a common requirement for scanners that rely on **raw sockets** (ICMP/ping-style discovery, SYN scans, etc.). Without it, tools may see hosts as down or fail with permission errors.

### Recommended Podman flags (depending on what you run inside PDTM)
- **Minimum** (what you suggested):

```bash
--cap-add=CAP_NET_RAW
```

- **Often also needed** (varies by tool/scan mode; especially for packet crafting / interface ops):

```bash
--cap-add=CAP_NET_ADMIN
```

- **If you still hit permission issues in rootless Podman**, the pragmatic fallback is `--privileged` (broad) or running the container rootful. I’d try `CAP_NET_RAW` first, then `CAP_NET_ADMIN`, and only then consider `--privileged`.

### Quick clarifier (so I give the right exact command)
Are you planning to keep **PDTM as a container** (Podman) while the rest runs standalone, or do you want **PDTM standalone** too?

```shellscript
--cap-add=CAP_NET_RAW
```

```shellscript
--cap-add=CAP_NET_ADMIN
```

---

**User**

Does Cursor have a terminal CLI that can be used in the same way as Claude Code to run queries and searches?

---

**Cursor**

Cursor doesn’t ship a first-party **“Claude Code–style” terminal CLI** for running natural-language repo queries/searches *outside* the editor. Cursor’s “agent” experience is primarily **inside the IDE** (chat + inline edits), and its MCP integration is configured via editor settings (e.g., `.cursor/mcp.json`).

### Closest equivalents
- **Inside Cursor**: use **Chat** + built-in codebase tools (search, “find references”, etc.) and MCP tools you’ve configured.
- **From a terminal**: there isn’t an official `cursor` command that gives you the same interactive agent over your repo in the way Claude Code does.

If you want a CLI workflow, the usual options are:
- **Claude Code** (as you mentioned), or
- **OpenAI Codex CLI / similar agent CLIs**, configured to point at your repo, or
- A small **custom CLI** that calls your local MCP servers (stdio or HTTP) and runs scripted searches/scans.

If you tell me what you want the CLI to do (e.g., “search repo for X”, “ask questions about code”, “run MCP tools”), I can recommend the most practical setup.

---

**User**

I would like to be able to use the MCP servers that we have built here via the commandline vs. having to use it here in the Cursor Chat - it seem a bit overkill and the chats here seem to be more intent on modifying code vs. just doing the scans, requests, etc that I request.

Is it possible to build a CLI that can act similar to Claude Code to allow me to ask, in plain english, to perform a scan, etc or to provide a JSON variable that can be sent to the MCP server.

---

**Cursor**

Yes — you can build a **terminal CLI** that talks to your MCP servers without using Cursor chat, in two useful modes:

### Option A (fastest, no AI): CLI that sends JSON to an MCP server tool
- **What you get**: `pentest-cli call pentest rustscan_scan --json '{...}'`
- **How it works**: the CLI starts the MCP server over **stdio** (or connects over HTTP), calls `list_tools/describe_tool`, then calls the tool with your JSON.
- **Pros**: reliable, deterministic, no API keys, easy to audit/log.
- **Cons**: you either need to know the tool name + params, or ask `list_tools` first.

### Option B (Claude-Code-like): CLI that accepts plain English and runs tools
- **What you get**: `pentest-cli ask "scan 192.168.1.1 ports 1-1024 with rustscan"`
- **How it works**:
  - The CLI uses an LLM to translate English → `{tool_name, args}` (or directly chooses from `list_tools`).
  - Then it executes the tool through MCP exactly like Option A.
- **Pros**: “plain English” experience.
- **Cons**: you must choose an LLM source (OpenAI/Anthropic/local model), handle tokens/keys, and add guardrails (confirm target scope, require `i_acknowledge_risk` for raw-mode tools, etc.).

### Recommended design (for your repo)
- Build a new standalone package under **`Standalone_Build/pentest-cli/`** that supports:
  - `list-tools <server>` (calls MCP `list_tools`)
  - `describe-tool <server> <tool>`
  - `call <server> <tool> --json @file.json` (or `--json '{...}'`)
  - `ask "<english>"` (optional; uses LLM + tool introspection)
- Start by targeting **stdio** using your existing launcher `Standalone_Build/run-mcp-stdio.sh`, so the CLI can simply spawn:
  - `run-mcp-stdio.sh pentest_mcp_server.server` and then speak MCP over stdin/stdout.

### Two quick choices so I build it the way you want
1. Which mode do you want first?
   - a) JSON-only CLI (no AI)
   - b) English + JSON (AI + fallback to JSON)
2. If you want English mode, which LLM source?
   - a) Local model (Ollama/etc.)
   - b) OpenAI API
   - c) Anthropic API

---

**User**

Lets go with 1.a) and please make the CLI have an interactive shell so I don't need to call the program each time, I can just enter my request within the shell - kind of the same way that Claude Code opens an interactive environment and provide a help system so I can easily figure out what MCP tools are available.

---

**Cursor**

Plan: I’ll add a new standalone package under `Standalone_Build/pentest-cli/` that starts your MCP servers in stdio mode, speaks the MCP protocol over stdin/stdout, and gives you an interactive shell with `help`, `servers`, `tools`, `describe`, and `call` (JSON). Next I’ll check whether `fastmcp` already ships a Python client we can reuse; if not, I’ll implement a small MCP stdio client (JSON-RPC framing).

Got it — I’ll build a **standalone interactive terminal CLI** (JSON-only) that can connect to your MCP servers over **stdio**, list available tools, show detailed schemas, and call tools by sending JSON. Next I’ll inspect the installed `fastmcp`/`mcp` client APIs and then implement a `pentest-cli` under `Standalone_Build/` that uses your existing `Standalone_Build/mcp.json` as its server registry.

I’ll implement a new **interactive terminal CLI** under `Standalone_Build/pentest-cli/` that reads `Standalone_Build/mcp.json`, lets you `servers`, `connect <name>`, `tools`, `describe <tool>`, and `call <tool> <json|@file>`. Next I’ll add the package, install it into the shared `Standalone_Build/.venv`, and then we’ll be able to run `pentest-cli` from your terminal.

```plaintext
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "pentest-cli"
version = "0.1.0"
description = "Interactive terminal CLI for calling MCP tools (stdio) using a local mcp.json"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
  "mcp>=1.0.0",
]

[project.scripts]
pentest-cli = "pentest_cli.__main__:main"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]


```

```markdown
# pentest-cli

Interactive terminal CLI for calling MCP tools over **stdio** using a local `mcp.json`.

## Install (shared venv)

From `Standalone_Build/`:

```bash
source .venv/bin/activate
pip install -e ./pentest-cli
```

## Run

```bash
pentest-cli
```

## Commands

- `servers` — list configured servers from `Standalone_Build/mcp.json`
- `connect <server>` — start and connect to a server (stdio)
- `status` — show current connection
- `tools [filter]` — list tools (optional substring filter)
- `describe <tool>` — show the MCP schema for a tool
- `call <tool> <json|@file>` — call a tool with JSON arguments
- `quit` / `exit` — leave the shell


```

```python
__all__ = ["__version__"]

__version__ = "0.1.0"


```

```python
from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass(frozen=True)
class McpServerConfig:
    name: str
    command: str
    args: list[str]
    env: dict[str, str]


def load_mcp_json(path: str) -> dict[str, McpServerConfig]:
    p = Path(path)
    raw = json.loads(p.read_text(encoding="utf-8"))
    servers = raw.get("mcpServers") or {}
    out: dict[str, McpServerConfig] = {}

    if not isinstance(servers, dict):
        return out

    for name, cfg in servers.items():
        if not isinstance(name, str) or not name.strip():
            continue
        if not isinstance(cfg, dict):
            continue

        command = cfg.get("command")
        args = cfg.get("args") or []
        env = cfg.get("env") or {}

        if not isinstance(command, str) or not command.strip():
            continue
        if not isinstance(args, list) or not all(isinstance(a, str) for a in args):
            args = []
        if not isinstance(env, dict):
            env = {}

        # stringify env values defensively
        env2: dict[str, str] = {}
        for k, v in env.items():
            if not isinstance(k, str) or not k.strip():
                continue
            if v is None:
                continue
            env2[k] = str(v)

        out[name] = McpServerConfig(name=name, command=command, args=list(args), env=env2)

    return out


def safe_json_loads(s: str) -> Any:
    return json.loads(s)


```

```python
from __future__ import annotations

import json
import os
import shlex
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show the MCP schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        conn = self._require_conn()
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        conn = self._require_conn()
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        conn = self._require_conn()
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._print("pentest-cli (MCP stdio). Type 'help' for commands.")
        while True:
            try:
                line = (await self._input("pentest> ")).strip()
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            except types.ErrorData as e:
                self._print(_dump(e))
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        return 0


```

```python
from __future__ import annotations

import argparse
from pathlib import Path

import anyio

from .repl import PentestCliRepl


def main() -> None:
    parser = argparse.ArgumentParser(prog="pentest-cli")
    parser.add_argument(
        "--config",
        default=str(Path(__file__).resolve().parents[3] / "mcp.json"),
        help="Path to mcp.json (default: Standalone_Build/mcp.json)",
    )
    args = parser.parse_args()

    repl = PentestCliRepl(config_path=args.config)
    raise SystemExit(anyio.run(repl.run))


if __name__ == "__main__":
    main()


```

Good catch: the CLI install succeeded, but the first run failed because it couldn’t locate `mcp.json` reliably (path handling). Next I’ll (1) make config loading resilient (search from current directory and don’t crash if missing) and (2) rerun a scripted interactive session to confirm `connect`, `tools`, `describe`, and `call` all work.

```python
from __future__ import annotations

import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass(frozen=True)
class McpServerConfig:
    name: str
    command: str
    args: list[str]
    env: dict[str, str]


def load_mcp_json(path: str) -> dict[str, McpServerConfig]:
    p = Path(path)
    if not p.exists():
        return {}
    raw = json.loads(p.read_text(encoding="utf-8"))
    servers = raw.get("mcpServers") or {}
    out: dict[str, McpServerConfig] = {}

    if not isinstance(servers, dict):
        return out

    for name, cfg in servers.items():
        if not isinstance(name, str) or not name.strip():
            continue
        if not isinstance(cfg, dict):
            continue

        command = cfg.get("command")
        args = cfg.get("args") or []
        env = cfg.get("env") or {}

        if not isinstance(command, str) or not command.strip():
            continue
        if not isinstance(args, list) or not all(isinstance(a, str) for a in args):
            args = []
        if not isinstance(env, dict):
            env = {}

        # stringify env values defensively
        env2: dict[str, str] = {}
        for k, v in env.items():
            if not isinstance(k, str) or not k.strip():
                continue
            if v is None:
                continue
            env2[k] = str(v)

        out[name] = McpServerConfig(name=name, command=command, args=list(args), env=env2)

    return out


def find_default_mcp_json(start_dir: str | None = None) -> str:
    """
    Best-effort discovery of a local mcp.json for Standalone_Build use.
    Preference order:
    - $PENTEST_CLI_CONFIG if set
    - ./mcp.json
    - ./Standalone_Build/mcp.json
    - walk up parents looking for Standalone_Build/mcp.json
    """
    env = (os.getenv("PENTEST_CLI_CONFIG", "") or "").strip()
    if env:
        return env

    base = Path(start_dir or Path.cwd())
    c1 = base / "mcp.json"
    if c1.exists():
        return str(c1)
    c2 = base / "Standalone_Build" / "mcp.json"
    if c2.exists():
        return str(c2)

    for parent in [base, *base.parents]:
        cand = parent / "Standalone_Build" / "mcp.json"
        if cand.exists():
            return str(cand)

    # Fall back to ./mcp.json even if missing (caller will handle empty config).
    return str(c1)


def safe_json_loads(s: str) -> Any:
    return json.loads(s)



```

```python
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass(frozen=True)
class McpServerConfig:
    name: str
    command: str
    args: list[str]
    env: dict[str, str]


def load_mcp_json(path: str) -> dict[str, McpServerConfig]:
    p = Path(path)
    if not p.exists():
        return {}
    raw = json.loads(p.read_text(encoding="utf-8"))
    servers = raw.get("mcpServers") or {}
    out: dict[str, McpServerConfig] = {}

    if not isinstance(servers, dict):
        return out

    for name, cfg in servers.items():
        if not isinstance(name, str) or not name.strip():
            continue
        if not isinstance(cfg, dict):
            continue

        command = cfg.get("command")
        args = cfg.get("args") or []
        env = cfg.get("env") or {}

        if not isinstance(command, str) or not command.strip():
            continue
        if not isinstance(args, list) or not all(isinstance(a, str) for a in args):
            args = []
        if not isinstance(env, dict):
            env = {}

        # stringify env values defensively
        env2: dict[str, str] = {}
        for k, v in env.items():
            if not isinstance(k, str) or not k.strip():
                continue
            if v is None:
                continue
            env2[k] = str(v)

        out[name] = McpServerConfig(name=name, command=command, args=list(args), env=env2)

    return out


def find_default_mcp_json(start_dir: str | None = None) -> str:
    """
    Best-effort discovery of a local mcp.json for Standalone_Build use.
    Preference order:
    - $PENTEST_CLI_CONFIG if set
    - ./mcp.json
    - ./Standalone_Build/mcp.json
    - walk up parents looking for Standalone_Build/mcp.json
    """
    env = (os.getenv("PENTEST_CLI_CONFIG", "") or "").strip()
    if env:
        return env

    base = Path(start_dir or Path.cwd())
    c1 = base / "mcp.json"
    if c1.exists():
        return str(c1)
    c2 = base / "Standalone_Build" / "mcp.json"
    if c2.exists():
        return str(c2)

    for parent in [base, *base.parents]:
        cand = parent / "Standalone_Build" / "mcp.json"
        if cand.exists():
            return str(cand)

    # Fall back to ./mcp.json even if missing (caller will handle empty config).
    return str(c1)


def safe_json_loads(s: str) -> Any:
    return json.loads(s)



```

```python
from __future__ import annotations

import argparse
from pathlib import Path

import anyio

from .config import find_default_mcp_json
from .repl import PentestCliRepl


def main() -> None:
    parser = argparse.ArgumentParser(prog="pentest-cli")
    parser.add_argument(
        "--config",
        default=None,
        help="Path to mcp.json (default: auto-discover from current directory; env: PENTEST_CLI_CONFIG)",
    )
    args = parser.parse_args()

    config_path = args.config or find_default_mcp_json(str(Path.cwd()))
    repl = PentestCliRepl(config_path=config_path)
    raise SystemExit(anyio.run(repl.run))


if __name__ == "__main__":
    main()



```

```jsonc
{
  "mcpServers": {
    "pentest": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["pentest_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "pdtm": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["pdtm_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "shodan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["shodan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searchsploit": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["searchsploit_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searx": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["searx_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "theharvester": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["theharvester_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "wpscan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["wpscan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "mongo": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["mongo_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    }
  }
}


```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    *,
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    *,
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    *,
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    *,
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    *,
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

### Done: JSON-only interactive CLI (Claude-Code-like shell, but for MCP tool calls)

You now have a new standalone package at:

- `Standalone_Build/pentest-cli/`

It’s installed into your shared venv and provides an **interactive shell**:

- **Run** (from anywhere):

```bash
/Users/pkincaid/Documents/bin/joesgarage.ai\ -\ AI\ Projects/MCP_Servers/Standalone_Build/.venv/bin/pentest-cli
```

It **auto-discovers** `Standalone_Build/mcp.json` (or you can set `PENTEST_CLI_CONFIG=/path/to/mcp.json`).

### What it can do
- **Help system**: `help`
- **Show servers** (from `Standalone_Build/mcp.json`): `servers`
- **Connect**: `connect pentest` (or `connect shodan`, `connect wpscan`, etc.)
- **List tools**: `tools` or `tools scan` (substring filter)
- **Describe tool schema**: `describe rustscan_scan`
- **Call tool with JSON**: `call rustscan_scan '{"targets":["192.168.1.1"],"ports":"1-1024"}'`
- **Call tool with JSON file**: `call rustscan_scan @args.json`
- **Exit**: `quit` / `exit`

### What I adjusted for usability
- The coordinator tool functions now have **docstrings**, so `tools` shows meaningful descriptions (e.g., `nmap_scan`, `rustscan_scan`, `naabu_scan`, etc.).

### Files involved
- **CLI code**: `Standalone_Build/pentest-cli/src/pentest_cli/…`
- **Server registry**: `Standalone_Build/mcp.json`
- **Shared env loader** (used by servers): `Standalone_Build/run-mcp-stdio.sh` which sources `Standalone_Build/.env`

```shellscript
/Users/pkincaid/Documents/bin/joesgarage.ai\ -\ AI\ Projects/MCP_Servers/Standalone_Build/.venv/bin/pentest-cli
```

---

**User**

When attempting to run the "tools" function in the pentest-cli - I receive the following error:

pentest> tools
Traceback (most recent call last):
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pentest-cli/src/pentest_cli/repl.py", line 230, in run
    await self.cmd_tools(args[0] if args else None)
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pentest-cli/src/pentest_cli/repl.py", line 161, in cmd_tools
    conn = self._require_conn()
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pentest-cli/src/pentest_cli/repl.py", line 85, in _require_conn
    raise RuntimeError("not connected (use: connect <server>)")
RuntimeError: not connected (use: connect <server>)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/bin/pentest-cli", line 9, in <module>
    sys.exit(main())
             ^^^^^^
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pentest-cli/src/pentest_cli/__main__.py", line 23, in main
    raise SystemExit(anyio.run(repl.run))
                     ^^^^^^^^^^^^^^^^^^^
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/lib/python3.11/site-packages/anyio/_core/_eventloop.py", line 75, in run
    return async_backend.run(func, args, {}, backend_options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 2365, in run
    return runner.run(wrapper())
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pkincaid/anaconda3/lib/python3.11/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pkincaid/anaconda3/lib/python3.11/asyncio/base_events.py", line 654, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py", line 2348, in wrapper
    return await func(*args)
           ^^^^^^^^^^^^^^^^^
  File "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/pentest-cli/src/pentest_cli/repl.py", line 239, in run
    except types.ErrorData as e:
TypeError: catching classes that do not inherit from BaseException is not allowed

---

**Cursor**

You hit two issues:

1) `tools` **requires an active connection** (so you must `connect <server>` first). That part is expected.

2) The CLI **should not crash** when you forget — it’s crashing because `types.ErrorData` is **not an Exception**, so Python throws `TypeError` on the `except types.ErrorData` clause.

I’ll fix `pentest-cli` so it cleanly prints the “not connected” message and keeps the REPL running.



---

**User**

Yes, please fix the CLI to prevent crashing when an error is recieved, please provide a clear explaination of why there was an error - like what you mentioned about needing to "connect" to a server first before running "tools". Also, is it possible to have the pentest-cli load all of the servers at start time?

---

**Cursor**

Plan: I’ll fix the REPL exception handling so it never tries to `except` non-exception types (the current crash), and I’ll make `tools/describe/call` print a friendly “not connected—run connect <server>” message instead of raising. Then I’ll add an optional startup auto-connect (default `pentest`) so you can start the CLI and immediately run `tools`.

```python
from __future__ import annotations

import json
import os
import shlex
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show the MCP schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._print("pentest-cli (MCP stdio). Type 'help' for commands.")
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                line = (await self._input("pentest> ")).strip()
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        return 0



```

```python
from __future__ import annotations

import argparse
from pathlib import Path

import anyio

from .config import find_default_mcp_json
from .repl import PentestCliRepl


def main() -> None:
    parser = argparse.ArgumentParser(prog="pentest-cli")
    parser.add_argument(
        "--config",
        default=None,
        help="Path to mcp.json (default: auto-discover from current directory; env: PENTEST_CLI_CONFIG)",
    )
    parser.add_argument(
        "--connect",
        default="pentest",
        help="Server name to auto-connect on startup (use empty string to disable)",
    )
    args = parser.parse_args()

    config_path = args.config or find_default_mcp_json(str(Path.cwd()))
    repl = PentestCliRepl(config_path=config_path, auto_connect=args.connect)
    raise SystemExit(anyio.run(repl.run))


if __name__ == "__main__":
    main()



```

### Fixed: `pentest-cli` no longer crashes on `tools` when not connected

#### Why it crashed
- `tools` requires an active MCP session, so calling it before `connect <server>` raised `RuntimeError: not connected …` (expected).
- Then the REPL tried to do `except types.ErrorData as e:` — but `mcp.types.ErrorData` is a **data model**, not a Python exception, so Python raised:
  - **`TypeError: catching classes that do not inherit from BaseException is not allowed`**
  - which killed the CLI.

#### What I changed
- **Removed the invalid exception handler** (`except types.ErrorData`).
- Made `tools`, `describe`, and `call` **handle “not connected” gracefully** and print a clear message instead of raising.
- Added **auto-connect on startup** (default: `pentest`) so you can run `tools` immediately in most cases.

### New behavior
- If you run `tools` without being connected, you’ll see:

`Not connected. Run: connect <server>  (try: servers)`

…and the REPL keeps running.

### Auto-load / auto-connect at startup
- The CLI now auto-connects to **`pentest`** at start time.
- You can change/disable that with:

```bash
pentest-cli --connect shodan
pentest-cli --connect ""
```

### Files changed
- `Standalone_Build/pentest-cli/src/pentest_cli/repl.py`
- `Standalone_Build/pentest-cli/src/pentest_cli/__main__.py`

```shellscript
pentest-cli --connect shodan
pentest-cli --connect ""
```

---

**User**

When running "describe <tool>" can you instead of just showing the JSON for the description, can you instead make the output of the describe <tool> be more of the common way of showing what the tool does and the basics on how to "call" that tool - such as the options, input/output, etc

---

**Cursor**

Makes sense — I’ll keep the raw JSON available (so nothing is lost), but update `describe <tool>` to render a human-friendly “manpage-style” view: purpose/description, required vs optional inputs (types + defaults), output schema summary, and an example `call <tool> ...` snippet you can paste. Next I’ll implement that formatter and run a quick CLI smoke-test.

```python
from __future__ import annotations

import json
import os
import shlex
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(f"Tool: {name}")
    if desc:
        lines.append("")
        lines.append("What it does:")
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append("Inputs:")
    if not props:
        lines.append("  (none)")
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            is_req = k in required
            default = s.get("default") if isinstance(s, dict) else None
            suffix_parts: list[str] = []
            suffix_parts.append("required" if is_req else "optional")
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {k}: {t} ({suffix})")

    # Output
    lines.append("")
    lines.append("Output:")
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_schema_type(output_schema)}")
    else:
        lines.append("  schema_type: unknown")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        if k in required:
            # Put simple placeholders for required fields
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif _schema_type(props[k]) in {"integer", "number"}:
                example_obj[k] = 0
            elif _schema_type(props[k]).startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append("How to call:")
    lines.append(f"  call {name} {json.dumps(example_obj)}")
    lines.append("")
    lines.append("Raw schema (if you need it):")
    lines.append(f"  describe-json {name}")
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show the MCP schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._print("pentest-cli (MCP stdio). Type 'help' for commands.")
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                line = (await self._input("pentest> ")).strip()
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        return 0



```

```python
from __future__ import annotations

import json
import os
import shlex
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(f"Tool: {name}")
    if desc:
        lines.append("")
        lines.append("What it does:")
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append("Inputs:")
    if not props:
        lines.append("  (none)")
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            is_req = k in required
            default = s.get("default") if isinstance(s, dict) else None
            suffix_parts: list[str] = []
            suffix_parts.append("required" if is_req else "optional")
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {k}: {t} ({suffix})")

    # Output
    lines.append("")
    lines.append("Output:")
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_schema_type(output_schema)}")
    else:
        lines.append("  schema_type: unknown")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        if k in required:
            # Put simple placeholders for required fields
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif _schema_type(props[k]) in {"integer", "number"}:
                example_obj[k] = 0
            elif _schema_type(props[k]).startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append("How to call:")
    lines.append(f"  call {name} {json.dumps(example_obj)}")
    lines.append("")
    lines.append("Raw schema (if you need it):")
    lines.append(f"  describe-json {name}")
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._print("pentest-cli (MCP stdio). Type 'help' for commands.")
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                line = (await self._input("pentest> ")).strip()
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        return 0



```

```python
from __future__ import annotations

import json
import os
import shlex
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(f"Tool: {name}")
    if desc:
        lines.append("")
        lines.append("What it does:")
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append("Inputs:")
    if not props:
        lines.append("  (none)")
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            is_req = k in required
            default = s.get("default") if isinstance(s, dict) else None
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append("required")
                if nullable:
                    suffix_parts.append("nullable")
            else:
                suffix_parts.append("optional")
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {k}: {t} ({suffix})")

    # Output
    lines.append("")
    lines.append("Output:")
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_schema_type(output_schema)}")
    else:
        lines.append("  schema_type: unknown")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        if k in required:
            # Put simple placeholders for required fields
            schema = props.get(k)
            t = _schema_type(schema)
            nullable = "null" in {p.strip() for p in t.split("|")}
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                example_obj[k] = 0
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append("How to call:")
    lines.append(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}")
    lines.append("")
    lines.append("Notes:")
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append("Raw schema (if you need it):")
    lines.append(f"  describe-json {name}")
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._print("pentest-cli (MCP stdio). Type 'help' for commands.")
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                line = (await self._input("pentest> ")).strip()
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        return 0



```

Updated `describe <tool>` to print a **human-friendly “how to use it”** view instead of dumping raw JSON.

### What you’ll see now
- **Tool name + what it does** (from the tool’s docstring/description)
- **Inputs** with:
  - type (from JSON Schema)
  - required vs optional
  - **nullable** when `null` is allowed
- **Output** schema type (summary)
- A **copy/paste `call <tool> {...}` example**, using **`null` for nullable fields** (so you don’t have to guess)
- A note explaining why some fields show as “required” even though they allow null
- Raw schema is still available via: **`describe-json <tool>`**

### Commands
- `describe rustscan_scan`
- `describe-json rustscan_scan`

If you want, I can also make the example JSON include more realistic defaults (e.g., `timeout_seconds: 300`) per tool.

---

**User**

Can you please implement 3 changes:
1. Make use of a "history" type of function where the user can use the up/down arrows to load previous commands
2. Make the "describe <tool>" pages a bit more colorful - it is challenging to see the output for the "describe" command with it being all white text
3. Make the pentest-cli looks kind of like Claude-Code where the current active line sticks out a bit more like the following:



---

**Cursor**

Plan: I’ll add readline-backed input (persistent history with ↑/↓), then layer in lightweight ANSI styling for the prompt and `describe` output (headings + required/optional highlights). After that I’ll reinstall `pentest-cli` into the shared venv and do a quick interactive smoke-test.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            is_req = k in required
            default = s.get("default") if isinstance(s, dict) else None
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        if k in required:
            # Put simple placeholders for required fields
            schema = props.get(k)
            t = _schema_type(schema)
            nullable = "null" in {p.strip() for p in t.split("|")}
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                example_obj[k] = 0
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                active = self.conn.name if self.conn else ""
                # Claude-Code-like: make the prompt stand out with inverse on the ">",
                # and show active server in cyan when connected.
                prompt = f"{_inverse('>')} "
                if active:
                    prompt = f"{_inverse('>')} {_cyan(active)} "
                line = (await self._input(prompt)).strip()
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

Implemented all 3 changes in `pentest-cli`.

### 1) Command history (↑ / ↓)
- Added **readline-backed history** so you can use **up/down arrows** to recall prior commands.
- History is persisted to: **`~/.pentest_cli_history`**
  - Override via env: `PENTEST_CLI_HISTORY=/path/to/file`

### 2) More colorful `describe <tool>`
- `describe` now uses **ANSI color** (when running in a real TTY):
  - Headings are colored/bold
  - Required/optional/nullable fields are highlighted
  - Example `call ...` line is highlighted
- Disable colors with `NO_COLOR=1` if you prefer plain output.

### 3) Prompt looks more like Claude Code / active line stands out
- The prompt now uses **inverse video** on the `>` and shows the **active server** in color, e.g.:
  - `> pentest …`
- It’s intentionally subtle but makes the current input line pop.

### How to verify (interactive)
Run it in a real terminal (not piped):

```bash
cd "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build"
./.venv/bin/pentest-cli
```

Then press ↑ after a few commands, and run `describe rustscan_scan` to see the colored formatting.

```shellscript
cd "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build"
./.venv/bin/pentest-cli
```

---

**User**

The cli is not loading any servers on the start of the cli:

Auto-connect skipped: unknown server 'pentest' (try: servers)

---

**Cursor**

I’ll first confirm whether `Standalone_Build/mcp.json` exists right now, then I’ll fix `pentest-cli` so it reliably finds that config even when you launch the CLI from *any* directory (and it will print which config file it loaded + how many servers).

You’re launching `pentest-cli` from a directory where auto-discovery isn’t finding `Standalone_Build/mcp.json`, so it loads **0 servers** and then auto-connect says “unknown server ‘pentest’”. Next I’ll make discovery also search relative to the installed `pentest-cli` package location (so it works from anywhere) and print `Config: <path> (loaded N servers)` at startup for clarity.

```python
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass(frozen=True)
class McpServerConfig:
    name: str
    command: str
    args: list[str]
    env: dict[str, str]


def load_mcp_json(path: str) -> dict[str, McpServerConfig]:
    p = Path(path)
    if not p.exists():
        return {}
    raw = json.loads(p.read_text(encoding="utf-8"))
    servers = raw.get("mcpServers") or {}
    out: dict[str, McpServerConfig] = {}

    if not isinstance(servers, dict):
        return out

    for name, cfg in servers.items():
        if not isinstance(name, str) or not name.strip():
            continue
        if not isinstance(cfg, dict):
            continue

        command = cfg.get("command")
        args = cfg.get("args") or []
        env = cfg.get("env") or {}

        if not isinstance(command, str) or not command.strip():
            continue
        if not isinstance(args, list) or not all(isinstance(a, str) for a in args):
            args = []
        if not isinstance(env, dict):
            env = {}

        # stringify env values defensively
        env2: dict[str, str] = {}
        for k, v in env.items():
            if not isinstance(k, str) or not k.strip():
                continue
            if v is None:
                continue
            env2[k] = str(v)

        out[name] = McpServerConfig(name=name, command=command, args=list(args), env=env2)

    return out


def find_default_mcp_json(start_dir: str | None = None) -> str:
    """
    Best-effort discovery of a local mcp.json for Standalone_Build use.
    Preference order:
    - $PENTEST_CLI_CONFIG if set
    - ./mcp.json
    - ./Standalone_Build/mcp.json
    - walk up parents looking for Standalone_Build/mcp.json
    """
    env = (os.getenv("PENTEST_CLI_CONFIG", "") or "").strip()
    if env:
        return env

    base = Path(start_dir or Path.cwd())
    c1 = base / "mcp.json"
    if c1.exists():
        return str(c1)
    c2 = base / "Standalone_Build" / "mcp.json"
    if c2.exists():
        return str(c2)

    for parent in [base, *base.parents]:
        cand = parent / "Standalone_Build" / "mcp.json"
        if cand.exists():
            return str(cand)

    # Also try relative to this installed package location (works even when
    # invoking the CLI from arbitrary directories).
    try:
        here = Path(__file__).resolve()
        for parent in [here, *here.parents]:
            # If we're inside Standalone_Build already
            if parent.name == "Standalone_Build":
                cand2 = parent / "mcp.json"
                if cand2.exists():
                    return str(cand2)
            # Or look for a sibling Standalone_Build
            cand3 = parent / "Standalone_Build" / "mcp.json"
            if cand3.exists():
                return str(cand3)
    except Exception:
        pass

    # Fall back to ./mcp.json even if missing (caller will handle empty config).
    return str(c1)


def safe_json_loads(s: str) -> Any:
    return json.loads(s)



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            is_req = k in required
            default = s.get("default") if isinstance(s, dict) else None
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        if k in required:
            # Put simple placeholders for required fields
            schema = props.get(k)
            t = _schema_type(schema)
            nullable = "null" in {p.strip() for p in t.split("|")}
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                example_obj[k] = 0
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                active = self.conn.name if self.conn else ""
                # Claude-Code-like: make the prompt stand out with inverse on the ">",
                # and show active server in cyan when connected.
                prompt = f"{_inverse('>')} "
                if active:
                    prompt = f"{_inverse('>')} {_cyan(active)} "
                line = (await self._input(prompt)).strip()
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

Fixed.

### Why you saw `Auto-connect skipped: unknown server 'pentest'`
That happens when `pentest-cli` **doesn’t load any servers** (usually because it didn’t find the right `mcp.json`), so `"pentest"` isn’t in the loaded server list.

### What I changed
- **Config discovery now works from any directory**: it will also search relative to the installed `pentest-cli` package location (so it can always find `Standalone_Build/mcp.json`).
- On startup it now prints:

- `Config: <path> (loaded N servers)`

…so you can immediately see which config file it used and whether servers were loaded.

### Verified
I reinstalled the CLI and ran it from `$HOME` (outside the repo) and it successfully found:

- `…/Standalone_Build/mcp.json` and loaded **8 servers**
- then auto-connected to `pentest`

If you still ever want to force it, you can also do:

- `pentest-cli --config "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json"`
- or `export PENTEST_CLI_CONFIG=...`

---

**User**

I am not crazy about the prompt, could you please change it to have a solid line (50% opacity) above and below the prompt and just have the prompt text be "pentest> "

---

**Cursor**

Got it — terminals can’t do real “50% opacity”, but we can get the same effect using **dim ANSI** lines. Next I’ll update the REPL so each prompt is framed by a dim horizontal rule above and below, and the prompt text is exactly `pentest> ` as requested.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            is_req = k in required
            default = s.get("default") if isinstance(s, dict) else None
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        if k in required:
            # Put simple placeholders for required fields
            schema = props.get(k)
            t = _schema_type(schema)
            nullable = "null" in {p.strip() for p in t.split("|")}
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                example_obj[k] = 0
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

Updated the prompt behavior.

### What changed
- The REPL prompt is now exactly: **`pentest> `**
- Each prompt is framed by a **dim horizontal rule above and below** (closest practical equivalent to “50% opacity” in terminals).

### Where
- `Standalone_Build/pentest-cli/src/pentest_cli/repl.py`

### Try it
From:

`/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build`

Run:

```bash
./.venv/bin/pentest-cli
```

If you want the line length fixed (e.g., always 80 chars) instead of auto terminal width, tell me and I’ll tweak it.

```shellscript
./.venv/bin/pentest-cli
```

---

**User**

Received the following error when running: 

pentest> call naabu_scan {"exclude_ports":null,"extra_args":null,"json_output":"","ports":"1-1024","rate":0,"save":null,"targets":["192.168.1.1"],"timeout_seconds":null,"top_ports":null}
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Error: JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)

---

**Cursor**

Good catch — this is happening because the REPL uses `shlex.split()`, which **strips the double-quotes inside your JSON**, turning valid JSON into `{exclude_ports:null,...}` (invalid). Next I’ll change `call` parsing to treat everything after the tool name as a raw JSON blob (no quote stripping), add a clearer error message, and re-test with your exact input.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            is_req = k in required
            default = s.get("default") if isinstance(s, dict) else None
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        if k in required:
            # Put simple placeholders for required fields
            schema = props.get(k)
            t = _schema_type(schema)
            nullable = "null" in {p.strip() for p in t.split("|")}
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                example_obj[k] = 0
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

Fixed: `call <tool> {...}` no longer crashes with `JSONDecodeError`.

### Why you got `JSONDecodeError`
Your JSON was valid, but the REPL used `shlex.split()` which **strips the quotes inside JSON**, turning:

`{"exclude_ports":null,...}`

into something like:

`{exclude_ports:null,...}`  ← **invalid JSON**, hence the decode error.

### What I changed
- `call` is now parsed from the **raw input line** (everything after the tool name is treated as the JSON blob / `@file`), so quotes inside JSON are preserved.

### What you’ll see next (your example input)
After this fix, your command now reaches the MCP server, and you’ll get a *real* validation/tool error instead of a JSON parse error. In your example you passed:

- `json_output: ""` (string) — but the tool expects a **boolean**.

So the correct form would be:

```text
pentest> call naabu_scan {"targets":["192.168.1.1"],"ports":"1-1024","json_output":true,"rate":1000}
```

(Also note: your machine currently doesn’t have `naabu` installed, so once the args are valid you may get a “naabu not found in PATH” error until it’s installed.)

```plaintext
pentest> call naabu_scan {"targets":["192.168.1.1"],"ports":"1-1024","json_output":true,"rate":1000}
```

---

**User**

I copied the example directly from the "describe naabu_scan" and received the following:

2025-12-27 22:28:39,682 INFO mcp.server.lowlevel.server Processing request of type CallToolRequest
[12/27/25 22:28:39] Error validating tool 'naabu_scan': 1 validation error for call[naabu_scan]
                    json_output
                      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='', input_type=str]
                        For further information visit https://errors.pydantic.dev/2.12/v/bool_parsing
                    ╭────────────────────────────────────── Traceback (most recent call last) ───────────────────────────────────────╮
                    │ /Users/pkincaid/Documents/bin/joesgarage.ai - AI                                                               │
                    │ Projects/MCP_Servers/Standalone_Build/.venv/lib/python3.11/site-packages/fastmcp/tools/tool_manager.py:160 in  │
                    │ call_tool                                                                                                      │
                    │                                                                                                                │
                    │ /Users/pkincaid/Documents/bin/joesgarage.ai - AI                                                               │
                    │ Projects/MCP_Servers/Standalone_Build/.venv/lib/python3.11/site-packages/fastmcp/tools/tool.py:381 in run      │
                    │                                                                                                                │
                    │ /Users/pkincaid/Documents/bin/joesgarage.ai - AI                                                               │
                    │ Projects/MCP_Servers/Standalone_Build/.venv/lib/python3.11/site-packages/pydantic/type_adapter.py:441 in       │
                    │ validate_python                                                                                                │
                    ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯
                    ValidationError: 1 validation error for call[naabu_scan]
                    json_output
                      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='', input_type=str]
                        For further information visit https://errors.pydantic.dev/2.12/v/bool_parsing
{
  "meta": null,
  "content": [
    {
      "type": "text",
      "text": "1 validation error for call[naabu_scan]\njson_output\n  Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/bool_parsing",
      "annotations": null,
      "meta": null
    }
  ],
  "structuredContent": null,
  "isError": true
}

---

**Cursor**

Yep — that’s on us: the `describe` generator currently guesses placeholders poorly for some parameter types, so it produced `json_output:""` (string) instead of a boolean. I’ll fix the `describe` renderer to use **schema defaults when present**, and otherwise generate type-correct examples (booleans become `true/false`, ints become numbers, nullable fields become `null`). Then I’ll re-test `describe naabu_scan` + a copy/paste `call` using the generated example.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

Fixed the `describe` example generator so it won’t produce invalid types like `json_output:""` anymore.

### What changed
In `Standalone_Build/pentest-cli/src/pentest_cli/repl.py`:

- **Example JSON generation is now type-aware**:
  - booleans → `true`
  - nullable fields → `null`
  - integers → `1` (instead of `0`)
  - common scanner fields like `ports` → `"1-1024"`
- **Input listing is more accurate**:
  - If a schema property has a `default`, we treat it as **optional-with-default** (FastMCP sometimes still marks it “required” in the schema).

### Your specific failure
`naabu_scan.json_output` is a **boolean**, so the old example `""` caused:

- `Input should be a valid boolean`

Now `describe naabu_scan` generates:

- `json_output: true`

### Copy/paste example (now valid)
From the updated `describe naabu_scan`:

```text
call naabu_scan {"exclude_ports":null,"extra_args":null,"json_output":true,"ports":"1-1024","rate":1,"save":null,"targets":["192.168.1.1"],"timeout_seconds":null,"top_ports":null}
```

One more note: you’ll still need `naabu` installed on your host for this tool to actually run (earlier we saw it was missing).

```plaintext
call naabu_scan {"exclude_ports":null,"extra_args":null,"json_output":true,"ports":"1-1024","rate":1,"save":null,"targets":["192.168.1.1"],"timeout_seconds":null,"top_ports":null}
```

---

**User**

Now getting the error:

2025-12-27 22:34:43,985 INFO mcp.server.lowlevel.server Processing request of type CallToolRequest
2025-12-27 22:34:43,994 INFO mcp.server.lowlevel.server Processing request of type ListToolsRequest
{
  "meta": null,
  "content": [
    {
      "type": "text",
      "text": "{\"ok\":false,\"error\":\"naabu not found in PATH\",\"details\":null}",
      "annotations": null,
      "meta": null
    }
  ],
  "structuredContent": {
    "ok": false,
    "error": "naabu not found in PATH",
    "details": null
  },
  "isError": false
}

---

**Cursor**

You’re past JSON/validation now — this error means the MCP tool ran, but it couldn’t find the **`naabu` binary on your host PATH**. Next I’ll (1) improve `pentest-cli` output so it surfaces these tool-level failures as clear “ERROR: …” messages with install hints, and (2) give you the exact macOS install commands / `NAABU_BIN` workaround to fix the root cause.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f\"{missing.upper()}_BIN\" if missing else \"<TOOL>_BIN\"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                self._print(f\"  - Install {missing} so it's available on PATH\") 
                self._print(f\"  - Or set {env_var} in Standalone_Build/.env to the full executable path\")
            return
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

That error is now the *real* underlying problem: **`naabu` isn’t installed (or isn’t on PATH)**, so the MCP tool can’t execute it.

### What it means
- The coordinator ran the tool wrapper correctly.
- The wrapper tried to locate `naabu` via `PATH` and failed, so it returned:

- `ok=false`
- `error="naabu not found in PATH"`

### Better CLI output (implemented)
I updated `pentest-cli` so these `ok=false` tool results are shown as a clear error with a fix hint (instead of dumping the raw JSON blob).

### How to fix it (macOS)
Pick one:

- **Install via Homebrew** (recommended if available):

```bash
brew install naabu
```

- **Or install via Go** (if you have Go installed):

```bash
go install github.com/projectdiscovery/naabu/v2/cmd/naabu@latest
```

Then ensure Go bin is on your PATH (often `~/go/bin`).

- **Or set an explicit path** (works even if PATH is messy)
Edit `Standalone_Build/.env` and set:

- `NAABU_BIN="/full/path/to/naabu"`

Then restart `pentest-cli` so it reloads `.env`.

If you run this and it still can’t find `naabu`, paste the output of:

```bash
command -v naabu
echo "$PATH"
```

```shellscript
brew install naabu
```

```shellscript
go install github.com/projectdiscovery/naabu/v2/cmd/naabu@latest
```

```shellscript
command -v naabu
echo "$PATH"
```

---

**User**

For any of the items that default to "null" in the JSON calling the tools like naabu - can you please make those optional flags and have them set to null by default when running the scans - and change them if the user adds the flags to the input, then change them in the request.

---

**Cursor**

Plan: I’ll first test whether the MCP server truly requires those “nullable” fields or if that’s just a schema/describe artifact. Then I’ll implement the behavior you want by making the CLI omit any keys that are `null` (and optionally any keys equal to a tool’s default) before sending the request, so “null means not provided”. If the server actually enforces requiredness, I’ll adjust the coordinator tool signatures/schema to make those fields optional at the MCP layer too.

Nice find: this isn’t just “null vs optional” in the CLI — FastMCP is currently treating **keyword-only parameters** as required at validation time (hence “Missing required keyword only argument”). Next I’ll fix this at the source by updating the **standalone `pentest-mcp-server` tool function signatures** to remove the `*` (so defaults actually work and nullable fields become truly optional), then I’ll rerun `call naabu_scan {"targets":[... ]}` to confirm it validates.

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

Done — and the behavior is now exactly what you asked for.

### What was happening
FastMCP was enforcing **keyword-only args** as required (even when they had defaults), so you were forced to pass lots of `null` keys. That made “optional flags” impossible.

### What I changed (in the standalone coordinator)
In `Standalone_Build/pentest-mcp-server/src/pentest_mcp_server/server.py` I removed the `*` keyword-only marker from the coordinator tools:

- `naabu_scan`, `naabu_scan_raw`
- `nmap_scan`, `nmap_scan_raw`
- `rustscan_scan`, `rustscan_scan_raw`
- `portscan_all`

This allows FastMCP/Pydantic to correctly apply Python defaults, so fields that used to be “null placeholders” are now **truly optional**.

### Verified
I ran:

```text
call naabu_scan {"targets":["192.168.1.1"]}
```

…and it **validated and executed successfully** using defaults (rate=1000, json_output=true, etc.), without requiring any of the nullable keys. The tool returned open ports on your router.

### What this means for you
- You can now omit any optional params entirely.
- If you include a param, it will override the default for that run.
- `describe <tool>` can now show a much cleaner “How to call” example (we can tighten that next if you want).

If you want the same “optional null fields” behavior for the *other* standalone MCP servers (pdtm/shodan/wpscan/etc.), I can apply the same signature fix there too.

```plaintext
call naabu_scan {"targets":["192.168.1.1"]}
```

---

**User**

Can you default to printing the output from the mcp tools from what is seen in stdout vs. JSON by default?

---

**Cursor**

Makes sense — right now `call` prints the full MCP response object (JSON-ish). I’ll change `call` so the default view is **tool stdout/stderr** (what you’d expect in a terminal), and I’ll add a `call-json` command to show the full structured MCP response when you need debugging/meta.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call-json <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any


class PentestCliRepl:
    def __init__(self, *, config_path: str, auto_connect: str | None = None):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  call-json <tool> <json|@file>     Call a tool and print the full MCP JSON response",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close)
        self._print(f"Connected to {name}.")

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call-json <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

Implemented.

### New default behavior
- **`call <tool> {...}` now prints tool `stdout` (and `stderr` if present)**, like a normal terminal command.
- If a tool doesn’t return `stdout/stderr`, it falls back to printing the full MCP response.

### New command for debugging
- **`call-json <tool> <json|@file>`** prints the full MCP response (structured content, meta, commandline, etc.).

### Example
- Default (stdout):

```text
pentest> call nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-100","-sT"],"force_unprivileged":true}
```

- Full JSON:

```text
pentest> call-json nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-10","-sT"],"force_unprivileged":true}
```

If you’d like, I can also add a toggle like `set output json|stdout` so you can switch defaults without using a separate command.

```plaintext
pentest> call nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-100","-sT"],"force_unprivileged":true}
```

```plaintext
pentest> call-json nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-10","-sT"],"force_unprivileged":true}
```

---

**User**

Are the scan outputs being saved to MongoDB by default?

---

**Cursor**

No — **not by default**.

Across these MCP servers, results are only saved to MongoDB when you explicitly pass a `save` object with `type: "mongo"` (or otherwise choose mongo saving). For example:

```text
pentest> call-json nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-100","-sT"],"save":{"type":"mongo"}}
```

And you also need `MONGO_URI` set (in `Standalone_Build/.env`) for the save to succeed.

If you want, I can add a CLI setting (or `.env` flag) to make `save={"type":"mongo"}` the default for all `call` invocations.

```plaintext
pentest> call-json nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-100","-sT"],"save":{"type":"mongo"}}
```

---

**User**

Yes, please make saving the JSON rendering of the output to the MongoDB by default.

---

**Cursor**

I’ll make `pentest-cli` automatically inject `save={"type":"mongo"}` for any tool that supports a `save` parameter, unless you explicitly provide your own `save`. Then I’ll add a small “saved to Mongo?” status line after stdout so you can confirm persistence without switching to `call-json`.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  call-json <tool> <json|@file>     Call a tool and print the full MCP JSON response",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call-json <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

```python
from __future__ import annotations

import argparse
from pathlib import Path

import anyio

from .config import find_default_mcp_json
from .repl import PentestCliRepl


def main() -> None:
    parser = argparse.ArgumentParser(prog="pentest-cli")
    parser.add_argument(
        "--config",
        default=None,
        help="Path to mcp.json (default: auto-discover from current directory; env: PENTEST_CLI_CONFIG)",
    )
    parser.add_argument(
        "--connect",
        default="pentest",
        help="Server name to auto-connect on startup (use empty string to disable)",
    )
    parser.add_argument(
        "--no-save-mongo",
        action="store_true",
        help="Disable default save={\"type\":\"mongo\"} injection for tools that support saving",
    )
    args = parser.parse_args()

    config_path = args.config or find_default_mcp_json(str(Path.cwd()))
    repl = PentestCliRepl(
        config_path=config_path,
        auto_connect=args.connect,
        default_save_mongo=(not args.no_save_mongo),
    )
    raise SystemExit(anyio.run(repl.run))


if __name__ == "__main__":
    main()



```

Done — `pentest-cli` now **saves to MongoDB by default** for any tool that supports a `save` parameter.

### What changed
- On every `call` / `call-json`, the CLI checks whether the tool’s input schema includes a `save` field.
- If it does, and you didn’t provide a non-null `save`, the CLI injects:

```json
{"save":{"type":"mongo"}}
```

So you can run simple calls like:

```text
pentest> call nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-10","-sT"]}
```

…and it will attempt to persist to Mongo automatically.

### Confirmation output
After printing `stdout`, the CLI prints a one-line status like:
- `saved: mongo (db.collection) id=<...>` on success
- `saved: failed (<error>)` on failure

Your last run showed **connection refused**, which means MongoDB isn’t running/reachable at the configured `MONGO_URI`.

### How to disable (if needed)
Run:

```bash
pentest-cli --no-save-mongo
```

### Next step (to make saves succeed)
Ensure `Standalone_Build/.env` has a valid `MONGO_URI` and MongoDB is running. For example:

- `MONGO_URI="mongodb://localhost:27017"` (and run Mongo locally), or
- point it at your Podman Mongo instance if you’re running one.

If you tell me where you want Mongo to run (local vs Podman), I’ll give you the exact `MONGO_URI` + start command.

```json
{"save":{"type":"mongo"}}
```

```plaintext
pentest> call nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-10","-sT"]}
```

```shellscript
pentest-cli --no-save-mongo
```

---

**User**

Can you have the default scans be both stdout/stderr and JSON, but only print the stdout/stderr to the screen and save the JSON to the MongoDB - but make sure you are only running the scan once, but outputting to stderr/stdout and JSON

---

**Cursor**

Got it. Right now we **run each scan once** and print stdout/stderr, and we *attempt* to save `{stdout, stderr}` to Mongo. I’ll upgrade the coordinator so the Mongo document contains a richer **JSON rendering** (stdout/stderr + parsed summary + scan metadata/command), while still only printing stdout/stderr to the terminal.

```python
*** Begin Patch
*** Update File: Standalone_Build/pentest-mcp-server/src/pentest_mcp_server/server.py
@@
 from __future__ import annotations
 
 import inspect
 import json
 import os
 import re
 from typing import Any
 
 from fastmcp import FastMCP
 
 from .logging_utils import configure_logging, get_logger, security_event
 from .mongo_store import save_to_mongo_result
 from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
 from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
 from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets
 
 
 configure_logging()
 logger = get_logger(__name__)
 
 mcp = FastMCP(name="pentest-suite")
 
 _TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
 _TOOL_REGISTRY: dict[str, dict[str, Any]] = {}
 
+_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
+_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")
+
+
+def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
+    """
+    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
+    """
+    items: list[dict[str, Any]] = []
+    total = 0
+    for line in (stdout or "").splitlines():
+        s = line.strip()
+        if not s:
+            continue
+        total += 1
+        if len(items) >= max_items:
+            continue
+        try:
+            obj = json.loads(s)
+            if isinstance(obj, dict):
+                items.append(obj)
+        except Exception:
+            continue
+    return {"parsed_count": total, "sample": items, "sample_limit": max_items}
+
+
+def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
+    """
+    Very small parser for Nmap's human output table (best-effort).
+    """
+    ports: list[dict[str, Any]] = []
+    for line in (stdout or "").splitlines():
+        m = _NMAP_PORT_LINE_RE.match(line.strip())
+        if not m:
+            continue
+        try:
+            p = int(m.group("port"))
+        except Exception:
+            continue
+        ports.append(
+            {
+                "port": p,
+                "proto": m.group("proto"),
+                "state": m.group("state"),
+                "service": m.group("service"),
+            }
+        )
+    return ports
+
+
+def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
+    """
+    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
+    """
+    out: list[dict[str, Any]] = []
+    total = 0
+    for line in (stdout or "").splitlines():
+        m = _RUSTSCAN_OPEN_RE.match(line.strip())
+        if not m:
+            continue
+        total += 1
+        if len(out) >= max_items:
+            continue
+        try:
+            port = int(m.group("port"))
+        except Exception:
+            continue
+        out.append({"host": m.group("host"), "port": port})
+    return {"parsed_count": total, "sample": out, "sample_limit": max_items}
+
@@
 def naabu_scan(
     targets: list[str],
     ports: str | None = None,
     top_ports: int | None = None,
     rate: int = 1000,
@@
 ) -> dict[str, Any]:
     """Run Naabu against targets with common structured options (safe wrapper)."""
@@
     try:
         rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
     except BinaryNotFoundError as e:
         return _tool_error(str(e))
 
     notes: list[str] = []
     meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
+    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
+    jsonl = _parse_jsonl(rr.stdout)
+    if jsonl.get("sample"):
+        payload["jsonl"] = jsonl
 
     if save and (save.get("type") or "").strip().lower() == "mongo":
         try:
             saved = save_to_mongo_result(
                 tool_name="naabu",
                 tool_commandline=rr.command,
                 scan_target=",".join(ok_targets),
-                data={"stdout": rr.stdout, "stderr": rr.stderr},
+                data={"result": payload, "meta": meta},
             )
             meta["saved"] = saved
         except Exception as e:
             meta["saved"] = {"saved": False, "error": str(e)}
 
     return _tool_ok(
-        {"stdout": rr.stdout, "stderr": rr.stderr},
+        payload,
         meta=meta,
     )
@@
 def naabu_scan_raw(
     targets: list[str],
     args: list[str],
@@
 ) -> dict[str, Any]:
     """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
@@
     try:
         rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
     except BinaryNotFoundError as e:
         return _tool_error(str(e))
 
     notes: list[str] = []
     meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
+    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
+    jsonl = _parse_jsonl(rr.stdout)
+    if jsonl.get("sample"):
+        payload["jsonl"] = jsonl
+
     if save and (save.get("type") or "").strip().lower() == "mongo":
         try:
             saved = save_to_mongo_result(
                 tool_name="naabu",
                 tool_commandline=rr.command,
                 scan_target=",".join(ok_targets),
-                data={"stdout": rr.stdout, "stderr": rr.stderr},
+                data={"result": payload, "meta": meta},
             )
             meta["saved"] = saved
         except Exception as e:
             meta["saved"] = {"saved": False, "error": str(e)}
 
     return _tool_ok(
-        {"stdout": rr.stdout, "stderr": rr.stderr},
+        payload,
         meta=meta,
     )
@@
 def nmap_scan(
     targets: list[str],
     args: list[str] | None = None,
@@
 ) -> dict[str, Any]:
     """Run Nmap against targets (structured wrapper)."""
@@
     try:
         rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
     except BinaryNotFoundError as e:
         return _tool_error(str(e))
 
     meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
+    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
+    parsed_ports = _parse_nmap_ports(rr.stdout)
+    if parsed_ports:
+        payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
+
     if save and (save.get("type") or "").strip().lower() == "mongo":
         try:
             saved = save_to_mongo_result(
                 tool_name="nmap",
                 tool_commandline=rr.command,
                 scan_target=",".join(ok_targets),
-                data={"stdout": rr.stdout, "stderr": rr.stderr},
+                data={"result": payload, "meta": meta},
             )
             meta["saved"] = saved
         except Exception as e:
             meta["saved"] = {"saved": False, "error": str(e)}
 
     return _tool_ok(
-        {"stdout": rr.stdout, "stderr": rr.stderr},
+        payload,
         meta=meta,
     )
@@
 def rustscan_scan(
     targets: list[str],
@@
 ) -> dict[str, Any]:
     """Run RustScan against targets with structured options (optionally passing Nmap args)."""
@@
     try:
         rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
     except BinaryNotFoundError as e:
         return _tool_error(str(e))
 
     notes: list[str] = []
     meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
+    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
+    parsed = _parse_rustscan_open_ports(rr.stdout)
+    if parsed.get("sample"):
+        payload["parsed"] = {"open_ports": parsed}
+
     if save and (save.get("type") or "").strip().lower() == "mongo":
         try:
             saved = save_to_mongo_result(
                 tool_name="rustscan",
                 tool_commandline=rr.command,
                 scan_target=",".join(ok_targets),
-                data={"stdout": rr.stdout, "stderr": rr.stderr},
+                data={"result": payload, "meta": meta},
             )
             meta["saved"] = saved
         except Exception as e:
             meta["saved"] = {"saved": False, "error": str(e)}
 
     return _tool_ok(
-        {"stdout": rr.stdout, "stderr": rr.stderr},
+        payload,
         meta=meta,
     )
*** End Patch
```

I see what’s going on: the coordinator currently only **stores `{stdout, stderr}`** in Mongo. To meet your “stdout+JSON but run once” requirement, I’ll update the coordinator so it still prints stdout/stderr, but the Mongo document includes a richer JSON object: `{result:{stdout,stderr,parsed...}, meta:{command,returncode,notes...}}`. No second scan run—just better serialization from the same run.

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}

_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")


def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
    """
    items: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        s = line.strip()
        if not s:
            continue
        total += 1
        if len(items) >= max_items:
            continue
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                items.append(obj)
        except Exception:
            continue
    return {"parsed_count": total, "sample": items, "sample_limit": max_items}


def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
    """
    Very small parser for Nmap's human output table (best-effort).
    """
    ports: list[dict[str, Any]] = []
    for line in (stdout or "").splitlines():
        m = _NMAP_PORT_LINE_RE.match(line.strip())
        if not m:
            continue
        try:
            p = int(m.group("port"))
        except Exception:
            continue
        ports.append(
            {
                "port": p,
                "proto": m.group("proto"),
                "state": m.group("state"),
                "service": m.group("service"),
            }
        )
    return ports


def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
    """
    out: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        m = _RUSTSCAN_OPEN_RE.match(line.strip())
        if not m:
            continue
        total += 1
        if len(out) >= max_items:
            continue
        try:
            port = int(m.group("port"))
        except Exception:
            continue
        out.append({"host": m.group("host"), "port": port})
    return {"parsed_count": total, "sample": out, "sample_limit": max_items}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}

_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")


def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
    """
    items: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        s = line.strip()
        if not s:
            continue
        total += 1
        if len(items) >= max_items:
            continue
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                items.append(obj)
        except Exception:
            continue
    return {"parsed_count": total, "sample": items, "sample_limit": max_items}


def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
    """
    Very small parser for Nmap's human output table (best-effort).
    """
    ports: list[dict[str, Any]] = []
    for line in (stdout or "").splitlines():
        m = _NMAP_PORT_LINE_RE.match(line.strip())
        if not m:
            continue
        try:
            p = int(m.group("port"))
        except Exception:
            continue
        ports.append(
            {
                "port": p,
                "proto": m.group("proto"),
                "state": m.group("state"),
                "service": m.group("service"),
            }
        )
    return ports


def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
    """
    out: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        m = _RUSTSCAN_OPEN_RE.match(line.strip())
        if not m:
            continue
        total += 1
        if len(out) >= max_items:
            continue
        try:
            port = int(m.group("port"))
        except Exception:
            continue
        out.append({"host": m.group("host"), "port": port})
    return {"parsed_count": total, "sample": out, "sample_limit": max_items}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}

_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")


def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
    """
    items: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        s = line.strip()
        if not s:
            continue
        total += 1
        if len(items) >= max_items:
            continue
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                items.append(obj)
        except Exception:
            continue
    return {"parsed_count": total, "sample": items, "sample_limit": max_items}


def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
    """
    Very small parser for Nmap's human output table (best-effort).
    """
    ports: list[dict[str, Any]] = []
    for line in (stdout or "").splitlines():
        m = _NMAP_PORT_LINE_RE.match(line.strip())
        if not m:
            continue
        try:
            p = int(m.group("port"))
        except Exception:
            continue
        ports.append(
            {
                "port": p,
                "proto": m.group("proto"),
                "state": m.group("state"),
                "service": m.group("service"),
            }
        )
    return ports


def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
    """
    out: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        m = _RUSTSCAN_OPEN_RE.match(line.strip())
        if not m:
            continue
        total += 1
        if len(out) >= max_items:
            continue
        try:
            port = int(m.group("port"))
        except Exception:
            continue
        out.append({"host": m.group("host"), "port": port})
    return {"parsed_count": total, "sample": out, "sample_limit": max_items}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"stdout": rr.stdout, "stderr": rr.stderr},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

I’ll finish wiring this through the remaining coordinator tools (`nmap_*`, `rustscan_*`, and the combined runner) so **each scan still runs exactly once**, but the MongoDB record stores a richer JSON object (`result` + parsed summaries + `meta`). Then I’ll reinstall the coordinator in the shared venv and do a quick `call-json` to confirm the saved payload shape.

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}

_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")


def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
    """
    items: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        s = line.strip()
        if not s:
            continue
        total += 1
        if len(items) >= max_items:
            continue
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                items.append(obj)
        except Exception:
            continue
    return {"parsed_count": total, "sample": items, "sample_limit": max_items}


def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
    """
    Very small parser for Nmap's human output table (best-effort).
    """
    ports: list[dict[str, Any]] = []
    for line in (stdout or "").splitlines():
        m = _NMAP_PORT_LINE_RE.match(line.strip())
        if not m:
            continue
        try:
            p = int(m.group("port"))
        except Exception:
            continue
        ports.append(
            {
                "port": p,
                "proto": m.group("proto"),
                "state": m.group("state"),
                "service": m.group("service"),
            }
        )
    return ports


def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
    """
    out: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        m = _RUSTSCAN_OPEN_RE.match(line.strip())
        if not m:
            continue
        total += 1
        if len(out) >= max_items:
            continue
        try:
            port = int(m.group("port"))
        except Exception:
            continue
        out.append({"host": m.group("host"), "port": port})
    return {"parsed_count": total, "sample": out, "sample_limit": max_items}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed_ports = _parse_nmap_ports(rr.stdout)
    if parsed_ports:
        payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed = _parse_rustscan_open_ports(rr.stdout)
    if parsed.get("sample"):
        payload["parsed"] = {"open_ports": parsed}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        results["naabu"] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        results["rustscan"] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        results["nmap"] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    return _tool_ok(
        results,
        meta={
            "invalid_targets": bad[:50],
            "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
            "nmap_coercion": (nmap_notes + nmap_notes2),
        },
    )


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

Done.

### What happens now (single run, dual output)
For the coordinator server (`Standalone_Build/pentest-mcp-server`):

- The scan still runs **exactly once**.
- The tool result still includes **`stdout` / `stderr`** (so the CLI prints it).
- The MongoDB save now stores a richer **JSON rendering** from that same run:

```json
{
  "result": {
    "stdout": "...",
    "stderr": "...",
    "parsed": { ... }   // when available
  },
  "meta": {
    "command": [...],
    "returncode": 0,
    "notes": [...]
  }
}
```

### Verified
`call-json nmap_scan ...` now shows `result.parsed` plus `meta.saved`, and Mongo insert succeeded (you can see the `inserted_id`).

If you want, I can extend the same “parsed JSON summary” approach to `portscan_all` too (it currently doesn’t support `save`).

```json
{
  "result": {
    "stdout": "...",
    "stderr": "...",
    "parsed": { ... }   // when available
  },
  "meta": {
    "command": [...],
    "returncode": 0,
    "notes": [...]
  }
}
```

---

**User**

Yes, please extend the same parsed JSON sunnary for all the portscan_all

---

**Cursor**

Plan: I’ll update `portscan_all` in the standalone coordinator to (1) compute and return parsed summaries for Naabu/RustScan/Nmap in its combined result, and (2) add a `save` parameter so the CLI’s default Mongo saving applies automatically. Then I’ll reinstall the coordinator and verify `call-json portscan_all ...` shows parsed summaries + `meta.saved`.

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}

_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")


def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
    """
    items: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        s = line.strip()
        if not s:
            continue
        total += 1
        if len(items) >= max_items:
            continue
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                items.append(obj)
        except Exception:
            continue
    return {"parsed_count": total, "sample": items, "sample_limit": max_items}


def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
    """
    Very small parser for Nmap's human output table (best-effort).
    """
    ports: list[dict[str, Any]] = []
    for line in (stdout or "").splitlines():
        m = _NMAP_PORT_LINE_RE.match(line.strip())
        if not m:
            continue
        try:
            p = int(m.group("port"))
        except Exception:
            continue
        ports.append(
            {
                "port": p,
                "proto": m.group("proto"),
                "state": m.group("state"),
                "service": m.group("service"),
            }
        )
    return ports


def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
    """
    out: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        m = _RUSTSCAN_OPEN_RE.match(line.strip())
        if not m:
            continue
        total += 1
        if len(out) >= max_items:
            continue
        try:
            port = int(m.group("port"))
        except Exception:
            continue
        out.append({"host": m.group("host"), "port": port})
    return {"parsed_count": total, "sample": out, "sample_limit": max_items}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed_ports = _parse_nmap_ports(rr.stdout)
    if parsed_ports:
        payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed = _parse_rustscan_open_ports(rr.stdout)
    if parsed.get("sample"):
        payload["parsed"] = {"open_ports": parsed}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        naabu_payload: dict[str, Any] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
        jsonl = _parse_jsonl(rr1.stdout)
        if jsonl.get("sample"):
            naabu_payload["parsed"] = {"jsonl": jsonl}
        results["naabu"] = naabu_payload
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        rust_payload: dict[str, Any] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
        parsed = _parse_rustscan_open_ports(rr2.stdout)
        if parsed.get("sample"):
            rust_payload["parsed"] = {"open_ports": parsed}
        results["rustscan"] = rust_payload
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        nmap_payload: dict[str, Any] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
        parsed_ports = _parse_nmap_ports(rr3.stdout)
        if parsed_ports:
            nmap_payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
        results["nmap"] = nmap_payload
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    meta: dict[str, Any] = {
        "invalid_targets": bad[:50],
        "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
        "nmap_coercion": (nmap_notes + nmap_notes2),
    }

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            tool_commandline = {
                "naabu": results.get("naabu", {}).get("command") if isinstance(results.get("naabu"), dict) else None,
                "rustscan": results.get("rustscan", {}).get("command") if isinstance(results.get("rustscan"), dict) else None,
                "nmap": results.get("nmap", {}).get("command") if isinstance(results.get("nmap"), dict) else None,
            }
            saved = save_to_mongo_result(
                tool_name="portscan_all",
                tool_commandline=tool_commandline,
                scan_target=",".join(ok_targets),
                data={"result": results, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(results, meta=meta)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}

_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")


def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
    """
    items: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        s = line.strip()
        if not s:
            continue
        total += 1
        if len(items) >= max_items:
            continue
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                items.append(obj)
        except Exception:
            continue
    return {"parsed_count": total, "sample": items, "sample_limit": max_items}


def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
    """
    Very small parser for Nmap's human output table (best-effort).
    """
    ports: list[dict[str, Any]] = []
    for line in (stdout or "").splitlines():
        m = _NMAP_PORT_LINE_RE.match(line.strip())
        if not m:
            continue
        try:
            p = int(m.group("port"))
        except Exception:
            continue
        ports.append(
            {
                "port": p,
                "proto": m.group("proto"),
                "state": m.group("state"),
                "service": m.group("service"),
            }
        )
    return ports


def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
    """
    out: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        m = _RUSTSCAN_OPEN_RE.match(line.strip())
        if not m:
            continue
        total += 1
        if len(out) >= max_items:
            continue
        try:
            port = int(m.group("port"))
        except Exception:
            continue
        out.append({"host": m.group("host"), "port": port})
    return {"parsed_count": total, "sample": out, "sample_limit": max_items}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed_ports = _parse_nmap_ports(rr.stdout)
    if parsed_ports:
        payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed = _parse_rustscan_open_ports(rr.stdout)
    if parsed.get("sample"):
        payload["parsed"] = {"open_ports": parsed}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    # Only require explicit risk acknowledgement when the caller provides "extra" args
    # that may enable aggressive scanning or additional behaviors (e.g., nmap scripts).
    risky_tokens: set[str] = {
        "--script",
        "--script-args",
        "--script-help",
        "-o",
        "-oA",
        "-oG",
        "-oN",
        "-oX",
        "--resume",
    }
    any_extra = bool(naabu_extra_args) or bool(rustscan_extra_args) or bool(nmap_extra_args)
    style_args = [a.strip() for a in (nmap_style_args2 or []) if isinstance(a, str)]
    needs_ack = any_extra or any(a in risky_tokens for a in style_args)
    if needs_ack:
        ok, err = _require_ack(i_acknowledge_risk)
        if not ok:
            return err  # type: ignore[return-value]

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        naabu_payload: dict[str, Any] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
        jsonl = _parse_jsonl(rr1.stdout)
        if jsonl.get("sample"):
            naabu_payload["parsed"] = {"jsonl": jsonl}
        results["naabu"] = naabu_payload
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        rust_payload: dict[str, Any] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
        parsed = _parse_rustscan_open_ports(rr2.stdout)
        if parsed.get("sample"):
            rust_payload["parsed"] = {"open_ports": parsed}
        results["rustscan"] = rust_payload
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        nmap_payload: dict[str, Any] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
        parsed_ports = _parse_nmap_ports(rr3.stdout)
        if parsed_ports:
            nmap_payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
        results["nmap"] = nmap_payload
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    meta: dict[str, Any] = {
        "invalid_targets": bad[:50],
        "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
        "nmap_coercion": (nmap_notes + nmap_notes2),
    }

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            tool_commandline = {
                "naabu": results.get("naabu", {}).get("command") if isinstance(results.get("naabu"), dict) else None,
                "rustscan": results.get("rustscan", {}).get("command") if isinstance(results.get("rustscan"), dict) else None,
                "nmap": results.get("nmap", {}).get("command") if isinstance(results.get("nmap"), dict) else None,
            }
            saved = save_to_mongo_result(
                tool_name="portscan_all",
                tool_commandline=tool_commandline,
                scan_target=",".join(ok_targets),
                data={"result": results, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(results, meta=meta)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .logging_utils import configure_logging, get_logger, security_event
from .mongo_store import save_to_mongo_result
from .normalize import coerce_nmap_unprivileged, normalize_nmap_style_args
from .runners import BinaryNotFoundError, run_naabu, run_nmap, run_rustscan
from .validation import clamp_int, normalize_rustscan_ports, validate_args, validate_targets


configure_logging()
logger = get_logger(__name__)

mcp = FastMCP(name="pentest-suite")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}

_NMAP_PORT_LINE_RE = re.compile(r"^(?P<port>\d{1,5})/(?P<proto>tcp|udp)\s+(?P<state>\S+)\s+(?P<service>\S+)\s*$")
_RUSTSCAN_OPEN_RE = re.compile(r"^Open\s+(?P<host>[^:]+):(?P<port>\d{1,5})\s*$")


def _parse_jsonl(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Best-effort parse of JSONL output into a small list for Mongo-friendly storage.
    """
    items: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        s = line.strip()
        if not s:
            continue
        total += 1
        if len(items) >= max_items:
            continue
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                items.append(obj)
        except Exception:
            continue
    return {"parsed_count": total, "sample": items, "sample_limit": max_items}


def _parse_nmap_ports(stdout: str) -> list[dict[str, Any]]:
    """
    Very small parser for Nmap's human output table (best-effort).
    """
    ports: list[dict[str, Any]] = []
    for line in (stdout or "").splitlines():
        m = _NMAP_PORT_LINE_RE.match(line.strip())
        if not m:
            continue
        try:
            p = int(m.group("port"))
        except Exception:
            continue
        ports.append(
            {
                "port": p,
                "proto": m.group("proto"),
                "state": m.group("state"),
                "service": m.group("service"),
            }
        )
    return ports


def _parse_rustscan_open_ports(stdout: str, *, max_items: int = 500) -> dict[str, Any]:
    """
    Parse lines like 'Open 192.168.1.1:443' from RustScan output (best-effort).
    """
    out: list[dict[str, Any]] = []
    total = 0
    for line in (stdout or "").splitlines():
        m = _RUSTSCAN_OPEN_RE.match(line.strip())
        if not m:
            continue
        total += 1
        if len(out) >= max_items:
            continue
        try:
            port = int(m.group("port"))
        except Exception:
            continue
        out.append({"host": m.group("host"), "port": port})
    return {"parsed_count": total, "sample": out, "sample_limit": max_items}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    """
    Decorator that records tool metadata (name/docstring/signature) so we can expose
    `list_tools`/`describe_tool` as normal MCP tools.
    """
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


@mcp.tool()
@register_tool
def naabu_scan(
    targets: list[str],
    ports: str | None = None,
    top_ports: int | None = None,
    rate: int = 1000,
    exclude_ports: str | None = None,
    json_output: bool = True,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu against targets with common structured options (safe wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if bad:
        security_event(logger, "invalid_targets", examples=bad[:5], count=len(bad))
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    try:
        rate = clamp_int(rate, min_value=1, max_value=5_000_000, name="rate")
        if top_ports is not None:
            top_ports = clamp_int(top_ports, min_value=1, max_value=65535, name="top_ports")
    except ValueError as e:
        return _tool_error(str(e))

    args: list[str] = ["-silent", "-rate", str(rate)]
    if json_output:
        args.append("-json")
    if ports:
        args.extend(["-p", ports])
    if top_ports is not None:
        args.extend(["-top-ports", str(top_ports)])
    if exclude_ports:
        args.extend(["-exclude-ports", exclude_ports])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            security_event(logger, "invalid_args", error=res.message)
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def naabu_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 300,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_naabu(targets=ok_targets, args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    jsonl = _parse_jsonl(rr.stdout)
    if jsonl.get("sample"):
        payload["jsonl"] = jsonl
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="naabu",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan(
    targets: list[str],
    args: list[str] | None = None,
    force_unprivileged: bool = True,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Nmap against targets (structured wrapper)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args2 = args or []

    notes: list[str] = []
    if force_unprivileged and os.getenv("NMAP_FORCE_UNPRIVILEGED", "1").strip() != "0":
        args2, notes = coerce_nmap_unprivileged(args2)
    res = validate_args(args2)
    if not res.ok:
        return _tool_error(res.message or "invalid args")

    try:
        rr = run_nmap(targets=ok_targets, args=args2, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed_ports = _parse_nmap_ports(rr.stdout)
    if parsed_ports:
        payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="nmap",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def nmap_scan_raw(
    targets: list[str],
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run Nmap with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    return nmap_scan(targets, args=args, timeout_seconds=timeout_seconds)


@mcp.tool()
@register_tool
def rustscan_scan(
    targets: list[str],
    ports: str | None = None,
    batch_size: int | None = None,
    timeout_millis: int | None = None,
    nmap_args: list[str] | None = None,
    extra_args: list[str] | None = None,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run RustScan against targets with structured options (optionally passing Nmap args)."""
    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    args: list[str] = []
    if ports:
        pres, pargs = normalize_rustscan_ports(ports)
        if not pres.ok:
            security_event(logger, "invalid_ports", error=pres.message, ports=ports)
            return _tool_error(pres.message or "invalid ports")
        args.extend(pargs)
    if batch_size is not None:
        try:
            batch_size = clamp_int(batch_size, min_value=1, max_value=100000, name="batch_size")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-b", str(batch_size)])
    if timeout_millis is not None:
        try:
            timeout_millis = clamp_int(timeout_millis, min_value=1, max_value=600000, name="timeout_millis")
        except ValueError as e:
            return _tool_error(str(e))
        args.extend(["-t", str(timeout_millis)])

    if extra_args:
        res = validate_args(extra_args)
        if not res.ok:
            return _tool_error(res.message or "invalid args")
        args.extend(extra_args)

    if nmap_args:
        res = validate_args(nmap_args)
        if not res.ok:
            return _tool_error(res.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    meta = {"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes}
    payload: dict[str, Any] = {"stdout": rr.stdout, "stderr": rr.stderr}
    parsed = _parse_rustscan_open_ports(rr.stdout)
    if parsed.get("sample"):
        payload["parsed"] = {"open_ports": parsed}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            saved = save_to_mongo_result(
                tool_name="rustscan",
                tool_commandline=rr.command,
                scan_target=",".join(ok_targets),
                data={"result": payload, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(
        payload,
        meta=meta,
    )


@mcp.tool()
@register_tool
def rustscan_scan_raw(
    targets: list[str],
    args: list[str],
    nmap_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
) -> dict[str, Any]:
    """Run RustScan with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    res = validate_args(args)
    if not res.ok:
        return _tool_error(res.message or "invalid args")
    if nmap_args:
        res2 = validate_args(nmap_args)
        if not res2.ok:
            return _tool_error(res2.message or "invalid nmap_args")

    try:
        rr = run_rustscan(targets=ok_targets, args=args, nmap_args=nmap_args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e))

    notes: list[str] = []
    return _tool_ok(
        {"stdout": rr.stdout, "stderr": rr.stderr},
        meta={"returncode": rr.returncode, "command": rr.command, "invalid_targets": bad[:50], "nmap_notes": notes},
    )


@mcp.tool()
@register_tool
def portscan_all(
    targets: list[str],
    nmap_style_args: list[str] | None = None,
    naabu_extra_args: list[str] | None = None,
    rustscan_extra_args: list[str] | None = None,
    nmap_extra_args: list[str] | None = None,
    i_acknowledge_risk: bool = False,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run Naabu, RustScan, and Nmap with a unified Nmap-style option set (best-effort mapping)."""

    ok_targets, bad = validate_targets(targets)
    if not ok_targets:
        return _tool_error("no valid targets", details={"invalid": bad[:50]})

    nmap_style_args2 = nmap_style_args or []
    res = validate_args(nmap_style_args2)
    if not res.ok:
        return _tool_error(res.message or "invalid nmap_style_args")

    # Only require explicit risk acknowledgement when the caller provides "extra" args
    # that may enable aggressive scanning or additional behaviors (e.g., nmap scripts).
    risky_tokens: set[str] = {
        "--script",
        "--script-args",
        "--script-help",
        "-o",
        "-oA",
        "-oG",
        "-oN",
        "-oX",
        "--resume",
    }
    any_extra = bool(naabu_extra_args) or bool(rustscan_extra_args) or bool(nmap_extra_args)
    style_args = [a.strip() for a in nmap_style_args2 if isinstance(a, str)]
    needs_ack = any_extra or any(a in risky_tokens for a in style_args)
    if needs_ack:
        ok, err = _require_ack(i_acknowledge_risk)
        if not ok:
            return err  # type: ignore[return-value]

    norm, nmap_remaining = normalize_nmap_style_args(nmap_style_args2)

    # Naabu mapping
    naabu_args: list[str] = ["-silent", "-json"]
    if norm.ports:
        naabu_args.extend(["-p", norm.ports])
    if norm.top_ports is not None:
        naabu_args.extend(["-top-ports", str(norm.top_ports)])
    if norm.min_rate is not None:
        naabu_args.extend(["-rate", str(norm.min_rate)])
    if naabu_extra_args:
        ra = validate_args(naabu_extra_args)
        if not ra.ok:
            return _tool_error(ra.message or "invalid naabu_extra_args")
        naabu_args.extend(naabu_extra_args)

    # RustScan mapping
    rust_args: list[str] = []
    if norm.ports:
        pres, pargs = normalize_rustscan_ports(norm.ports)
        if not pres.ok:
            return _tool_error(pres.message or "invalid ports")
        rust_args.extend(pargs)
    if rustscan_extra_args:
        ra2 = validate_args(rustscan_extra_args)
        if not ra2.ok:
            return _tool_error(ra2.message or "invalid rustscan_extra_args")
        rust_args.extend(rustscan_extra_args)

    # Nmap args
    nmap_args: list[str] = nmap_remaining
    if nmap_extra_args:
        rn = validate_args(nmap_extra_args)
        if not rn.ok:
            return _tool_error(rn.message or "invalid nmap_extra_args")
        nmap_args.extend(nmap_extra_args)

    results: dict[str, Any] = {}

    try:
        rr1 = run_naabu(targets=ok_targets, args=naabu_args, timeout_seconds=300)
        naabu_payload: dict[str, Any] = {"stdout": rr1.stdout, "stderr": rr1.stderr, "returncode": rr1.returncode, "command": rr1.command}
        jsonl = _parse_jsonl(rr1.stdout)
        if jsonl.get("sample"):
            naabu_payload["parsed"] = {"jsonl": jsonl}
        results["naabu"] = naabu_payload
    except Exception as e:
        results["naabu"] = {"error": str(e)}

    try:
        nmap_args_safe, nmap_notes = coerce_nmap_unprivileged(nmap_args)
        rr2 = run_rustscan(targets=ok_targets, args=rust_args, nmap_args=nmap_args_safe, timeout_seconds=900)
        rust_payload: dict[str, Any] = {"stdout": rr2.stdout, "stderr": rr2.stderr, "returncode": rr2.returncode, "command": rr2.command}
        parsed = _parse_rustscan_open_ports(rr2.stdout)
        if parsed.get("sample"):
            rust_payload["parsed"] = {"open_ports": parsed}
        results["rustscan"] = rust_payload
    except Exception as e:
        results["rustscan"] = {"error": str(e)}
        nmap_notes = []

    try:
        nmap_args_final, nmap_notes2 = coerce_nmap_unprivileged(nmap_args)
        rr3 = run_nmap(targets=ok_targets, args=nmap_args_final, timeout_seconds=900)
        nmap_payload: dict[str, Any] = {"stdout": rr3.stdout, "stderr": rr3.stderr, "returncode": rr3.returncode, "command": rr3.command}
        parsed_ports = _parse_nmap_ports(rr3.stdout)
        if parsed_ports:
            nmap_payload["parsed"] = {"ports": parsed_ports, "count": len(parsed_ports)}
        results["nmap"] = nmap_payload
    except Exception as e:
        results["nmap"] = {"error": str(e)}
        nmap_notes2 = []

    meta: dict[str, Any] = {
        "invalid_targets": bad[:50],
        "normalized": {"ports": norm.ports, "top_ports": norm.top_ports, "min_rate": norm.min_rate},
        "nmap_coercion": (nmap_notes + nmap_notes2),
    }

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            tool_commandline = {
                "naabu": results.get("naabu", {}).get("command") if isinstance(results.get("naabu"), dict) else None,
                "rustscan": results.get("rustscan", {}).get("command") if isinstance(results.get("rustscan"), dict) else None,
                "nmap": results.get("nmap", {}).get("command") if isinstance(results.get("nmap"), dict) else None,
            }
            saved = save_to_mongo_result(
                tool_name="portscan_all",
                tool_commandline=tool_commandline,
                scan_target=",".join(ok_targets),
                data={"result": results, "meta": meta},
            )
            meta["saved"] = saved
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(results, meta=meta)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        security_event(logger, "invalid_tool_name", tool_name=tool_name)
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port_raw = os.getenv("MCP_PORT", "4598")
    # Cursor MCP "command" servers speak stdio. Default to stdio so a plain
    # `python -m pentest_mcp_server.server` works in Cursor without extra env.
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    path = os.getenv("MCP_PATH", "").strip() or None

    # FastMCP's stdio transport does not accept HTTP server args (host/port/path).
    if transport == "stdio":
        logger.info("Starting MCP server", extra={"transport": transport})
        mcp.run(transport="stdio")
        return

    try:
        port = int(port_raw)
    except ValueError:
        security_event(logger, "invalid_mcp_port", value=port_raw)
        port = 4598

    if transport in {"http", "sse", "streamable-http"}:
        logger.info("Starting MCP server", extra={"transport": transport, "host": host, "port": port, "path": path or ""})
        mcp.run(transport=transport, host=host, port=port, path=path)
        return

    security_event(logger, "unknown_mcp_transport", value=transport)
    logger.info("Starting MCP server with fallback transport", extra={"transport": "streamable-http", "host": host, "port": port, "path": path or ""})
    mcp.run(transport="streamable-http", host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

Implemented for `portscan_all`.

### What’s new
- **Parsed JSON summaries** are now included for each sub-scan in `portscan_all`:
  - **naabu**: `parsed.jsonl` (sample of JSONL output)
  - **rustscan**: `parsed.open_ports` (sample of `Open host:port` lines)
  - **nmap**: `parsed.ports` (parsed table rows with `port/proto/state/service`)
- `portscan_all` now supports **`save`**, so your CLI’s default `save={"type":"mongo"}` injection works and Mongo gets the full structured payload.
- Still **runs each scanner once** and reuses that single run’s outputs for both terminal stdout/stderr and Mongo JSON storage.

### Note on `i_acknowledge_risk`
`portscan_all` no longer requires `i_acknowledge_risk=true` for the **common safe case** (no extra args). It will only require it if you pass extra args or script/output-style flags.

---

**User**

Can you also please update the documentation on the pentest-cli, including examples for the various tools that are supported.

Also, can you please add functions to be able to search and query the MongoDB? At this time, you can simply support the ability for the user to put in a pymongo query filter for find_one or find (many) and output what is found.

---

**Cursor**

Plan: I’ll extend `pentest-cli` docs with copy/paste examples for the main tools (pentest scans, Shodan, Searchsploit, Nmap/RustScan/portscan_all, plus save-to-Mongo defaults). Then I’ll add new REPL commands `mongo-use`, `mongo-find-one`, and `mongo-find` that accept a JSON filter (or `@file.json`) and print results nicely, using `MONGO_URI`/`MONGO_DB`/`MONGO_COLLECTION` from `Standalone_Build/.env`.

```python
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass(frozen=True)
class McpServerConfig:
    name: str
    command: str
    args: list[str]
    env: dict[str, str]


def load_mcp_json(path: str) -> dict[str, McpServerConfig]:
    p = Path(path)
    if not p.exists():
        return {}
    raw = json.loads(p.read_text(encoding="utf-8"))
    servers = raw.get("mcpServers") or {}
    out: dict[str, McpServerConfig] = {}

    if not isinstance(servers, dict):
        return out

    for name, cfg in servers.items():
        if not isinstance(name, str) or not name.strip():
            continue
        if not isinstance(cfg, dict):
            continue

        command = cfg.get("command")
        args = cfg.get("args") or []
        env = cfg.get("env") or {}

        if not isinstance(command, str) or not command.strip():
            continue
        if not isinstance(args, list) or not all(isinstance(a, str) for a in args):
            args = []
        if not isinstance(env, dict):
            env = {}

        # stringify env values defensively
        env2: dict[str, str] = {}
        for k, v in env.items():
            if not isinstance(k, str) or not k.strip():
                continue
            if v is None:
                continue
            env2[k] = str(v)

        out[name] = McpServerConfig(name=name, command=command, args=list(args), env=env2)

    return out


def find_default_mcp_json(start_dir: str | None = None) -> str:
    """
    Best-effort discovery of a local mcp.json for Standalone_Build use.
    Preference order:
    - $PENTEST_CLI_CONFIG if set
    - ./mcp.json
    - ./Standalone_Build/mcp.json
    - walk up parents looking for Standalone_Build/mcp.json
    """
    env = (os.getenv("PENTEST_CLI_CONFIG", "") or "").strip()
    if env:
        return env

    base = Path(start_dir or Path.cwd())
    c1 = base / "mcp.json"
    if c1.exists():
        return str(c1)
    c2 = base / "Standalone_Build" / "mcp.json"
    if c2.exists():
        return str(c2)

    for parent in [base, *base.parents]:
        cand = parent / "Standalone_Build" / "mcp.json"
        if cand.exists():
            return str(cand)

    # Also try relative to this installed package location (works even when
    # invoking the CLI from arbitrary directories).
    try:
        here = Path(__file__).resolve()
        for parent in [here, *here.parents]:
            # If we're inside Standalone_Build already
            if parent.name == "Standalone_Build":
                cand2 = parent / "mcp.json"
                if cand2.exists():
                    return str(cand2)
            # Or look for a sibling Standalone_Build
            cand3 = parent / "Standalone_Build" / "mcp.json"
            if cand3.exists():
                return str(cand3)
    except Exception:
        pass

    # Fall back to ./mcp.json even if missing (caller will handle empty config).
    return str(c1)


def safe_json_loads(s: str) -> Any:
    return json.loads(s)


def load_dotenv_file(path: str, *, override: bool = False) -> dict[str, str]:
    """
    Minimal .env loader (no external deps).
    - Supports KEY=VALUE with optional quotes.
    - Ignores blank lines and comments.
    - By default does NOT override existing os.environ.
    """
    p = Path(path)
    if not p.exists():
        return {}
    out: dict[str, str] = {}
    for raw in p.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        k, v = line.split("=", 1)
        key = k.strip()
        if not key:
            continue
        val = v.strip()
        if (val.startswith('"') and val.endswith('"')) or (val.startswith("'") and val.endswith("'")):
            val = val[1:-1]
        out[key] = val
        if override or (key not in os.environ):
            os.environ[key] = val
    return out



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  call-json <tool> <json|@file>     Call a tool and print the full MCP JSON response",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call-json <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  call-json <tool> <json|@file>     Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Disconnect existing connection first.
        await self.cmd_disconnect()

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)

        # Keep the stdio transport + session contexts open across REPL commands.
        stack = anyio.create_task_group()  # placeholder for typing; not used directly
        del stack

        cm = stdio_client(params)
        streams = await cm.__aenter__()  # type: ignore[misc]
        read_stream, write_stream = streams

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        self.conn = ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        res = await conn.session.list_tools()
        tools = res.tools or []
        q = (filt or "").strip().lower()
        if q:
            tools = [t for t in tools if q in (t.name or "").lower() or q in (t.description or "").lower()]

        self._print(f"Tools ({len(tools)}):")
        for t in tools:
            desc = (t.description or "").strip().splitlines()[0] if t.description else ""
            self._print(f"  - {t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_format_describe(tool))

    async def cmd_describe_json(self, tool_name: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: describe-json <tool>")
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)")
            return
        name = (tool_name or "").strip()
        if not name:
            raise ValueError("usage: call-json <tool> <json|@file>")
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

```plaintext
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "pentest-cli"
version = "0.1.0"
description = "Interactive terminal CLI for calling MCP tools (stdio) using a local mcp.json"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
  "mcp>=1.0.0",
  "pymongo>=4.7.0",
]

[project.scripts]
pentest-cli = "pentest_cli.__main__:main"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]



```

```markdown
# pentest-cli

Interactive terminal CLI for calling MCP tools over **stdio** using a local `mcp.json`.

## Install (shared venv)

From `Standalone_Build/`:

```bash
source .venv/bin/activate
pip install -e ./pentest-cli
```

## Run

```bash
pentest-cli
```

## Commands

- `servers` — list configured servers from `Standalone_Build/mcp.json`
- `connect <server>` — start and connect to a server (stdio)
- `status` — show current connection
- `tools [filter]` — list tools (optional substring filter)
- `describe <tool>` — human-friendly help for a tool (inputs + example call)
- `describe-json <tool>` — raw tool schema (MCP JSON schema)
- `call <tool> <json|@file>` — call a tool (prints stdout/stderr by default)
- `call-json <tool> <json|@file>` — call a tool and print full MCP JSON response
- `mongo-use <db> <collection>` — set default db/collection for CLI Mongo queries
- `mongo-find-one <json|@file>` — run `find_one(filter)` against default db/collection
- `mongo-find <json|@file> [limit=N]` — run `find(filter).limit(N)` against default db/collection
- `quit` / `exit` — leave the shell

## Examples (pentest coordinator)

List tools:

```text
pentest> tools
pentest> tools scan
```

Describe a tool:

```text
pentest> describe nmap_scan
pentest> describe-json nmap_scan
```

Nmap scan (ports 1-1024):

```text
pentest> call nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
```

RustScan scan (ports 1-1024):

```text
pentest> call rustscan_scan {"targets":["192.168.1.1"],"ports":"1-1024"}
```

All-in-one port scanning (naabu + rustscan + nmap):

```text
pentest> call portscan_all {"targets":["192.168.1.1"],"nmap_style_args":["-p","1-1024","-sT"]}
```

Notes:
- By default, `pentest-cli` injects `save={"type":"mongo"}` for tools that support saving (unless you run with `--no-save-mongo`).\n+- Ensure `MONGO_URI` is set and MongoDB is running, or you’ll see `saved: failed (...)`.\n+
## MongoDB query examples (CLI-side, via pymongo)

Set default db/collection for queries:

```text
pentest> mongo-use mcp_db results
```

Find one recent run for a tool:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

Find many (limit 5):

```text
pentest> mongo-find {"tool_name":"portscan_all"} limit=5
```

## Config and .env

`pentest-cli` uses:
- `Standalone_Build/mcp.json` for server definitions
- `Standalone_Build/.env` (auto-loaded, unless `PENTEST_CLI_NO_DOTENV` is set) for variables like `MONGO_URI`, `MONGO_DB`, `MONGO_COLLECTION`


```
I reinstalled the CLI and ran it from $HOME (outside the repo) and it successfully found:
…/Standalone_Build/mcp.json and loaded 8 servers
then auto-connected to pentest
If you still ever want to force it, you can also do:
pentest-cli --config "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json"
or export PENTEST_CLI_CONFIG=...
```
```

### Updated `pentest-cli` documentation (with examples)
I expanded `Standalone_Build/pentest-cli/README.md` to include:
- Updated command list (`describe`, `describe-json`, `call`, `call-json`)
- Examples for the main pentest tools:
  - `nmap_scan`, `rustscan_scan`, `portscan_all`
- Notes about the default Mongo save behavior
- Mongo query examples (`mongo-use`, `mongo-find-one`, `mongo-find`)

### Added MongoDB query commands to `pentest-cli` (CLI-side, via `pymongo`)
New REPL commands (no MCP server needed for these):
- `mongo-use <db> <collection>`
- `mongo-find-one <json|@file>`
- `mongo-find <json|@file> [limit=N]`

They accept a **JSON filter** exactly like a pymongo filter and print pretty JSON (with `_id` converted to a string).

### `.env` integration for the CLI
`pentest-cli` now **auto-loads `Standalone_Build/.env`** (unless you set `PENTEST_CLI_NO_DOTENV`), so the Mongo query commands use:
- `MONGO_URI`
- `MONGO_DB`
- `MONGO_COLLECTION`

### Verified
I ran `mongo-find-one {"tool_name":"nmap"}` and it successfully returned a stored document from MongoDB, including the parsed summary you added earlier.

If you want, I can add optional `--projection` support (or `mongo-find <filter> projection=@proj.json`) next.

---

**User**

Did you document all of those changes?

---

**Cursor**

Yes.

- **CLI docs updated**: `Standalone_Build/pentest-cli/README.md` now includes:
  - The new/updated commands (`describe-json`, `call-json`, Mongo query commands)
  - Examples for `nmap_scan`, `rustscan_scan`, and `portscan_all`
  - Notes about **default Mongo saving** and `.env` usage

- **CLI help updated**: the in-CLI `help` output (from `Standalone_Build/pentest-cli/src/pentest_cli/repl.py`) also lists the new Mongo commands.

---

**User**

 Can you now add in the rest of the standalone_build mcp servers? Please add in shodan, searchsploit, theharvester, wpscan and searx so they can be called from the pentest-cli. The entries for the mcp servers should already be in the standalone_build/mcp.json file

---

**Cursor**

I’ll first verify what’s currently in `Standalone_Build/mcp.json` and what `pentest-cli` sees at runtime. If those servers are already listed, then nothing needs “adding” — you can `connect shodan` / `connect searchsploit` etc. If you want **one shell to call tools across servers without reconnecting**, I’ll add a `use <server>` alias plus a `call <server>.<tool> {...}` convenience.

You already *have* those servers wired into `Standalone_Build/mcp.json`, and `pentest-cli` is loading them (I can see `shodan`, `searchsploit`, `theharvester`, `wpscan`, `searx` in `servers`). Next I’ll run quick smoke checks connecting to each one and listing tools, and then I’ll update the `pentest-cli` README with “how to switch servers and call tools” examples so it’s obvious in day-to-day use.

```markdown
*** Begin Patch
*** Update File: Standalone_Build/pentest-cli/README.md
@@
 ## Examples (pentest coordinator)
@@
 Notes:
 - By default, `pentest-cli` injects `save={"type":"mongo"}` for tools that support saving (unless you run with `--no-save-mongo`).\n - Ensure `MONGO_URI` is set and MongoDB is running, or you’ll see `saved: failed (...)`.\n 
+## Examples (other servers)
+
+Switch servers (you must `connect` before calling tools on that server):
+
+```text
+pentest> servers
+pentest> connect shodan
+```
+
+### Shodan
+
+```text
+pentest> connect shodan
+pentest> tools
+pentest> describe shodan_search
+pentest> call shodan_search {"query":"org:\"Example Corp\"","max_results":5}
+```
+
+### Searchsploit
+
+```text
+pentest> connect searchsploit
+pentest> call searchsploit_search {"terms":["wordpress","plugin"],"case_insensitive":true}
+```
+
+### theHarvester
+
+```text
+pentest> connect theharvester
+pentest> call theharvester_run {"domain":"example.com","sources":"all","limit":200,"start":0}
+```
+
+### WPScan
+
+```text
+pentest> connect wpscan
+pentest> call wpscan_scan {"url":"https://example.com","enumerate":"vp,vt,cb,u","stealthy":true}
+```
+
+### SearXNG
+
+```text
+pentest> connect searx
+pentest> call searx_search {"query":"example.com exposed admin","max_results":10}
+```
+
 ## MongoDB query examples (CLI-side, via pymongo)
*** End Patch
```

```markdown
# pentest-cli

Interactive terminal CLI for calling MCP tools over **stdio** using a local `mcp.json`.

## Install (shared venv)

From `Standalone_Build/`:

```bash
source .venv/bin/activate
pip install -e ./pentest-cli
```

## Run

```bash
pentest-cli
```

## Commands

- `servers` — list configured servers from `Standalone_Build/mcp.json`
- `connect <server>` — start and connect to a server (stdio)
- `status` — show current connection
- `tools [filter]` — list tools (optional substring filter)
- `describe <tool>` — human-friendly help for a tool (inputs + example call)
- `describe-json <tool>` — raw tool schema (MCP JSON schema)
- `call <tool> <json|@file>` — call a tool (prints stdout/stderr by default)
- `call-json <tool> <json|@file>` — call a tool and print full MCP JSON response
- `mongo-use <db> <collection>` — set default db/collection for CLI Mongo queries
- `mongo-find-one <json|@file>` — run `find_one(filter)` against default db/collection
- `mongo-find <json|@file> [limit=N]` — run `find(filter).limit(N)` against default db/collection
- `quit` / `exit` — leave the shell

## Examples (pentest coordinator)

List tools:

```text
pentest> tools
pentest> tools scan
```

Describe a tool:

```text
pentest> describe nmap_scan
pentest> describe-json nmap_scan
```

Nmap scan (ports 1-1024):

```text
pentest> call nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
```

RustScan scan (ports 1-1024):

```text
pentest> call rustscan_scan {"targets":["192.168.1.1"],"ports":"1-1024"}
```

All-in-one port scanning (naabu + rustscan + nmap):

```text
pentest> call portscan_all {"targets":["192.168.1.1"],"nmap_style_args":["-p","1-1024","-sT"]}
```

Notes:
- By default, `pentest-cli` injects `save={"type":"mongo"}` for tools that support saving (unless you run with `--no-save-mongo`).
- Ensure `MONGO_URI` is set and MongoDB is running, or you’ll see `saved: failed (...)`.

## Examples (other servers)

Switch servers (you must `connect` before calling tools on that server):

```text
pentest> servers
pentest> connect shodan
```

### Shodan

```text
pentest> connect shodan
pentest> tools
pentest> describe shodan_search
pentest> call shodan_search {"query":"org:\"Example Corp\"","max_results":5}
```

### Searchsploit

```text
pentest> connect searchsploit
pentest> call searchsploit_search {"terms":["wordpress","plugin"],"case_insensitive":true}
```

### theHarvester

```text
pentest> connect theharvester
pentest> call theharvester_run {"domain":"example.com","sources":"all","limit":200,"start":0}
```

### WPScan

```text
pentest> connect wpscan
pentest> call wpscan_scan {"url":"https://example.com","enumerate":"vp,vt,cb,u","stealthy":true}
```

### SearXNG

```text
pentest> connect searx
pentest> call searx_search {"query":"example.com exposed admin","max_results":10}
```
## MongoDB query examples (CLI-side, via pymongo)

Set default db/collection for queries:

```text
pentest> mongo-use mcp_db results
```

Find one recent run for a tool:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

Find many (limit 5):

```text
pentest> mongo-find {"tool_name":"portscan_all"} limit=5
```

## Config and .env

`pentest-cli` uses:
- `Standalone_Build/mcp.json` for server definitions
- `Standalone_Build/.env` (auto-loaded, unless `PENTEST_CLI_NO_DOTENV` is set) for variables like `MONGO_URI`, `MONGO_DB`, `MONGO_COLLECTION`

## Config discovery

By default, `pentest-cli` auto-discovers `Standalone_Build/mcp.json` even when run outside the repo.

To force a specific config:

- `pentest-cli --config "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json"`
- or `export PENTEST_CLI_CONFIG=/path/to/mcp.json`
```

They’re already callable from `pentest-cli` — nothing new needed in `mcp.json` (those entries are present), you just need to **switch servers** before calling their tools.

### What I did
- **Verified** `pentest-cli` loads all servers from `Standalone_Build/mcp.json` (it shows `shodan`, `searchsploit`, `theharvester`, `wpscan`, `searx`).
- **Smoke-tested** `connect <server>` + `tools` for each of those servers — all list tools successfully.
- **Updated docs** so it’s clear how to use them.

### Documentation update
I updated: `Standalone_Build/pentest-cli/README.md` with a new **“Examples (other servers)”** section showing how to:

- `connect shodan` then `call shodan_search {...}`
- `connect searchsploit` then `call searchsploit_search {...}`
- `connect theharvester` then `call theharvester_run {...}`
- `connect wpscan` then `call wpscan_scan {...}`
- `connect searx` then `call searx_search {...}`

### How to use in the CLI
Example:

```text
pentest> connect shodan
pentest> tools
pentest> call shodan_search {"query":"ssl:true","max_results":5}
```

If you want, I can also add a convenience syntax like `call shodan.shodan_search {...}` so you don’t have to manually `connect`/switch servers.

```plaintext
pentest> connect shodan
pentest> tools
pentest> call shodan_search {"query":"ssl:true","max_results":5}
```

---

**User**

Yes, if you could add the convenience syntax like the `call shodan.shodan_search {...}` to allow the calling without the servers running all the time. Also, please add all of the convenience syntaxes to the "tools" and "describe_tools" functions.

---

**Cursor**

Plan: I’ll add `server.tool` support across `call`, `call-json`, `describe`, `describe-json`, and `tools`. Under the hood, the CLI will spin up the target server **on-demand**, run the request, then shut it down—so nothing stays running unless you explicitly `connect`. Next I’ll update the CLI help + README examples accordingly and smoke-test a couple of prefixed calls.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (optional substring filter)",
                    "  describe <tool>                   Show a human-friendly description + how to call it",
                    "  describe-json <tool>              Show the raw MCP JSON schema for a tool",
                    "  call <tool> <json|@file>          Call a tool with JSON arguments",
                    "  call-json <tool> <json|@file>     Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # If connected and no filter, list tools for the current server only (fast).
        if self.conn and not q:
            res = await self.conn.session.list_tools()
            tools = res.tools or []
            self._print(f"Tools ({len(tools)}):")
            for t in tools:
                desc = (t.description or "").strip().splitlines()[0] if t.description else ""
                self._print(f"  - {self.conn.name}.{t.name}: {desc}")
            return

        # Otherwise, list tools across servers on-demand (or for a specific server if q matches).
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            # Reuse current connection if it matches; otherwise open a temp one.
            if self.conn and self.conn.name == s:
                res = await self.conn.session.list_tools()
                tools = res.tools or []
                for t in tools:
                    items.append((s, t))
            else:
                async with self._temp_connection(s) as conn:
                    res = await conn.session.list_tools()
                    tools = res.tools or []
                    for t in tools:
                        items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            self._print(f"  - {s}.{t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
            return

        # Unqualified tool name: require existing connection.
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)  OR use: describe <server>.<tool>")
            return
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {conn.name}.{name}")
        self._print(_format_describe_with_name(tool, display_name=f"{conn.name}.{name}"))

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
            return

        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)  OR use: describe-json <server>.<tool>")
            return
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {conn.name}.{name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        # server.tool => one-off connection, do not keep server running.
        if server:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)
                # Reuse the same printing logic below by shadowing `conn`
                pass
        else:
            try:
                conn = self._require_conn()
            except RuntimeError:
                self._print("Not connected. Run: connect <server>  (try: servers)  OR use: call <server>.<tool> {...}")
                return
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if server:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)
                self._print(_dump(result))
            return

        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)  OR use: call-json <server>.<tool> {...}")
            return
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

Nice—`pentest-cli` already has clean connection lifecycle primitives, so adding `server.tool` can be done without keeping any servers running. Next I’ll tighten the help/docs and run a couple real prefixed calls (`shodan.shodan_filters`, `tools shodan`, `describe shodan.shodan_search`) to confirm end-to-end behavior.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (supports 'server' and 'server.tool' style filtering)",
                    "  describe <tool|server.tool>       Show a human-friendly description + how to call it",
                    "  describe-json <tool|server.tool>  Show the raw MCP JSON schema for a tool",
                    "  call <tool|server.tool> <json|@file>      Call a tool (server.tool runs on-demand, no persistent connect)",
                    "  call-json <tool|server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # If connected and no filter, list tools for the current server only (fast).
        if self.conn and not q:
            res = await self.conn.session.list_tools()
            tools = res.tools or []
            self._print(f"Tools ({len(tools)}):")
            for t in tools:
                desc = (t.description or "").strip().splitlines()[0] if t.description else ""
                self._print(f"  - {self.conn.name}.{t.name}: {desc}")
            return

        # Otherwise, list tools across servers on-demand (or for a specific server if q matches).
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            # Reuse current connection if it matches; otherwise open a temp one.
            if self.conn and self.conn.name == s:
                res = await self.conn.session.list_tools()
                tools = res.tools or []
                for t in tools:
                    items.append((s, t))
            else:
                async with self._temp_connection(s) as conn:
                    res = await conn.session.list_tools()
                    tools = res.tools or []
                    for t in tools:
                        items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            self._print(f"  - {s}.{t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
            return

        # Unqualified tool name: require existing connection.
        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)  OR use: describe <server>.<tool>")
            return
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {conn.name}.{name}")
        self._print(_format_describe_with_name(tool, display_name=f"{conn.name}.{name}"))

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
            return

        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)  OR use: describe-json <server>.<tool>")
            return
        res = await conn.session.list_tools()
        tool = next((t for t in (res.tools or []) if t.name == name), None)
        if not tool:
            raise ValueError(f"tool not found: {conn.name}.{name}")
        self._print(_dump(tool))

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        # server.tool => one-off connection, do not keep server running.
        if server:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)
                # Reuse the same printing logic below by shadowing `conn`
                pass
        else:
            try:
                conn = self._require_conn()
            except RuntimeError:
                self._print("Not connected. Run: connect <server>  (try: servers)  OR use: call <server>.<tool> {...}")
                return
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if server:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)
                self._print(_dump(result))
            return

        try:
            conn = self._require_conn()
        except RuntimeError:
            self._print("Not connected. Run: connect <server>  (try: servers)  OR use: call-json <server>.<tool> {...}")
            return
        args = _read_json_arg(json_arg)
        args = self._maybe_inject_save_mongo(conn, name, args)
        result = await conn.session.call_tool(name=name, arguments=args)
        self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        self._history_save()
        return 0



```

```markdown
# pentest-cli

Interactive terminal CLI for calling MCP tools over **stdio** using a local `mcp.json`.

## Install (shared venv)

From `Standalone_Build/`:

```bash
source .venv/bin/activate
pip install -e ./pentest-cli
```

## Run

```bash
pentest-cli
```

## Commands

- `servers` — list configured servers from `Standalone_Build/mcp.json`
- `connect <server>` — start and connect to a server (stdio)
- `status` — show current connection
- `tools [filter]` — list tools (optional substring filter)
- `describe <tool|server.tool>` — human-friendly help for a tool (inputs + example call)
- `describe-json <tool|server.tool>` — raw tool schema (MCP JSON schema)
- `call <tool|server.tool> <json|@file>` — call a tool (prints stdout/stderr by default)
- `call-json <tool|server.tool> <json|@file>` — call a tool and print full MCP JSON response
- `mongo-use <db> <collection>` — set default db/collection for CLI Mongo queries
- `mongo-find-one <json|@file>` — run `find_one(filter)` against default db/collection
- `mongo-find <json|@file> [limit=N]` — run `find(filter).limit(N)` against default db/collection
- `quit` / `exit` — leave the shell

## Examples (pentest coordinator)

List tools:

```text
pentest> tools
pentest> tools scan
```

Describe a tool:

```text
pentest> describe nmap_scan
pentest> describe-json nmap_scan
```

Nmap scan (ports 1-1024):

```text
pentest> call nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
```

RustScan scan (ports 1-1024):

```text
pentest> call rustscan_scan {"targets":["192.168.1.1"],"ports":"1-1024"}
```

All-in-one port scanning (naabu + rustscan + nmap):

```text
pentest> call portscan_all {"targets":["192.168.1.1"],"nmap_style_args":["-p","1-1024","-sT"]}
```

Notes:
- By default, `pentest-cli` injects `save={"type":"mongo"}` for tools that support saving (unless you run with `--no-save-mongo`).
- Ensure `MONGO_URI` is set and MongoDB is running, or you’ll see `saved: failed (...)`.

## Examples (other servers)

Switch servers (you must `connect` before calling tools on that server):

```text
pentest> servers
pentest> connect shodan
```

You can also call tools **on-demand** without keeping a server connected by using `server.tool`:

```text
pentest> call shodan.shodan_filters {}
pentest> describe shodan.shodan_search
```

### Shodan

```text
pentest> tools shodan
pentest> describe shodan.shodan_search
pentest> call shodan.shodan_search {"query":"org:\"Example Corp\"","max_results":5}
```

### Searchsploit

```text
pentest> call searchsploit.searchsploit_search {"terms":["wordpress","plugin"],"case_insensitive":true}
```

### theHarvester

```text
pentest> call theharvester.theharvester_run {"domain":"example.com","sources":"all","limit":200,"start":0}
```

### WPScan

```text
pentest> call wpscan.wpscan_scan {"url":"https://example.com","enumerate":"vp,vt,cb,u","stealthy":true}
```

### SearXNG

```text
pentest> call searx.searx_search {"query":"example.com exposed admin","max_results":10}
```
## MongoDB query examples (CLI-side, via pymongo)

Set default db/collection for queries:

```text
pentest> mongo-use mcp_db results
```

Find one recent run for a tool:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

Find many (limit 5):

```text
pentest> mongo-find {"tool_name":"portscan_all"} limit=5
```

## Config and .env

`pentest-cli` uses:
- `Standalone_Build/mcp.json` for server definitions
- `Standalone_Build/.env` (auto-loaded, unless `PENTEST_CLI_NO_DOTENV` is set) for variables like `MONGO_URI`, `MONGO_DB`, `MONGO_COLLECTION`

## Config discovery

By default, `pentest-cli` auto-discovers `Standalone_Build/mcp.json` even when run outside the repo.

To force a specific config:

- `pentest-cli --config "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json"`
- or `export PENTEST_CLI_CONFIG=/path/to/mcp.json`
```

### Done — `server.tool` convenience syntax is now supported everywhere you asked

You can now run tools **without pre-connecting** (the CLI spins the server up for that single command, then shuts it down):

- **`call shodan.shodan_search {...}`**
- **`call-json shodan.shodan_search {...}`**
- **`describe shodan.shodan_search`**
- **`describe-json shodan.shodan_search`**
- **`tools` output now prints qualified names** like `shodan.shodan_search`, and `tools shodan` works as a server-scoped filter.

### What changed
- **`pentest-cli` REPL**: `Standalone_Build/pentest-cli/src/pentest_cli/repl.py`
  - Added on-demand per-command connection for `server.tool`
  - Updated `tools` to output `server.tool`
  - Updated `describe` / `describe-json` to accept `server.tool` and to render examples using the qualified name
- **Docs**: `Standalone_Build/pentest-cli/README.md`
  - Updated examples to show `server.tool` syntax

### Verified
I ran:

- `tools shodan`
- `describe shodan.shodan_filters`
- `call-json shodan.shodan_filters {}`

…and it worked end-to-end without a persistent `connect`.

---

**User**

Hmm, if I switch over to Shodan via "tools shodan" it does not appear as though I can get back to the pentest tools such as naabu_scan. Perhaps we could instead load up all of the servers (you do not need to show all of the FastMCP server log outputs), provide a listing of those servers that have been loaded prior to the prompt, and then allow all tools to just be called via <mcpname>.<toolname> without having to switch servers. And, for the scan tools, please use the prefix of "portscan" instead of "pentest" for those tools.

---

**Cursor**

Got it — right now `tools shodan` is just *filtering the list*, but because unprefixed calls/describes still depend on the “current connection”, it feels like you’re “stuck” on Shodan. I’ll shift the CLI to a **multi-server model**: it will preload all MCP servers at startup (quietly), print which ones loaded, and require/encourage `mcpname.toolname` for everything. I’ll also rename the coordinator server key from `pentest` → **`portscan`** so scans become `portscan.naabu_scan`, `portscan.nmap_scan`, etc. Next I’ll find the FastMCP env flag (or capture stderr) to suppress those banners.

```jsonc
{
  "mcpServers": {
    "portscan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["pentest_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "pdtm": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["pdtm_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "shodan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["shodan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searchsploit": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["searchsploit_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searx": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["searx_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "theharvester": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["theharvester_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "wpscan": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["wpscan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "mongo": {
      "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
      "args": ["mongo_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    }
  }
}



```

```shellscript
#!/usr/bin/env bash
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ENV_FILE="$SCRIPT_DIR/.env"

if [[ -f "$ENV_FILE" ]]; then
  set -a
  # shellcheck disable=SC1090
  source "$ENV_FILE"
  set +a
fi

PY="$SCRIPT_DIR/.venv/bin/python"
if [[ ! -x "$PY" ]]; then
  echo "Missing shared venv python at: $PY" >&2
  echo "Create it with: cd $SCRIPT_DIR && python -m venv .venv && ./.venv/bin/pip install -e <servers>" >&2
  exit 2
fi

if [[ $# -lt 1 ]]; then
  echo "Usage: $0 <python_module> [args...]" >&2
  echo "Example: $0 pentest_mcp_server.server" >&2
  exit 2
fi

MODULE="$1"
shift

LOG_DIR="$SCRIPT_DIR/logs"
mkdir -p "$LOG_DIR"
LOG_FILE="$LOG_DIR/${MODULE//./_}.stderr.log"

# MCP protocol is on stdout; FastMCP logs/banners go to stderr. We keep stderr out of
# the CLI UI by redirecting it to a per-module log file.
exec "$PY" -m "$MODULE" "$@" 2>>"$LOG_FILE"

```

```python
from __future__ import annotations

import argparse
from pathlib import Path

import anyio

from .config import find_default_mcp_json
from .repl import PentestCliRepl


def main() -> None:
    parser = argparse.ArgumentParser(prog="pentest-cli")
    parser.add_argument(
        "--config",
        default=None,
        help="Path to mcp.json (default: auto-discover from current directory; env: PENTEST_CLI_CONFIG)",
    )
    parser.add_argument(
        "--connect",
        default="",
        help="Server name to auto-connect on startup (optional). Prefer server.tool calls instead.",
    )
    parser.add_argument(
        "--no-autoload-all",
        action="store_true",
        help="Disable autoloading (starting) all servers on startup",
    )
    parser.add_argument(
        "--no-save-mongo",
        action="store_true",
        help="Disable default save={\"type\":\"mongo\"} injection for tools that support saving",
    )
    args = parser.parse_args()

    config_path = args.config or find_default_mcp_json(str(Path.cwd()))
    repl = PentestCliRepl(
        config_path=config_path,
        auto_connect=args.connect,
        default_save_mongo=(not args.no_save_mongo),
        autoload_all=(not args.no_autoload_all),
    )
    raise SystemExit(anyio.run(repl.run))


if __name__ == "__main__":
    main()



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
        autoload_all: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.conns: dict[str, ActiveConnection] = {}
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self.autoload_all = bool(autoload_all)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (supports 'server' and 'server.tool' style filtering)",
                    "  describe <tool|server.tool>       Show a human-friendly description + how to call it",
                    "  describe-json <tool|server.tool>  Show the raw MCP JSON schema for a tool",
                    "  call <tool|server.tool> <json|@file>      Call a tool (server.tool runs on-demand, no persistent connect)",
                    "  call-json <tool|server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_disconnect_all(self) -> None:
        """
        Disconnect all autoloaded servers (and the current connection, if any).
        """
        # Close current connection if it's also in the pool.
        if self.conn:
            try:
                await self.conn.close_fn()
            except Exception:
                pass
            self.conn = None

        for name in list(self.conns.keys()):
            c = self.conns.pop(name, None)
            if not c:
                continue
            try:
                await c.close_fn()
            except Exception:
                pass

    async def cmd_autoload_all(self) -> None:
        """
        Start and connect to all configured servers up-front for fast, global tool access.
        """
        loaded: list[str] = []
        failed: dict[str, str] = {}
        for name in sorted(self.servers.keys()):
            if name in self.conns:
                loaded.append(name)
                continue
            try:
                self.conns[name] = await self._open_connection(name)
                loaded.append(name)
            except Exception as e:
                failed[name] = f"{type(e).__name__}: {e}"
        self._print(_dim(f"Autoloaded servers ({len(loaded)}/{len(self.servers)}): {', '.join(loaded) if loaded else '(none)'}"))
        if failed:
            self._print(_bold(_yellow("Some servers failed to load:")))
            for k in sorted(failed.keys()):
                self._print(f"  - {k}: {failed[k]}")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # Prefer the autoloaded pool; fall back to on-demand if autoload is disabled.
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            pooled = self.conns.get(s)
            if pooled is not None:
                res = await pooled.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))
                continue
            async with self._temp_connection(s) as conn:
                res = await conn.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            self._print(f"  - {s}.{t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return

        raise ValueError("usage: describe <server>.<tool>")

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return

        raise ValueError("usage: describe-json <server>.<tool>")

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            conn = pooled
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
        else:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call-json <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(pooled, name, args)
            result = await pooled.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))
            return

        async with self._temp_connection(server) as conn:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if self.autoload_all and self.servers:
            await self.cmd_autoload_all()
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        await self.cmd_disconnect_all()
        self._history_save()
        return 0



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
        autoload_all: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.conns: dict[str, ActiveConnection] = {}
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self.autoload_all = bool(autoload_all)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (supports 'server' and 'server.tool' style filtering)",
                    "  describe <tool|server.tool>       Show a human-friendly description + how to call it",
                    "  describe-json <tool|server.tool>  Show the raw MCP JSON schema for a tool",
                    "  call <tool|server.tool> <json|@file>      Call a tool (server.tool runs on-demand, no persistent connect)",
                    "  call-json <tool|server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                    _dim("Tip: this CLI prefers qualified tool names like: portscan.naabu_scan  or  shodan.shodan_search"),
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            await self.conn.close_fn()
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_disconnect_all(self) -> None:
        """
        Disconnect all autoloaded servers (and the current connection, if any).
        """
        # Close current connection if it's also in the pool.
        if self.conn:
            try:
                await self.conn.close_fn()
            except Exception:
                pass
            self.conn = None

        for name in list(self.conns.keys()):
            c = self.conns.pop(name, None)
            if not c:
                continue
            try:
                await c.close_fn()
            except Exception:
                pass

    async def cmd_autoload_all(self) -> None:
        """
        Start and connect to all configured servers up-front for fast, global tool access.
        """
        loaded: list[str] = []
        failed: dict[str, str] = {}
        for name in sorted(self.servers.keys()):
            if name in self.conns:
                loaded.append(name)
                continue
            try:
                self.conns[name] = await self._open_connection(name)
                loaded.append(name)
            except Exception as e:
                failed[name] = f"{type(e).__name__}: {e}"
        self._print(_dim(f"Autoloaded servers ({len(loaded)}/{len(self.servers)}): {', '.join(loaded) if loaded else '(none)'}"))
        if failed:
            self._print(_bold(_yellow("Some servers failed to load:")))
            for k in sorted(failed.keys()):
                self._print(f"  - {k}: {failed[k]}")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # Prefer the autoloaded pool; fall back to on-demand if autoload is disabled.
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            pooled = self.conns.get(s)
            if pooled is not None:
                res = await pooled.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))
                continue
            async with self._temp_connection(s) as conn:
                res = await conn.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            self._print(f"  - {s}.{t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return

        raise ValueError("usage: describe <server>.<tool>")

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return

        raise ValueError("usage: describe-json <server>.<tool>")

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            conn = pooled
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
        else:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call-json <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(pooled, name, args)
            result = await pooled.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))
            return

        async with self._temp_connection(server) as conn:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if self.autoload_all and self.servers:
            await self.cmd_autoload_all()
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        await self.cmd_disconnect_all()
        self._history_save()
        return 0



```

```markdown
# pentest-cli

Interactive terminal CLI for calling MCP tools over **stdio** using a local `mcp.json`.

## Install (shared venv)

From `Standalone_Build/`:

```bash
source .venv/bin/activate
pip install -e ./pentest-cli
```

## Run

```bash
pentest-cli
```

## Commands

- `servers` — list configured servers from `Standalone_Build/mcp.json`
- `connect <server>` — start and connect to a server (stdio)
- `status` — show current connection
- `tools [filter]` — list tools (optional substring filter)
- `describe <tool|server.tool>` — human-friendly help for a tool (inputs + example call)
- `describe-json <tool|server.tool>` — raw tool schema (MCP JSON schema)
- `call <tool|server.tool> <json|@file>` — call a tool (prints stdout/stderr by default)
- `call-json <tool|server.tool> <json|@file>` — call a tool and print full MCP JSON response
- `mongo-use <db> <collection>` — set default db/collection for CLI Mongo queries
- `mongo-find-one <json|@file>` — run `find_one(filter)` against default db/collection
- `mongo-find <json|@file> [limit=N]` — run `find(filter).limit(N)` against default db/collection
- `quit` / `exit` — leave the shell

## Examples (pentest coordinator)

List tools:

```text
pentest> tools
pentest> tools scan
```

Describe a tool:

```text
pentest> describe nmap_scan
pentest> describe-json nmap_scan
```

Nmap scan (ports 1-1024):

```text
pentest> call portscan.nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
```

RustScan scan (ports 1-1024):

```text
pentest> call portscan.rustscan_scan {"targets":["192.168.1.1"],"ports":"1-1024"}
```

All-in-one port scanning (naabu + rustscan + nmap):

```text
pentest> call portscan.portscan_all {"targets":["192.168.1.1"],"nmap_style_args":["-p","1-1024","-sT"]}
```

Notes:
- By default, `pentest-cli` injects `save={"type":"mongo"}` for tools that support saving (unless you run with `--no-save-mongo`).
- Ensure `MONGO_URI` is set and MongoDB is running, or you’ll see `saved: failed (...)`.

## Examples (other servers)

Switch servers (you must `connect` before calling tools on that server):

```text
pentest> servers
pentest> connect shodan
```

You can also call tools **on-demand** without keeping a server connected by using `server.tool`:

```text
pentest> call shodan.shodan_filters {}
pentest> describe shodan.shodan_search
```

### Shodan

```text
pentest> tools shodan
pentest> describe shodan.shodan_search
pentest> call shodan.shodan_search {"query":"org:\"Example Corp\"","max_results":5}
```

### Searchsploit

```text
pentest> call searchsploit.searchsploit_search {"terms":["wordpress","plugin"],"case_insensitive":true}
```

### theHarvester

```text
pentest> call theharvester.theharvester_run {"domain":"example.com","sources":"all","limit":200,"start":0}
```

### WPScan

```text
pentest> call wpscan.wpscan_scan {"url":"https://example.com","enumerate":"vp,vt,cb,u","stealthy":true}
```

### SearXNG

```text
pentest> call searx.searx_search {"query":"example.com exposed admin","max_results":10}
```
## MongoDB query examples (CLI-side, via pymongo)

Set default db/collection for queries:

```text
pentest> mongo-use mcp_db results
```

Find one recent run for a tool:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

Find many (limit 5):

```text
pentest> mongo-find {"tool_name":"portscan_all"} limit=5
```

## Config and .env

`pentest-cli` uses:
- `Standalone_Build/mcp.json` for server definitions
- `Standalone_Build/.env` (auto-loaded, unless `PENTEST_CLI_NO_DOTENV` is set) for variables like `MONGO_URI`, `MONGO_DB`, `MONGO_COLLECTION`

## Config discovery

By default, `pentest-cli` auto-discovers `Standalone_Build/mcp.json` even when run outside the repo.

To force a specific config:

- `pentest-cli --config "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json"`
- or `export PENTEST_CLI_CONFIG=/path/to/mcp.json`
```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
        autoload_all: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.conns: dict[str, ActiveConnection] = {}
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self.autoload_all = bool(autoload_all)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools (supports 'server' and 'server.tool' style filtering)",
                    "  describe <tool|server.tool>       Show a human-friendly description + how to call it",
                    "  describe-json <tool|server.tool>  Show the raw MCP JSON schema for a tool",
                    "  call <tool|server.tool> <json|@file>      Call a tool (server.tool runs on-demand, no persistent connect)",
                    "  call-json <tool|server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                    _dim("Tip: this CLI prefers qualified tool names like: portscan.naabu_scan  or  shodan.shodan_search"),
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            try:
                await self.conn.close_fn()
            except BaseException:
                # Closing stdio transports can raise cancellation-related exceptions; ignore on shutdown.
                pass
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_disconnect_all(self) -> None:
        """
        Disconnect all autoloaded servers (and the current connection, if any).
        """
        # Close current connection if it's also in the pool.
        if self.conn:
            try:
                await self.conn.close_fn()
            except BaseException:
                pass
            self.conn = None

        for name in list(self.conns.keys()):
            c = self.conns.pop(name, None)
            if not c:
                continue
            try:
                await c.close_fn()
            except BaseException:
                pass

    async def cmd_autoload_all(self) -> None:
        """
        Start and connect to all configured servers up-front for fast, global tool access.
        """
        loaded: list[str] = []
        failed: dict[str, str] = {}
        for name in sorted(self.servers.keys()):
            if name in self.conns:
                loaded.append(name)
                continue
            try:
                self.conns[name] = await self._open_connection(name)
                loaded.append(name)
            except Exception as e:
                failed[name] = f"{type(e).__name__}: {e}"
        self._print(_dim(f"Autoloaded servers ({len(loaded)}/{len(self.servers)}): {', '.join(loaded) if loaded else '(none)'}"))
        if failed:
            self._print(_bold(_yellow("Some servers failed to load:")))
            for k in sorted(failed.keys()):
                self._print(f"  - {k}: {failed[k]}")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # Prefer the autoloaded pool; fall back to on-demand if autoload is disabled.
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            pooled = self.conns.get(s)
            if pooled is not None:
                res = await pooled.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))
                continue
            async with self._temp_connection(s) as conn:
                res = await conn.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            self._print(f"  - {s}.{t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return

        raise ValueError("usage: describe <server>.<tool>")

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return

        raise ValueError("usage: describe-json <server>.<tool>")

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            conn = pooled
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
        else:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call-json <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(pooled, name, args)
            result = await pooled.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))
            return

        async with self._temp_connection(server) as conn:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if self.autoload_all and self.servers:
            await self.cmd_autoload_all()
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        await self.cmd_disconnect_all()
        self._history_save()
        return 0



```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
        autoload_all: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.conns: dict[str, ActiveConnection] = {}
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self.autoload_all = bool(autoload_all)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools across all servers (qualified as server.tool)",
                    "  describe <server.tool>            Show a human-friendly description + how to call it",
                    "  describe-json <server.tool>       Show the raw MCP JSON schema for a tool",
                    "  call <server.tool> <json|@file>   Call a tool (servers are autoloaded by default)",
                    "  call-json <server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                    _dim("Tip: this CLI prefers qualified tool names like: portscan.naabu_scan  or  shodan.shodan_search"),
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            try:
                await self.conn.close_fn()
            except BaseException:
                # Closing stdio transports can raise cancellation-related exceptions; ignore on shutdown.
                pass
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_disconnect_all(self) -> None:
        """
        Disconnect all autoloaded servers (and the current connection, if any).
        """
        # Close current connection if it's also in the pool.
        if self.conn:
            try:
                await self.conn.close_fn()
            except BaseException:
                pass
            self.conn = None

        for name in list(self.conns.keys()):
            c = self.conns.pop(name, None)
            if not c:
                continue
            try:
                await c.close_fn()
            except BaseException:
                pass

    async def cmd_autoload_all(self) -> None:
        """
        Start and connect to all configured servers up-front for fast, global tool access.
        """
        loaded: list[str] = []
        failed: dict[str, str] = {}
        for name in sorted(self.servers.keys()):
            if name in self.conns:
                loaded.append(name)
                continue
            try:
                self.conns[name] = await self._open_connection(name)
                loaded.append(name)
            except Exception as e:
                failed[name] = f"{type(e).__name__}: {e}"
        self._print(_dim(f"Autoloaded servers ({len(loaded)}/{len(self.servers)}): {', '.join(loaded) if loaded else '(none)'}"))
        if failed:
            self._print(_bold(_yellow("Some servers failed to load:")))
            for k in sorted(failed.keys()):
                self._print(f"  - {k}: {failed[k]}")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # Prefer the autoloaded pool; fall back to on-demand if autoload is disabled.
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            pooled = self.conns.get(s)
            if pooled is not None:
                res = await pooled.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))
                continue
            async with self._temp_connection(s) as conn:
                res = await conn.session.list_tools()
                for t in (res.tools or []):
                    items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            self._print(f"  - {s}.{t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return

        raise ValueError("usage: describe <server>.<tool>")

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return

        raise ValueError("usage: describe-json <server>.<tool>")

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            conn = pooled
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
        else:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call-json <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(pooled, name, args)
            result = await pooled.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))
            return

        async with self._temp_connection(server) as conn:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if self.autoload_all and self.servers:
            await self.cmd_autoload_all()
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        await self.cmd_disconnect_all()
        self._history_save()
        return 0



```

```markdown
# pentest-cli

Interactive terminal CLI for calling MCP tools over **stdio** using a local `mcp.json`.

## Install (shared venv)

From `Standalone_Build/`:

```bash
source .venv/bin/activate
pip install -e ./pentest-cli
```

## Run

```bash
pentest-cli
```

## Commands

- `servers` — list configured servers from `Standalone_Build/mcp.json`
- `connect <server>` — start and connect to a server (stdio)
- `status` — show current connection
- `tools [filter]` — list tools (optional substring filter)
- `describe <server.tool>` — human-friendly help for a tool (inputs + example call)
- `describe-json <server.tool>` — raw tool schema (MCP JSON schema)
- `call <server.tool> <json|@file>` — call a tool (prints stdout/stderr by default)
- `call-json <server.tool> <json|@file>` — call a tool and print full MCP JSON response
- `mongo-use <db> <collection>` — set default db/collection for CLI Mongo queries
- `mongo-find-one <json|@file>` — run `find_one(filter)` against default db/collection
- `mongo-find <json|@file> [limit=N]` — run `find(filter).limit(N)` against default db/collection
- `quit` / `exit` — leave the shell

## Examples (portscan coordinator)

List tools:

```text
pentest> tools
pentest> tools scan
```

Describe a tool:

```text
pentest> describe portscan.nmap_scan
pentest> describe-json portscan.nmap_scan
```

Nmap scan (ports 1-1024):

```text
pentest> call portscan.nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
```

RustScan scan (ports 1-1024):

```text
pentest> call portscan.rustscan_scan {"targets":["192.168.1.1"],"ports":"1-1024"}
```

All-in-one port scanning (naabu + rustscan + nmap):

```text
pentest> call portscan.portscan_all {"targets":["192.168.1.1"],"nmap_style_args":["-p","1-1024","-sT"]}
```

Notes:
- By default, `pentest-cli` injects `save={"type":"mongo"}` for tools that support saving (unless you run with `--no-save-mongo`).
- Ensure `MONGO_URI` is set and MongoDB is running, or you’ll see `saved: failed (...)`.

## Examples (other servers)

Switch servers (you must `connect` before calling tools on that server):

```text
pentest> servers
pentest> connect shodan
```

You can also call tools **on-demand** without keeping a server connected by using `server.tool`:

```text
pentest> call shodan.shodan_filters {}
pentest> describe shodan.shodan_search
```

### Shodan

```text
pentest> tools shodan
pentest> describe shodan.shodan_search
pentest> call shodan.shodan_search {"query":"org:\"Example Corp\"","max_results":5}
```

### Searchsploit

```text
pentest> call searchsploit.searchsploit_search {"terms":["wordpress","plugin"],"case_insensitive":true}
```

### theHarvester

```text
pentest> call theharvester.theharvester_run {"domain":"example.com","sources":"all","limit":200,"start":0}
```

### WPScan

```text
pentest> call wpscan.wpscan_scan {"url":"https://example.com","enumerate":"vp,vt,cb,u","stealthy":true}
```

### SearXNG

```text
pentest> call searx.searx_search {"query":"example.com exposed admin","max_results":10}
```
## MongoDB query examples (CLI-side, via pymongo)

Set default db/collection for queries:

```text
pentest> mongo-use mcp_db results
```

Find one recent run for a tool:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

Find many (limit 5):

```text
pentest> mongo-find {"tool_name":"portscan_all"} limit=5
```

## Config and .env

`pentest-cli` uses:
- `Standalone_Build/mcp.json` for server definitions
- `Standalone_Build/.env` (auto-loaded, unless `PENTEST_CLI_NO_DOTENV` is set) for variables like `MONGO_URI`, `MONGO_DB`, `MONGO_COLLECTION`

## Config discovery

By default, `pentest-cli` auto-discovers `Standalone_Build/mcp.json` even when run outside the repo.

To force a specific config:

- `pentest-cli --config "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json"`
- or `export PENTEST_CLI_CONFIG=/path/to/mcp.json`
```

```markdown
*** Begin Patch
*** Update File: Standalone_Build/README.md
@@
-    "pentest": {
+    "portscan": {
       "command": "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/run-mcp-stdio.sh",
       "args": ["pentest_mcp_server.server"],
       "env": { "MCP_TRANSPORT": "stdio" }
     },
*** End Patch
```

```markdown
# Standalone_Build (local / terminal MCP servers)

`Standalone_Build/` is the **local-first** (non-Podman) version of the MCP servers in this repo.

- The original Podman servers (e.g. `portscan-mcp-server/`) are kept intact.
- The standalone copies live here and are safe to modify.
- Default transport is **stdio** so Cursor can launch them as **command MCP servers**.

## Quickstart (recommended)

### 1) Install required host binaries (per tool)

You must install the underlying CLI tools on your host, or set `*_BIN` env vars to point at them.

**Port scanning (coordinator):**
- `rustscan` (or `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or `NMAP_BIN=/path/to/nmap`)
- `naabu` (or `NAABU_BIN=/path/to/naabu`)

Other standalone servers in this directory have their own host dependencies (WPScan, theHarvester, Searchsploit, etc.).

### 2) Create a single shared Python venv (recommended) and install all servers

Each server directory here is a standalone Python package with a `pyproject.toml`, but you can (and should) run them all from a **single shared venv** to keep Cursor config simple.

Create the shared venv at `Standalone_Build/.venv` and install all servers into it:

```bash
cd "Standalone_Build"
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e ./pentest-mcp-server \
            -e ./portscan-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### 3) Run (stdio)

From inside `Standalone_Build/` (venv active):

```bash
python -m pentest_mcp_server.server
```

## Cursor MCP configuration (stdio command server)

Cursor uses stdio “command” MCP servers. A typical `.cursor/mcp.json` entry looks like:

```json
{
  "mcpServers": {
    "portscan": {
      "command": "python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
```

Notes:
- This assumes `pentest-mcp-server` was installed into the Python environment Cursor will use to launch the command.
- If you prefer, you can set `command` to an absolute path to the venv Python (recommended for reliability).



```

Yep — updated to the model you described.

### What changed
- **All servers are now autoloaded at startup** (kept running), and the CLI prints a **single “Autoloaded servers …”** line before the first prompt.
- **FastMCP banners/log spam is suppressed**: `Standalone_Build/run-mcp-stdio.sh` now redirects server **stderr** to `Standalone_Build/logs/<module>.stderr.log` instead of the terminal.
- **All tool usage is now “global” and qualified**:
  - `tools` lists everything as `mcpname.toolname`
  - `describe`, `describe-json`, `call`, `call-json` all expect `mcpname.toolname`
- **Scan tools are now under `portscan.*`**:
  - `Standalone_Build/mcp.json` renamed the coordinator server key from `pentest` → **`portscan`**
  - So you do: `call portscan.naabu_scan {...}` / `call portscan.nmap_scan {...}` / `call portscan.portscan_all {...}`

### Example
```text
pentest> tools portscan
pentest> describe portscan.naabu_scan
pentest> call portscan.nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
pentest> call shodan.shodan_search {"query":"ssl:true","max_results":5}
```

If you want, I can also add a `status` view that shows **all** loaded servers + whether each is healthy.

```plaintext
pentest> tools portscan
pentest> describe portscan.naabu_scan
pentest> call portscan.nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
pentest> call shodan.shodan_search {"query":"ssl:true","max_results":5}
```

---

**User**

When running the "tools" function, you do not need to include the .list_tools nor .describe_tool for each of the servers - it is implied that each of the servers have .list_tools and .describe_tool

---

**Cursor**

Plan: I’ll update `pentest-cli`’s `tools` listing to automatically hide the ubiquitous helper tools (`list_tools`, `describe_tool`) from every server so the output is just the “real” capabilities. Then I’ll reinstall the CLI and verify `tools shodan` / `tools portscan` output looks clean.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
        autoload_all: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.conns: dict[str, ActiveConnection] = {}
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self.autoload_all = bool(autoload_all)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools across all servers (qualified as server.tool)",
                    "  describe <server.tool>            Show a human-friendly description + how to call it",
                    "  describe-json <server.tool>       Show the raw MCP JSON schema for a tool",
                    "  call <server.tool> <json|@file>   Call a tool (servers are autoloaded by default)",
                    "  call-json <server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                    _dim("Tip: this CLI prefers qualified tool names like: portscan.naabu_scan  or  shodan.shodan_search"),
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            try:
                await self.conn.close_fn()
            except BaseException:
                # Closing stdio transports can raise cancellation-related exceptions; ignore on shutdown.
                pass
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_disconnect_all(self) -> None:
        """
        Disconnect all autoloaded servers (and the current connection, if any).
        """
        # Close current connection if it's also in the pool.
        if self.conn:
            try:
                await self.conn.close_fn()
            except BaseException:
                pass
            self.conn = None

        for name in list(self.conns.keys()):
            c = self.conns.pop(name, None)
            if not c:
                continue
            try:
                await c.close_fn()
            except BaseException:
                pass

    async def cmd_autoload_all(self) -> None:
        """
        Start and connect to all configured servers up-front for fast, global tool access.
        """
        loaded: list[str] = []
        failed: dict[str, str] = {}
        for name in sorted(self.servers.keys()):
            if name in self.conns:
                loaded.append(name)
                continue
            try:
                self.conns[name] = await self._open_connection(name)
                loaded.append(name)
            except Exception as e:
                failed[name] = f"{type(e).__name__}: {e}"
        self._print(_dim(f"Autoloaded servers ({len(loaded)}/{len(self.servers)}): {', '.join(loaded) if loaded else '(none)'}"))
        if failed:
            self._print(_bold(_yellow("Some servers failed to load:")))
            for k in sorted(failed.keys()):
                self._print(f"  - {k}: {failed[k]}")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # Prefer the autoloaded pool; fall back to on-demand if autoload is disabled.
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        hidden_tool_names = {"list_tools", "describe_tool"}
        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            pooled = self.conns.get(s)
            if pooled is not None:
                res = await pooled.session.list_tools()
                for t in (res.tools or []):
                    if getattr(t, "name", None) in hidden_tool_names:
                        continue
                    items.append((s, t))
                continue
            async with self._temp_connection(s) as conn:
                res = await conn.session.list_tools()
                for t in (res.tools or []):
                    if getattr(t, "name", None) in hidden_tool_names:
                        continue
                    items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            self._print(f"  - {s}.{t.name}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return

        raise ValueError("usage: describe <server>.<tool>")

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return

        raise ValueError("usage: describe-json <server>.<tool>")

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            conn = pooled
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
        else:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call-json <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(pooled, name, args)
            result = await pooled.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))
            return

        async with self._temp_connection(server) as conn:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if self.autoload_all and self.servers:
            await self.cmd_autoload_all()
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        await self.cmd_disconnect_all()
        self._history_save()
        return 0



```

Updated: `tools` now **hides** `list_tools` and `describe_tool` for every server.

- Implemented in `Standalone_Build/pentest-cli/src/pentest_cli/repl.py` (`cmd_tools`)
- Verified output:
  - `tools shodan` now shows only `shodan.shodan_search` and `shodan.shodan_filters`
  - `tools portscan` now shows only the scan tools (no `.list_tools` / `.describe_tool`)

---

**User**

Can you color code each of the servers a different color (or at least alternating 3 or 4 colors for each tool that is listed via "tools" - it is difficult to see the different server and tool name - but please only color the server.tool_name and not the entire line

---

**Cursor**

Plan: I’ll add a deterministic color palette for server names and use it in `tools` so only the `server.tool` part is colorized (description stays plain). Then I’ll reinstall the CLI and show a quick `tools` output to confirm readability.

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _color_for_server(server: str) -> str:
    """
    Deterministic ANSI color code for a given server name (cycles a small palette).
    Only used when stdout supports color.
    """
    palette = ["36", "35", "34", "32"]  # cyan, magenta, blue, green
    s = (server or "").strip().lower()
    # Stable hash (avoid Python's randomized hash()).
    h = 0
    for ch in s:
        h = (h * 131 + ord(ch)) & 0xFFFFFFFF
    return palette[h % len(palette)]


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
        autoload_all: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.conns: dict[str, ActiveConnection] = {}
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self.autoload_all = bool(autoload_all)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools across all servers (qualified as server.tool)",
                    "  describe <server.tool>            Show a human-friendly description + how to call it",
                    "  describe-json <server.tool>       Show the raw MCP JSON schema for a tool",
                    "  call <server.tool> <json|@file>   Call a tool (servers are autoloaded by default)",
                    "  call-json <server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                    _dim("Tip: this CLI prefers qualified tool names like: portscan.naabu_scan  or  shodan.shodan_search"),
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cfg.command, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            try:
                await self.conn.close_fn()
            except BaseException:
                # Closing stdio transports can raise cancellation-related exceptions; ignore on shutdown.
                pass
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_disconnect_all(self) -> None:
        """
        Disconnect all autoloaded servers (and the current connection, if any).
        """
        # Close current connection if it's also in the pool.
        if self.conn:
            try:
                await self.conn.close_fn()
            except BaseException:
                pass
            self.conn = None

        for name in list(self.conns.keys()):
            c = self.conns.pop(name, None)
            if not c:
                continue
            try:
                await c.close_fn()
            except BaseException:
                pass

    async def cmd_autoload_all(self) -> None:
        """
        Start and connect to all configured servers up-front for fast, global tool access.
        """
        loaded: list[str] = []
        failed: dict[str, str] = {}
        for name in sorted(self.servers.keys()):
            if name in self.conns:
                loaded.append(name)
                continue
            try:
                self.conns[name] = await self._open_connection(name)
                loaded.append(name)
            except Exception as e:
                failed[name] = f"{type(e).__name__}: {e}"
        self._print(_dim(f"Autoloaded servers ({len(loaded)}/{len(self.servers)}): {', '.join(loaded) if loaded else '(none)'}"))
        if failed:
            self._print(_bold(_yellow("Some servers failed to load:")))
            for k in sorted(failed.keys()):
                self._print(f"  - {k}: {failed[k]}")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # Prefer the autoloaded pool; fall back to on-demand if autoload is disabled.
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        hidden_tool_names = {"list_tools", "describe_tool"}
        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            pooled = self.conns.get(s)
            if pooled is not None:
                res = await pooled.session.list_tools()
                for t in (res.tools or []):
                    if getattr(t, "name", None) in hidden_tool_names:
                        continue
                    items.append((s, t))
                continue
            async with self._temp_connection(s) as conn:
                res = await conn.session.list_tools()
                for t in (res.tools or []):
                    if getattr(t, "name", None) in hidden_tool_names:
                        continue
                    items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            qualified = f"{s}.{t.name}"
            qualified_colored = _c(qualified, _color_for_server(s))
            self._print(f"  - {qualified_colored}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return

        raise ValueError("usage: describe <server>.<tool>")

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return

        raise ValueError("usage: describe-json <server>.<tool>")

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            conn = pooled
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
        else:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call-json <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(pooled, name, args)
            result = await pooled.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))
            return

        async with self._temp_connection(server) as conn:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if self.autoload_all and self.servers:
            await self.cmd_autoload_all()
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        await self.cmd_disconnect_all()
        self._history_save()
        return 0



```

Done.

- In `pentest-cli`, the `tools` output now **colorizes only the `server.tool` portion** (not the description), using a deterministic 4‑color palette so each server is consistently colored.
- Implemented in: `Standalone_Build/pentest-cli/src/pentest_cli/repl.py` (`cmd_tools`)

Note: in the captured output above you won’t see colors because it’s not a true interactive TTY, but in your normal terminal it will render properly.

---

**User**

Can you please ensure all documentation is up-to-date with the latest changes?

---

**Cursor**

Plan: I’ll scan all docs under `Standalone_Build/` for any stale references (old `pentest` server name, old CLI behavior, old examples), then update `Standalone_Build/README.md`, `Standalone_Build/pentest-cli/README.md`, and `Standalone_Build/pentest-mcp-server/README.md` to match the current “autoload-all + server.tool everywhere + portscan prefix + quiet logs” behavior. After that I’ll do a quick grep to confirm there are no outdated snippets left.

```markdown
# pentest-cli

Interactive terminal CLI for calling MCP tools over **stdio** using a local `mcp.json`.

## Install (shared venv)

From `Standalone_Build/`:

```bash
source .venv/bin/activate
pip install -e ./pentest-cli
```

## Run

```bash
pentest-cli
```

## Startup behavior

- By default, `pentest-cli` **autoloads (starts) all MCP servers** from `Standalone_Build/mcp.json` so all tools are immediately available.
- To disable autoloading (start servers only when you explicitly `connect`), run: `pentest-cli --no-autoload-all`
- Server stderr logs (FastMCP banners, logs, etc.) are redirected to: `Standalone_Build/logs/*.stderr.log`

## Commands

- `servers` — list configured servers from `Standalone_Build/mcp.json`
- `connect <server>` — connect to a server (optional; autoload already connects everything by default)
- `status` — show current connection (mostly useful when using `connect`)
- `tools [filter]` — list tools across all servers (shows `server.tool` and hides `list_tools`/`describe_tool`)
- `describe <server.tool>` — human-friendly help for a tool (inputs + example call)
- `describe-json <server.tool>` — raw tool schema (MCP JSON schema)
- `call <server.tool> <json|@file>` — call a tool (prints stdout/stderr by default)
- `call-json <server.tool> <json|@file>` — call a tool and print full MCP JSON response
- `mongo-use <db> <collection>` — set default db/collection for CLI Mongo queries
- `mongo-find-one <json|@file>` — run `find_one(filter)` against default db/collection
- `mongo-find <json|@file> [limit=N]` — run `find(filter).limit(N)` against default db/collection
- `quit` / `exit` — leave the shell

## Examples (portscan coordinator)

List tools:

```text
pentest> tools
pentest> tools scan
```

Describe a tool:

```text
pentest> describe portscan.nmap_scan
pentest> describe-json portscan.nmap_scan
```

Nmap scan (ports 1-1024):

```text
pentest> call portscan.nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
```

RustScan scan (ports 1-1024):

```text
pentest> call portscan.rustscan_scan {"targets":["192.168.1.1"],"ports":"1-1024"}
```

All-in-one port scanning (naabu + rustscan + nmap):

```text
pentest> call portscan.portscan_all {"targets":["192.168.1.1"],"nmap_style_args":["-p","1-1024","-sT"]}
```

Notes:
- By default, `pentest-cli` injects `save={"type":"mongo"}` for tools that support saving (unless you run with `--no-save-mongo`).
- Ensure `MONGO_URI` is set and MongoDB is running, or you’ll see `saved: failed (...)`.

## Examples (other servers)

All tools are called the same way: `server.tool`.

### Shodan

```text
pentest> tools shodan
pentest> describe shodan.shodan_search
pentest> call shodan.shodan_search {"query":"org:\"Example Corp\"","max_results":5}
```

### Searchsploit

```text
pentest> call searchsploit.searchsploit_search {"terms":["wordpress","plugin"],"case_insensitive":true}
```

### theHarvester

```text
pentest> call theharvester.theharvester_run {"domain":"example.com","sources":"all","limit":200,"start":0}
```

### WPScan

```text
pentest> call wpscan.wpscan_scan {"url":"https://example.com","enumerate":"vp,vt,cb,u","stealthy":true}
```

### SearXNG

```text
pentest> call searx.searx_search {"query":"example.com exposed admin","max_results":10}
```
## MongoDB query examples (CLI-side, via pymongo)

Set default db/collection for queries:

```text
pentest> mongo-use mcp_db results
```

Find one recent run for a tool:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

Find many (limit 5):

```text
pentest> mongo-find {"tool_name":"portscan_all"} limit=5
```

## Config and .env

`pentest-cli` uses:
- `Standalone_Build/mcp.json` for server definitions
- `Standalone_Build/.env` (auto-loaded, unless `PENTEST_CLI_NO_DOTENV` is set) for variables like `MONGO_URI`, `MONGO_DB`, `MONGO_COLLECTION`

## Config discovery

By default, `pentest-cli` auto-discovers `Standalone_Build/mcp.json` even when run outside the repo.

To force a specific config:

- `pentest-cli --config "/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/mcp.json"`
- or `export PENTEST_CLI_CONFIG=/path/to/mcp.json`
```

```markdown
# Standalone_Build (local / terminal MCP servers)

`Standalone_Build/` is the **local-first** (non-Podman) version of the MCP servers in this repo.

- The original Podman servers (e.g. `portscan-mcp-server/`) are kept intact.
- The standalone copies live here and are safe to modify.
- Default transport is **stdio** so Cursor can launch them as **command MCP servers**.

## Quickstart (recommended)

### 1) Install required host binaries (per tool)

You must install the underlying CLI tools on your host, or set `*_BIN` env vars to point at them.

**Port scanning (coordinator):**
- `rustscan` (or `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or `NMAP_BIN=/path/to/nmap`)
- `naabu` (or `NAABU_BIN=/path/to/naabu`)

Other standalone servers in this directory have their own host dependencies (WPScan, theHarvester, Searchsploit, etc.).

### 2) Create a single shared Python venv (recommended) and install all servers

Each server directory here is a standalone Python package with a `pyproject.toml`, but you can (and should) run them all from a **single shared venv** to keep Cursor config simple.

Create the shared venv at `Standalone_Build/.venv` and install all servers into it:

```bash
cd "Standalone_Build"
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e ./pentest-mcp-server \
            -e ./portscan-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server \
            -e ./pentest-cli
```

### 3) Run (recommended: `pentest-cli`)

From inside `Standalone_Build/` (venv active), start the interactive CLI:

```bash
pentest-cli
```

Notes:
- The CLI autoloads all servers from `Standalone_Build/mcp.json` so you can call tools as `server.tool` (for example `portscan.nmap_scan` or `shodan.shodan_search`).
- FastMCP banners/logs are written to `Standalone_Build/logs/*.stderr.log` (so the CLI stays readable).

## Cursor MCP configuration (stdio command server)

Cursor uses stdio “command” MCP servers. A typical `.cursor/mcp.json` entry looks like:

```json
{
  "mcpServers": {
    "portscan": {
      "command": "python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
```

Notes:
- This assumes `pentest-mcp-server` was installed into the Python environment Cursor will use to launch the command.
- If you prefer, you can set `command` to an absolute path to the venv Python (recommended for reliability).



```

```markdown
# pentest-mcp-server (Standalone coordinator, stdio-first)

This is a **standalone** MCP server (Python + FastMCP) intended to be run locally via **stdio** (Cursor command servers).

It exposes a **spawn-on-demand** port scanning toolset (RustScan / Nmap / Naabu) by invoking the underlying binaries as subprocesses (no shell).

## Compatibility (tool names)

The coordinator intentionally exports **the same tool names** as `Standalone_Build/portscan-mcp-server` so an AI agent can call them consistently:

- `naabu_scan`, `naabu_scan_raw`
- `rustscan_scan`, `rustscan_scan_raw`
- `nmap_scan`, `nmap_scan_raw`
- `portscan_all`

It also exports the standard introspection tools:

- `list_tools`
- `describe_tool`

## Naming in `Standalone_Build/mcp.json`

In the standalone CLI config (`Standalone_Build/mcp.json`) this server is registered under the MCP name:

- **`portscan`**

So from `pentest-cli`, you call tools like:

- `call portscan.naabu_scan {...}`
- `call portscan.nmap_scan {...}`
- `call portscan.portscan_all {...}`

(`pentest-cli` hides `list_tools` / `describe_tool` in its `tools` output, but they still exist.)

## Result persistence (MongoDB)

These tools support `save={"type":"mongo"}` and include parsed summaries where available:

- `naabu_scan`: best-effort JSONL sample parsing (`result.jsonl`)
- `nmap_scan`: best-effort open-port table parsing (`result.parsed.ports`)
- `rustscan_scan`: best-effort open-port parsing (`result.parsed.open_ports`)
- `portscan_all`: includes per-subtool parsed summaries and supports `save`

## Transport

- Default: `MCP_TRANSPORT=stdio` (Cursor-friendly)
- Optional: `MCP_TRANSPORT=streamable-http` for HTTP clients (set `MCP_HOST`, `MCP_PORT`)

## Required host binaries

- `rustscan` (or set `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or set `NMAP_BIN=/path/to/nmap`)
- `naabu` (or set `NAABU_BIN=/path/to/naabu`)

## Local run (stdio)

From this directory (in a venv):

```bash
python -m pentest_mcp_server.server
```

## Tools

- `naabu_scan`, `naabu_scan_raw`
- `rustscan_scan`, `rustscan_scan_raw`
- `nmap_scan`, `nmap_scan_raw`
- `portscan_all`
- `list_tools`, `describe_tool`



```

```markdown
# portscan-mcp-server (reference implementation)

This directory contains a **reference / legacy** implementation of port scanning tools.

In `Standalone_Build/mcp.json`, the default scan toolset is provided by the **coordinator** server:

- `Standalone_Build/pentest-mcp-server` (MCP name: **`portscan`**)

The coordinator exports the same tool names (`naabu_scan`, `nmap_scan`, `rustscan_scan`, `portscan_all`) and is what `pentest-cli` uses by default.

## Tools (names)

- `naabu_scan`, `naabu_scan_raw`
- `rustscan_scan`, `rustscan_scan_raw`
- `nmap_scan`, `nmap_scan_raw`
- `portscan_all`

## Standalone usage

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh pentest_mcp_server.server
```

Then use `pentest-cli`:

```text
pentest> call portscan.nmap_scan {"targets":["192.168.1.1"],"args":["-p","1-1024","-sT"],"force_unprivileged":true}
```

## Podman

Podman/container-specific docs for the original servers are intentionally kept outside the standalone workflow. See `Standalone_Build/README.podman-reference.md`.

```

```markdown
# shodan-mcp-server (Standalone, stdio-first)

This is a **standalone** MCP server (Python + **FastMCP**) that lets you search Shodan using the official `shodan` Python library.

In `Standalone_Build`, it is intended to be launched via **stdio** and called from `pentest-cli` as `shodan.<tool>`.

## Examples

```
Run shodan_search for http.html:"secureauth" and show me the results.
```

## Tools

- `shodan_search`: run a Shodan search query (returns at most **25** results + total count)
- `shodan_filters`: list known Shodan filters, or describe one filter by name

## Configuration

- Set `SHODAN_API_KEY` in `Standalone_Build/.env`

## Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh shodan_mcp_server.server
```

## Call from `pentest-cli`

```text
pentest> call shodan.shodan_search {"query":"ssl:true","max_results":5}
pentest> call shodan.shodan_filters {}
```



```

```markdown
# searchsploit-mcp-server (Standalone, stdio-first)

This MCP server exposes Searchsploit/ExploitDB searching and local exploit source inspection.

In `Standalone_Build`, it is intended to be launched via **stdio** and called from `pentest-cli` as `searchsploit.<tool>`.

## Requirements

- A local ExploitDB/Searchsploit install must be present on the host (the MCP server wraps the local binaries/repos).

## Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh searchsploit_mcp_server.server
```

## Call from `pentest-cli`

```text
pentest> call searchsploit.searchsploit_search {"terms":["wordpress","plugin"],"case_insensitive":true}
pentest> call searchsploit.searchsploit_read_exploit {"relative_path":"exploits/php/webapps/xxxx.txt","max_bytes":200000}
```

## Podman

Podman/container-specific docs for the original servers are intentionally kept outside the standalone workflow. See `Standalone_Build/README.podman-reference.md`.



```

```markdown
# searx-mcp-server (Standalone, stdio-first)

Standalone MCP server wrapper for SearXNG queries.

In `Standalone_Build`, it is intended to be launched via **stdio** and called from `pentest-cli` as `searx.<tool>`.

## Configuration

Environment variables (optional):

- **`SEARXNG_URL`**: Internal URL used by MCP to reach SearXNG (default `http://127.0.0.1:8080`).
- **`SEARXNG_SETTINGS_PATH`**: Where the container writes/reads its runtime `settings.yml` (default `/tmp/searxng-settings.yml`).
- **`SEARXNG_SECRET_KEY`**: If set, used as `server.secret_key` in the runtime `settings.yml`.
  - If not set, a secure random key is generated at container start.
- **`SEARX_DEFAULT_ENGINES`**: Comma-separated default engines when `engines` is not provided to `searx_search` (default `startpage,qwant,swisscows`).
- **`SEARX_TIMEOUT_LIMIT_SECONDS`**: Default SearXNG `timeout_limit` passed to `/search` to prevent long hangs when engines are blocked (default `8`).
- **`SEARXNG_WORKERS`**: Gunicorn worker count for SearXNG (default `1`).  
  - If you set this >1, SearXNG may fail to boot with `sqlite3.OperationalError: database is locked` during plugin/cache initialization.
- **`SEARX_MCP_USER_AGENT`**: User-Agent header used by the MCP client when calling the internal SearXNG `/search` endpoint.  
  - Useful if SearXNG botdetection returns `403 Forbidden` for default HTTP client user agents.
- **`SEARXNG_OUTGOING_PROXIES`**: Comma-separated list of proxy URLs for SearXNG engine outbound requests (written into `outgoing.proxies` in the runtime `settings.yml`).  
  - Example: `SEARXNG_OUTGOING_PROXIES="http://proxy:8080,socks5://proxy:1080"`

## Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh searx_mcp_server.server
```

## Call from `pentest-cli`

```text
pentest> call searx.searx_search {"query":"example.com exposed admin","max_results":10}
```

## Podman

Podman/container-specific docs for the original servers are intentionally kept outside the standalone workflow. See `Standalone_Build/README.podman-reference.md`.


```

```markdown
# theharvester-mcp-server (Standalone, stdio-first)

This is a **standalone** MCP server (Python + **FastMCP**) that exposes **theHarvester** ([`laramies/theHarvester`](https://github.com/laramies/theHarvester)) as safe, structured MCP tools.

API key setup reference: [theHarvester Installation wiki](https://github.com/laramies/theHarvester/wiki/Installation).

In `Standalone_Build`, it is intended to be launched via **stdio** and called from `pentest-cli` as `theharvester.<tool>`.

## What it provides

- `theharvester_run`: run theHarvester for a domain (sources, limit, start, etc.), return results as JSON, and write output files into the mounted host directory.
- `theharvester_version`: show theHarvester version

## Configuration

- API keys: configure via theHarvester’s standard `api-keys.yaml` locations (see upstream wiki)
- Output directory: set `HARVESTER_OUTPUT_DIR` (or `OUTPUT_DIR`) in `Standalone_Build/.env`

## Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh theharvester_mcp_server.server
```

## Call from `pentest-cli`

```text
pentest> call theharvester.theharvester_run {"domain":"example.com","sources":"all","limit":200,"start":0}
```

## Podman

Podman/container-specific docs for the original servers are intentionally kept outside the standalone workflow. See `Standalone_Build/README.podman-reference.md`.



```

```markdown
# wpscan-mcp-server (Standalone, stdio-first)

This is a **standalone** MCP server (Python + **FastMCP**) that exposes **WPScan** as safe, structured MCP tools.

- WPScan repo: [`wpscanteam/wpscan`](https://github.com/wpscanteam/wpscan)
- WPScan docs/wiki: [`WPScan User Documentation`](https://github.com/wpscanteam/wpscan/wiki/WPScan-User-Documentation)

In `Standalone_Build`, it is intended to be launched via **stdio** and called from `pentest-cli` as `wpscan.<tool>`.

## Tools

- `wpscan_scan`: run a scan against a target URL with common options
- `wpscan_version`: print WPScan version
- `wpscan_debug_binary`: show the resolved `wpscan` binary path + version
- `wpscan_scan_raw`: (optional) pass arbitrary WPScan CLI args (requires `i_acknowledge_risk=true`)

## Configuration

- Set `WPSCAN_API_TOKEN` in `Standalone_Build/.env` (optional, but recommended)

## Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh wpscan_mcp_server.server
```

## Call from `pentest-cli`

```text
pentest> call wpscan.wpscan_scan {"url":"https://example.com","enumerate":"vp,vt,cb,u","stealthy":true}
```

## Podman

Podman/container-specific docs for the original servers are intentionally kept outside the standalone workflow. See `Standalone_Build/README.podman-reference.md`.

### WPScan API token

If you have a WPScan API token, set it via env var (preferred):

- `WPSCAN_API_TOKEN`

(Per upstream docs: [`WPScan User Documentation`](https://github.com/wpscanteam/wpscan/wiki/WPScan-User-Documentation))

```

```markdown
## mongo-mcp-server

An MCP server that **queries scan results stored in MongoDB** (single DB + collection):

- **DB**: `mcp_db`
- **Collection**: `results`

Record format (written by other MCP servers):

```json
{
  "tool_name": "naabu",
  "date_run": "2025-12-25T19:56:16.651404+00:00",
  "tool_commandline": "[\"naabu\",\"-silent\",\"-json\",...]",
  "scan_target": "example.com",
  "data": { "stdout": "...", "stderr": "", "json": {} }
}
```

## Configuration

Set these in `Standalone_Build/.env`:

- `MONGO_URI` (example: `mongodb://127.0.0.1:27017/mcp_db`)
- `MONGO_DB` (default: `mcp_db`)
- `MONGO_COLLECTION` (default: `results`)

## Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh mongo_mcp_server.server
```

## Call from `pentest-cli`

```text
pentest> call mongo.mongo_stats {}
pentest> call mongo.mongo_find {"tool_name":"nmap","limit":5}
```

Note: `pentest-cli` also supports **CLI-side** Mongo queries without MCP via:

- `mongo-find-one {...}`
- `mongo-find {...} limit=N`

### Tools

- **`mongo_ping`**: verify Mongo connectivity
- **`mongo_find`**: query by tool_name / scan_target / date range
- **`mongo_get`**: fetch a record by `_id`
- **`mongo_stats`**: basic counts



```

```markdown
## pdtm-mcp-server

An MCP server that exposes **multiple ProjectDiscovery tools** (installed via **PDTM**) behind a single FastMCP server.

- PDTM repo: [projectdiscovery/pdtm](https://github.com/projectdiscovery/pdtm)
- ProjectDiscovery OSS docs: [ProjectDiscovery Open Source Tools](https://docs.projectdiscovery.io/opensource)

In `Standalone_Build`, this server is intended to be launched locally via **stdio** and called from `pentest-cli` as `pdtm.<tool>`.

### Tools exposed

- **`pd_run`**: Run a supported ProjectDiscovery tool with explicit CLI flags/options (safe mode).
- **`pd_run_raw`**: Run a supported ProjectDiscovery tool with arbitrary args (requires `i_acknowledge_risk=true`).
- **`pd_smart`**: Accept a vague intent (e.g. “find subdomains for example.com”) and choose a tool + flags.

### Cursor (MCP stdio)

Cursor MCP “command” servers communicate over **stdio**. In the standalone build, `Standalone_Build/mcp.json` already sets `MCP_TRANSPORT=stdio` and launches this server via `Standalone_Build/run-mcp-stdio.sh`.

### Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh pdtm_mcp_server.server
```

### Call from `pentest-cli`

```text
pentest> call pdtm.pd_supported_tools {}
pentest> call pdtm.pd_smart {"request":"find subdomains for example.com","domain":"example.com"}
```

### Examples

**Subdomains (explicit):**

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-d", "example.com"]
}
```

**Subdomains (smart):**

```json
{
  "request": "Please find me the subdomains for example.com"
}
```

**Save to a file in `/data/output`:**

```json
{
  "tool": "httpx",
  "args": ["-silent", "-sc", "-title"],
  "stdin_lines": ["https://example.com"],
  "save": { "type": "file", "filename": "httpx-example.json" }
}
```

**Save to MongoDB:**

```json
{
  "request": "crawl https://example.com",
  "save": { "type": "mongo", "mongo_db": "recon", "mongo_collection": "katana_runs" }
}
```

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-all", "-d", "warnermusic.com"],
  "timeout_seconds": 600,
  "save": { "type": "file" }
}

# List
{ "prefix": "warnermusic.com-2025-12-25", "recursive": true }

# Read/Download
{ "path": "warnermusic.com-2025-12-25/subfinder.json", "max_bytes": 2000000, "as_base64": false }
```

### Result persistence

- **Files**: save to `/data/output` (mount a Podman volume; recommended)
- **MongoDB**: save to a database/collection (configure via env)

### Podman run (HTTP MCP on port 4599)

Build:

```bash
podman build -t pdtm-mcp-server -f Containerfile .
```

Run (expose port 4599 and persist outputs):

```bash
podman volume create pdtm_data
podman run --rm -p 4599:4599 -v pdtm_data:/data/output pdtm-mcp-server
```

### File layout in the Podman volume (recommended)

When saving with `{"save": {"type": "file"}}`, the server writes into `OUTPUT_DIR` (default `/data/output`).

- If `save.run_dir` is not provided, the server will auto-create (or reuse) a directory named:
  - `<target>-YYYY-MM-DD` (example: `wmg.com-2025-12-25`)
- If `save.filename` is not provided, the server defaults to:
  - `<tool>.json` (example: `subfinder.json`)
- If a file name already exists, the server will **not overwrite** it; it will append:
  - `-HH_MM_SS` (and a counter if needed)

Example save:

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-d", "wmg.com"],
  "timeout_seconds": 600,
  "save": { "type": "file" }
}
```

### Browsing / downloading saved results (via MCP)

- **`pd_results_list`**: list files/dirs under `/data/output` (Podman volume)
- **`pd_results_read`**: read a file from `/data/output` (text or base64) — this is the supported “download” path
- **`pd_results_export`**: copy a file from `/data/output` into `/data/downloads` (requires a host bind-mount)

To export directly into your host `~/Downloads` folder, bind-mount it to `/data/downloads` when launching the container.

- **Via `cursor-stdio.sh`**:

```bash
PDTM_OUTPUT_VOLUME=pdtm_data PDTM_DOWNLOADS_DIR="$HOME/Downloads" ./cursor-stdio.sh
```

- **Via `mcp.json`** (example on macOS):

```json
"-v",
"/Users/pkincaid/Downloads:/data/downloads"
```

### Note on transports

- **stdio**: for Cursor (set `MCP_TRANSPORT=stdio`)
- **HTTP**: for networked use (set `MCP_TRANSPORT=streamable-http`, default in the Containerfile)

### MongoDB configuration

Set these env vars when running the container:

- `MONGO_URI` (example: `mongodb://mongo:27017`)
- `MONGO_DB` (default: `pdtm_mcp`)

### Notes / references

- PDTM is ProjectDiscovery’s tool manager: [projectdiscovery/pdtm](https://github.com/projectdiscovery/pdtm)
- General docs for ProjectDiscovery OSS tools: [ProjectDiscovery Open Source Tools](https://docs.projectdiscovery.io/opensource)
- Recon workflow inspiration (3rd-party article): `https://medium.com/@enessyibrahim/mastering-reconnaissance-with-project-discovery-99d7a21e299a`


## mcp.json

```
{
  "mcpServers": {
    "project_discovery": {
      "command": "podman",
      "args": [
        "run",
        "--rm",
        "-i",
        "-e",
        "MCP_TRANSPORT=stdio",
        "-v",
        "pdtm_data:/data/output",
        "--name",
        "pdtm-mcp-stdio",
        "pdtm-mcp-server"
      ]
    }
  }
}
```
```

```markdown
## pdtm-mcp-server

An MCP server that exposes **multiple ProjectDiscovery tools** (installed via **PDTM**) behind a single FastMCP server.

- PDTM repo: [projectdiscovery/pdtm](https://github.com/projectdiscovery/pdtm)
- ProjectDiscovery OSS docs: [ProjectDiscovery Open Source Tools](https://docs.projectdiscovery.io/opensource)

In `Standalone_Build`, this server is intended to be launched locally via **stdio** and called from `pentest-cli` as `pdtm.<tool>`.

### Tools exposed

- **`pd_run`**: Run a supported ProjectDiscovery tool with explicit CLI flags/options (safe mode).
- **`pd_run_raw`**: Run a supported ProjectDiscovery tool with arbitrary args (requires `i_acknowledge_risk=true`).
- **`pd_smart`**: Accept a vague intent (e.g. “find subdomains for example.com”) and choose a tool + flags.

### Cursor (MCP stdio)

Cursor MCP “command” servers communicate over **stdio**. In the standalone build, `Standalone_Build/mcp.json` already sets `MCP_TRANSPORT=stdio` and launches this server via `Standalone_Build/run-mcp-stdio.sh`.

### Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh pdtm_mcp_server.server
```

### Call from `pentest-cli`

```text
pentest> call pdtm.pd_supported_tools {}
pentest> call pdtm.pd_smart {"request":"find subdomains for example.com","domain":"example.com"}
```

### Examples

**Subdomains (explicit):**

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-d", "example.com"]
}
```

**Subdomains (smart):**

```json
{
  "request": "Please find me the subdomains for example.com"
}
```

**Save to a file in `/data/output`:**

```json
{
  "tool": "httpx",
  "args": ["-silent", "-sc", "-title"],
  "stdin_lines": ["https://example.com"],
  "save": { "type": "file", "filename": "httpx-example.json" }
}
```

**Save to MongoDB:**

```json
{
  "request": "crawl https://example.com",
  "save": { "type": "mongo", "mongo_db": "recon", "mongo_collection": "katana_runs" }
}
```

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-all", "-d", "warnermusic.com"],
  "timeout_seconds": 600,
  "save": { "type": "file" }
}

# List
{ "prefix": "warnermusic.com-2025-12-25", "recursive": true }

# Read/Download
{ "path": "warnermusic.com-2025-12-25/subfinder.json", "max_bytes": 2000000, "as_base64": false }
```

### Result persistence

- **Files**: save to `OUTPUT_DIR` (configure via env; in `Standalone_Build` this is typically set via `Standalone_Build/.env`)
- **MongoDB**: save to a database/collection (configure via env / `Standalone_Build/.env`)

### Podman run (reference)

Build:

```bash
podman build -t pdtm-mcp-server -f Containerfile .
```

Run (expose port 4599 and persist outputs):

```bash
podman volume create pdtm_data
podman run --rm -p 4599:4599 -v pdtm_data:/data/output pdtm-mcp-server
```

### File layout in the Podman volume (recommended)

When saving with `{"save": {"type": "file"}}`, the server writes into `OUTPUT_DIR`.

- If `save.run_dir` is not provided, the server will auto-create (or reuse) a directory named:
  - `<target>-YYYY-MM-DD` (example: `wmg.com-2025-12-25`)
- If `save.filename` is not provided, the server defaults to:
  - `<tool>.json` (example: `subfinder.json`)
- If a file name already exists, the server will **not overwrite** it; it will append:
  - `-HH_MM_SS` (and a counter if needed)

Example save:

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-d", "wmg.com"],
  "timeout_seconds": 600,
  "save": { "type": "file" }
}
```

### Browsing / downloading saved results (via MCP)

- **`pd_results_list`**: list files/dirs under `OUTPUT_DIR`
- **`pd_results_read`**: read a file from `OUTPUT_DIR` (text or base64)
- **`pd_results_export`**: copy a file from `OUTPUT_DIR` into `DOWNLOAD_DIR` (requires a host bind-mount when containerized)

To export directly into your host `~/Downloads` folder, bind-mount it to `/data/downloads` when launching the container.

- **Via `cursor-stdio.sh`**:

```bash
PDTM_OUTPUT_VOLUME=pdtm_data PDTM_DOWNLOADS_DIR="$HOME/Downloads" ./cursor-stdio.sh
```

- **Via `mcp.json`** (example on macOS):

```json
"-v",
"/Users/pkincaid/Downloads:/data/downloads"
```

### Note on transports

- **stdio**: for Cursor (set `MCP_TRANSPORT=stdio`)
- **HTTP**: for networked use (set `MCP_TRANSPORT=streamable-http`, default in the Containerfile)

### MongoDB configuration

Set these env vars when running the container:

- `MONGO_URI` (example: `mongodb://mongo:27017`)
- `MONGO_DB` (default: `pdtm_mcp`)

### Notes / references

- PDTM is ProjectDiscovery’s tool manager: [projectdiscovery/pdtm](https://github.com/projectdiscovery/pdtm)
- General docs for ProjectDiscovery OSS tools: [ProjectDiscovery Open Source Tools](https://docs.projectdiscovery.io/opensource)
- Recon workflow inspiration (3rd-party article): `https://medium.com/@enessyibrahim/mastering-reconnaissance-with-project-discovery-99d7a21e299a`


## mcp.json

```
{
  "mcpServers": {
    "project_discovery": {
      "command": "podman",
      "args": [
        "run",
        "--rm",
        "-i",
        "-e",
        "MCP_TRANSPORT=stdio",
        "-v",
        "pdtm_data:/data/output",
        "--name",
        "pdtm-mcp-stdio",
        "pdtm-mcp-server"
      ]
    }
  }
}
```
```

```markdown
# Standalone_Build (local / terminal MCP servers)

`Standalone_Build/` is the **local-first** (non-Podman) version of the MCP servers in this repo.

- The original Podman servers (at the repo root) are kept intact as read-only references.
- The standalone copies live here and are safe to modify.
- Default transport is **stdio** so Cursor can launch them as **command MCP servers**.

## Quickstart (recommended)

### 1) Install required host binaries (per tool)

You must install the underlying CLI tools on your host, or set `*_BIN` env vars to point at them.

**Port scanning (coordinator):**
- `rustscan` (or `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or `NMAP_BIN=/path/to/nmap`)
- `naabu` (or `NAABU_BIN=/path/to/naabu`)

Other standalone servers in this directory have their own host dependencies (WPScan, theHarvester, Searchsploit, etc.).

### 2) Create a single shared Python venv (recommended) and install all servers

Each server directory here is a standalone Python package with a `pyproject.toml`, but you can (and should) run them all from a **single shared venv** to keep Cursor config simple.

Create the shared venv at `Standalone_Build/.venv` and install all servers into it:

```bash
cd "Standalone_Build"
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e ./pentest-mcp-server \
            -e ./portscan-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server \
            -e ./pentest-cli
```

### 3) Run (recommended: `pentest-cli`)

From inside `Standalone_Build/` (venv active), start the interactive CLI:

```bash
pentest-cli
```

Notes:
- The CLI autoloads all servers from `Standalone_Build/mcp.json` so you can call tools as `server.tool` (for example `portscan.nmap_scan` or `shodan.shodan_search`).
- FastMCP banners/logs are written to `Standalone_Build/logs/*.stderr.log` (so the CLI stays readable).

## Cursor MCP configuration (stdio command server)

Cursor uses stdio “command” MCP servers. A typical `.cursor/mcp.json` entry looks like:

```json
{
  "mcpServers": {
    "portscan": {
      "command": "python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
```

Notes:
- This assumes `pentest-mcp-server` was installed into the Python environment Cursor will use to launch the command.
- If you prefer, you can set `command` to an absolute path to the venv Python (recommended for reliability).



```

```markdown
## pdtm-mcp-server

An MCP server that exposes **multiple ProjectDiscovery tools** (installed via **PDTM**) behind a single FastMCP server.

- PDTM repo: [projectdiscovery/pdtm](https://github.com/projectdiscovery/pdtm)
- ProjectDiscovery OSS docs: [ProjectDiscovery Open Source Tools](https://docs.projectdiscovery.io/opensource)

In `Standalone_Build`, this server is intended to be launched locally via **stdio** and called from `pentest-cli` as `pdtm.<tool>`.

### Tools exposed

- **`pd_run`**: Run a supported ProjectDiscovery tool with explicit CLI flags/options (safe mode).
- **`pd_run_raw`**: Run a supported ProjectDiscovery tool with arbitrary args (requires `i_acknowledge_risk=true`).
- **`pd_smart`**: Accept a vague intent (e.g. “find subdomains for example.com”) and choose a tool + flags.

### Cursor (MCP stdio)

Cursor MCP “command” servers communicate over **stdio**. In the standalone build, `Standalone_Build/mcp.json` already sets `MCP_TRANSPORT=stdio` and launches this server via `Standalone_Build/run-mcp-stdio.sh`.

### Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh pdtm_mcp_server.server
```

### Call from `pentest-cli`

```text
pentest> call pdtm.pd_supported_tools {}
pentest> call pdtm.pd_smart {"request":"find subdomains for example.com","domain":"example.com"}
```

### Examples

**Subdomains (explicit):**

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-d", "example.com"]
}
```

**Subdomains (smart):**

```json
{
  "request": "Please find me the subdomains for example.com"
}
```

**Save to a file in `/data/output`:**

```json
{
  "tool": "httpx",
  "args": ["-silent", "-sc", "-title"],
  "stdin_lines": ["https://example.com"],
  "save": { "type": "file", "filename": "httpx-example.json" }
}
```

**Save to MongoDB:**

```json
{
  "request": "crawl https://example.com",
  "save": { "type": "mongo", "mongo_db": "recon", "mongo_collection": "katana_runs" }
}
```

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-all", "-d", "warnermusic.com"],
  "timeout_seconds": 600,
  "save": { "type": "file" }
}

# List
{ "prefix": "warnermusic.com-2025-12-25", "recursive": true }

# Read/Download
{ "path": "warnermusic.com-2025-12-25/subfinder.json", "max_bytes": 2000000, "as_base64": false }
```

### Result persistence

- **Files**: save to `OUTPUT_DIR` (configure via env; in `Standalone_Build` this is typically set via `Standalone_Build/.env`)
- **MongoDB**: save to a database/collection (configure via env / `Standalone_Build/.env`)

### Podman run (reference)

Build:

```bash
podman build -t pdtm-mcp-server -f Containerfile .
```

Run (expose port 4599 and persist outputs):

```bash
podman volume create pdtm_data
podman run --rm -p 4599:4599 -v pdtm_data:/data/output pdtm-mcp-server
```

### File layout in `OUTPUT_DIR` (recommended)

When saving with `{"save": {"type": "file"}}`, the server writes into `OUTPUT_DIR`.

- If `save.run_dir` is not provided, the server will auto-create (or reuse) a directory named:
  - `<target>-YYYY-MM-DD` (example: `wmg.com-2025-12-25`)
- If `save.filename` is not provided, the server defaults to:
  - `<tool>.json` (example: `subfinder.json`)
- If a file name already exists, the server will **not overwrite** it; it will append:
  - `-HH_MM_SS` (and a counter if needed)

Example save:

```json
{
  "tool": "subfinder",
  "args": ["-silent", "-d", "wmg.com"],
  "timeout_seconds": 600,
  "save": { "type": "file" }
}
```

### Browsing / downloading saved results (via MCP)

- **`pd_results_list`**: list files/dirs under `OUTPUT_DIR`
- **`pd_results_read`**: read a file from `OUTPUT_DIR` (text or base64)
- **`pd_results_export`**: copy a file from `OUTPUT_DIR` into `DOWNLOAD_DIR` (requires a host bind-mount when containerized)

To export directly into your host `~/Downloads` folder, bind-mount it to `/data/downloads` when launching the container.

- **Via `cursor-stdio.sh`**:

```bash
PDTM_OUTPUT_VOLUME=pdtm_data PDTM_DOWNLOADS_DIR="$HOME/Downloads" ./cursor-stdio.sh
```

- **Via `mcp.json`** (example on macOS):

```json
"-v",
"/Users/pkincaid/Downloads:/data/downloads"
```

### Note on transports

- **stdio**: for Cursor (set `MCP_TRANSPORT=stdio`)
- **HTTP**: for networked use (set `MCP_TRANSPORT=streamable-http`, default in the Containerfile)

### MongoDB configuration

Set these env vars when running the container:

- `MONGO_URI` (example: `mongodb://mongo:27017`)
- `MONGO_DB` (default: `pdtm_mcp`)

### Notes / references

- PDTM is ProjectDiscovery’s tool manager: [projectdiscovery/pdtm](https://github.com/projectdiscovery/pdtm)
- General docs for ProjectDiscovery OSS tools: [ProjectDiscovery Open Source Tools](https://docs.projectdiscovery.io/opensource)
- Recon workflow inspiration (3rd-party article): `https://medium.com/@enessyibrahim/mastering-reconnaissance-with-project-discovery-99d7a21e299a`


## mcp.json

```
{
  "mcpServers": {
    "project_discovery": {
      "command": "podman",
      "args": [
        "run",
        "--rm",
        "-i",
        "-e",
        "MCP_TRANSPORT=stdio",
        "-v",
        "pdtm_data:/data/output",
        "--name",
        "pdtm-mcp-stdio",
        "pdtm-mcp-server"
      ]
    }
  }
}
```
```

Yes — I just brought **all the human-facing docs in `Standalone_Build/`** up to date with the latest behavior:

### Updated docs
- **`Standalone_Build/pentest-cli/README.md`**
  - Documents **autoload-all by default**, `--no-autoload-all`, and `server.tool` usage everywhere
  - Notes stderr logs go to **`Standalone_Build/logs/*.stderr.log`**
  - Removes outdated “switch servers / connect first” guidance
- **`Standalone_Build/README.md`**
  - Quickstart now recommends running **`pentest-cli`**
  - Adds notes about **qualified tool calls** and **quiet logs**
  - Clarifies Podman servers are at repo root (standalone copies are here)
- **`Standalone_Build/pentest-mcp-server/README.md`**
  - Documents the MCP name **`portscan`** and examples like `portscan.naabu_scan`
  - Documents parsed summaries + Mongo save behavior (including `portscan_all`)
- **Standalone server READMEs** (so they no longer incorrectly look “Podman-only”):
  - `Standalone_Build/shodan-mcp-server/README.md`
  - `Standalone_Build/searchsploit-mcp-server/README.md`
  - `Standalone_Build/searx-mcp-server/README.md`
  - `Standalone_Build/theharvester-mcp-server/README.md`
  - `Standalone_Build/wpscan-mcp-server/README.md`
  - `Standalone_Build/mongo-mcp-server/README.md`
  - `Standalone_Build/pdtm-mcp-server/README.md`
  - `Standalone_Build/portscan-mcp-server/README.md` (now clearly marked as **reference/legacy**; coordinator is preferred)

### Verification
I also ran a repo-wide check to ensure there are **no stale examples** left (old `connect`-required wording, old unqualified `call nmap_scan`, old `"pentest": {` config snippet, etc.).

---

**User**

For the 'pentest-cli' is there anything outside of the "Standalone_Build" that is necessary for the pentest-cli to run? I am looking to determine what can be packaged up and moved to different systems.

---

**Cursor**

### What `pentest-cli` needs outside `Standalone_Build/`
You can move `Standalone_Build/` as a self-contained bundle, but `pentest-cli` still depends on a few **external** things:

- **Python runtime**: a compatible Python (your venv is currently `Standalone_Build/.venv`).
- **Underlying tool binaries on the host** (only for tools you actually use):
  - `portscan.*`: `nmap`, `naabu`, `rustscan` (or `NMAP_BIN` / `NAABU_BIN` / `RUSTSCAN_BIN`)
  - `searchsploit.*`: `searchsploit` + local ExploitDB data
  - `theharvester.*`: `theHarvester` + its API keys file(s)
  - `wpscan.*`: `wpscan` (and optional `WPSCAN_API_TOKEN`)
  - `searx.*`: needs network access to whatever `SEARXNG_URL` points to (often a local SearXNG instance)
- **MongoDB** (only if you want saving/querying):
  - reachable via `MONGO_URI` (local daemon or remote host)
- **Config files**:
  - `Standalone_Build/mcp.json` (server definitions)
  - `Standalone_Build/.env` (API keys, Mongo URI, binary paths, output dirs, etc.)

### What you can package and move
- **All of `Standalone_Build/`**, including:
  - `mcp.json`
  - `run-mcp-stdio.sh`
  - all `*-mcp-server/` packages
  - `pentest-cli/`
  - optionally `logs/` (can be recreated)

### Recommended “portable” layout
- Copy `Standalone_Build/` to the new machine
- Recreate `Standalone_Build/.venv` on that machine (or ship it, but rebuilding is more reliable)
- Install required host binaries (or set `*_BIN` paths)
- Provide `Standalone_Build/.env` with keys/URIs

If you tell me the target OS (macOS/Linux) and whether you want “single folder + venv” vs “pipx install + external config”, I can give you the cleanest packaging approach.

---

**User**

Yes, can you please provide me an INSTALLATION.md file, requirements.txt for the .venv environment, etc and how we can package everything to run on a MacOS system as well as for a Linux system

---

**Cursor**

Plan: I’ll generate a clean `Standalone_Build/requirements.txt` from your current shared `.venv` (pinned third‑party deps, excluding the local editable packages), then add a `Standalone_Build/INSTALLATION.md` that documents macOS + Linux prerequisites, venv setup, `.env` configuration, and a practical “package + move” workflow (including an optional wheelhouse for offline installs).

Plan: I’ll add `Standalone_Build/INSTALLATION.md` + a pinned `Standalone_Build/requirements.txt`, and I’ll also make the CLI config portable by letting `Standalone_Build/mcp.json` use `./run-mcp-stdio.sh` (resolved relative to the config file). Then I’ll do a quick smoke test on the CLI to confirm it still autoloads and runs tools.

```plaintext
annotated-types==0.7.0
anyio==4.12.0
attrs==25.4.0
Authlib==1.6.6
backports.tarfile==1.2.0
beartype==0.22.9
cachetools==6.2.4
certifi==2025.11.12
cffi==2.0.0
charset-normalizer==3.4.4
click==8.3.1
click-plugins==1.1.1.2
cloudpickle==3.1.2
colorama==0.4.6
cryptography==46.0.3
cyclopts==4.4.1
diskcache==5.6.3
dnspython==2.8.0
docstring_parser==0.17.0
docutils==0.22.4
email-validator==2.3.0
exceptiongroup==1.3.1
fakeredis==2.33.0
fastmcp==2.14.1
filelock==3.20.1
h11==0.16.0
httpcore==1.0.9
httpx==0.28.1
httpx-sse==0.4.3
idna==3.11
importlib_metadata==8.7.1
jaraco.classes==3.4.0
jaraco.context==6.0.2
jaraco.functools==4.4.0
jsonschema==4.25.1
jsonschema-path==0.3.4
jsonschema-specifications==2025.9.1
keyring==25.7.0
lupa==2.6
markdown-it-py==4.0.0
mcp==1.25.0
mdurl==0.1.2
more-itertools==10.8.0
openapi-pydantic==0.5.1
opentelemetry-api==1.39.1
opentelemetry-exporter-prometheus==0.60b1
opentelemetry-instrumentation==0.60b1
opentelemetry-sdk==1.39.1
opentelemetry-semantic-conventions==0.60b1
packaging==25.0
pathable==0.4.4
pathvalidate==3.3.1
platformdirs==4.5.1
prometheus_client==0.23.1
py-key-value-aio==0.3.0
py-key-value-shared==0.3.0
pycparser==2.23
pydantic==2.12.5
pydantic-settings==2.12.0
pydantic_core==2.41.5
pydocket==0.16.3
Pygments==2.19.2
PyJWT==2.10.1
pymongo==4.15.5
pyperclip==1.11.0
python-dotenv==1.2.1
python-json-logger==4.0.0
python-multipart==0.0.21
PyYAML==6.0.3
redis==7.1.0
referencing==0.36.2
requests==2.32.5
requests-file==3.0.1
rich==14.2.0
rich-rst==1.3.2
rpds-py==0.30.0
shellingham==1.5.4
shodan==1.31.0
sortedcontainers==2.4.0
sse-starlette==3.1.1
starlette==0.50.0
tldextract==5.3.0
typer==0.21.0
typing-inspection==0.4.2
typing_extensions==4.15.0
urllib3==2.6.2
uvicorn==0.40.0
websockets==15.0.1
wrapt==1.17.3
xlsxwriter==3.2.9
zipp==3.23.0

```

```markdown
# Installation / Packaging (Standalone_Build)

This document explains how to install and package the **Standalone_Build** MCP toolchain so it runs on:

- **macOS**
- **Linux**

The goal is: run `pentest-cli`, which autoloads the MCP servers from `Standalone_Build/mcp.json`, and then call tools as:

- `portscan.nmap_scan`
- `shodan.shodan_search`
- etc.

---

## What you move between systems

Copy this whole directory:

- `Standalone_Build/` (everything inside)

You typically **do not** copy:

- `Standalone_Build/.venv/` (recreate it per-machine; faster + more reliable)
- `Standalone_Build/logs/` (optional; regenerated)

---

## 0) Prereqs (both macOS + Linux)

- **Python 3.11+** (recommended)
- `git`
- A working C toolchain (needed by some Python deps on some systems)
- External binaries you want to use (see per-platform sections below)

---

## 1) Configure environment (`Standalone_Build/.env`)

Create `Standalone_Build/.env` on the target machine (do not commit secrets). Typical variables:

```bash
# Mongo (optional but recommended)
MONGO_URI="mongodb://127.0.0.1:27017/mcp_db"
MONGO_DB="mcp_db"
MONGO_COLLECTION="results"

# API tokens (optional, per server)
SHODAN_API_KEY="..."
WPSCAN_API_TOKEN="..."

# Optional: override binary paths if not in PATH
# NMAP_BIN="/usr/bin/nmap"
# NAABU_BIN="/usr/local/bin/naabu"
# RUSTSCAN_BIN="/usr/local/bin/rustscan"
```

Notes:
- `run-mcp-stdio.sh` loads this `.env` before launching servers.
- `pentest-cli` also auto-loads `Standalone_Build/.env` by default (set `PENTEST_CLI_NO_DOTENV=1` to disable).

---

## 2) macOS install

### System packages

Using Homebrew:

```bash
brew install python@3.11 git
brew install nmap
```

Optional scanners:

```bash
brew install rustscan
brew install naabu
```

Other tool servers (optional):

```bash
brew install exploitdb    # provides searchsploit + exploit db
brew install mongosh      # optional client
```

WPScan and theHarvester are often easiest via their own installers / language ecosystems; if you don’t install them, the MCP wrappers still run but tool calls will fail with “binary not found”.

### Create venv + install Python deps + local packages

From your copied `Standalone_Build/`:

```bash
cd "Standalone_Build"
python3.11 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip

# Install pinned 3rd-party deps
pip install -r requirements.txt

# Install all local MCP packages + CLI
pip install -e ./pentest-cli \
            -e ./pentest-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### Run

```bash
pentest-cli
```

---

## 3) Linux install

### System packages (Debian/Ubuntu example)

```bash
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv python3-pip git ca-certificates
sudo apt-get install -y nmap
```

Optional scanners:

```bash
# rustscan: see https://github.com/RustScan/RustScan releases
# naabu: see https://github.com/projectdiscovery/naabu releases
```

Searchsploit:

```bash
sudo apt-get install -y exploitdb
```

### Create venv + install Python deps + local packages

```bash
cd "Standalone_Build"
python3.11 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip
pip install -r requirements.txt

pip install -e ./pentest-cli \
            -e ./pentest-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### Run

```bash
./.venv/bin/pentest-cli
```

---

## 4) How the CLI finds/launches servers (portable config)

- `pentest-cli` reads server definitions from: `Standalone_Build/mcp.json`
- Each entry points to `./run-mcp-stdio.sh <python_module>`
- The CLI resolves `./run-mcp-stdio.sh` **relative to the config file**, so you can move `Standalone_Build/` without editing paths.

Server logs (stderr) are written to:

- `Standalone_Build/logs/<module>.stderr.log`

---

## 5) Packaging / moving to other machines

### Recommended approach (rebuild venv per machine)

1. Copy `Standalone_Build/` to the new machine
2. Install host binaries you need (nmap, rustscan, etc.)
3. Create `Standalone_Build/.env`
4. Recreate `.venv` and install:
   - `pip install -r requirements.txt`
   - `pip install -e ...` local packages

### Offline / airgapped installs (optional)

On a machine with internet:

```bash
cd Standalone_Build
source .venv/bin/activate
mkdir -p wheels
pip download -r requirements.txt -d wheels
```

Copy `Standalone_Build/` (including `wheels/`) to the offline machine, then:

```bash
cd Standalone_Build
python3.11 -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install --no-index --find-links wheels -r requirements.txt
pip install -e ./pentest-cli -e ./pentest-mcp-server -e ./pdtm-mcp-server -e ./shodan-mcp-server -e ./searchsploit-mcp-server -e ./searx-mcp-server -e ./theharvester-mcp-server -e ./wpscan-mcp-server -e ./mongo-mcp-server
```

---

## 6) Quick validation checklist

Inside the CLI:

```text
pentest> tools portscan
pentest> describe portscan.nmap_scan
pentest> call portscan.nmap_scan {"targets":["127.0.0.1"],"args":["-p","1-10","-sT"],"force_unprivileged":true}
```

If Mongo is configured:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```


```

```python
from __future__ import annotations

import json
import os
import shlex
import sys
import shutil
import re
import contextlib
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import anyio
import mcp.types as types
from mcp.client.session import ClientSession
from mcp.client.stdio import StdioServerParameters, stdio_client

from .config import McpServerConfig, load_dotenv_file, load_mcp_json, safe_json_loads


def _supports_color() -> bool:
    if os.getenv("NO_COLOR") is not None:
        return False
    try:
        return sys.stdout.isatty()
    except Exception:
        return False


def _c(text: str, code: str) -> str:
    if not _supports_color():
        return text
    return f"\x1b[{code}m{text}\x1b[0m"


def _bold(text: str) -> str:
    return _c(text, "1")


def _dim(text: str) -> str:
    return _c(text, "2")


def _cyan(text: str) -> str:
    return _c(text, "36")


def _green(text: str) -> str:
    return _c(text, "32")


def _yellow(text: str) -> str:
    return _c(text, "33")


def _magenta(text: str) -> str:
    return _c(text, "35")


def _inverse(text: str) -> str:
    return _c(text, "7")


def _color_for_server(server: str) -> str:
    """
    Deterministic ANSI color code for a given server name (cycles a small palette).
    Only used when stdout supports color.
    """
    palette = ["36", "35", "34", "32"]  # cyan, magenta, blue, green
    s = (server or "").strip().lower()
    # Stable hash (avoid Python's randomized hash()).
    h = 0
    for ch in s:
        h = (h * 131 + ord(ch)) & 0xFFFFFFFF
    return palette[h % len(palette)]


def _hr(char: str = "─") -> str:
    """
    Dim horizontal rule sized to terminal width (best-effort).
    """
    try:
        cols = shutil.get_terminal_size(fallback=(80, 20)).columns
    except Exception:
        cols = 80
    cols = max(20, min(int(cols), 200))
    return _dim(char * cols)


def _dump(obj: Any) -> str:
    if hasattr(obj, "model_dump"):
        return json.dumps(obj.model_dump(), indent=2, default=str)
    if hasattr(obj, "dict"):
        return json.dumps(obj.dict(), indent=2, default=str)  # type: ignore[attr-defined]
    return json.dumps(obj, indent=2, default=str)


def _schema_type(schema: Any) -> str:
    """
    Best-effort human type string from a JSON Schema fragment.
    """
    if not isinstance(schema, dict):
        return "unknown"
    t = schema.get("type")
    if isinstance(t, str):
        return t
    if isinstance(t, list):
        return " | ".join(str(x) for x in t)
    if "anyOf" in schema and isinstance(schema["anyOf"], list):
        parts: list[str] = []
        for s in schema["anyOf"]:
            parts.append(_schema_type(s))
        # de-dupe while preserving order
        seen: set[str] = set()
        out: list[str] = []
        for p in parts:
            if p not in seen:
                seen.add(p)
                out.append(p)
        return " | ".join(out) if out else "unknown"
    if "oneOf" in schema and isinstance(schema["oneOf"], list):
        parts = [_schema_type(s) for s in schema["oneOf"]]
        return " | ".join(parts) if parts else "unknown"
    return "object" if "properties" in schema else "unknown"


def _format_describe(tool: Any) -> str:
    """
    Render a tool in a human-friendly format (instead of raw JSON schema).
    Expects an MCP Tool model (mcp.types.Tool).
    """
    name = getattr(tool, "name", "") or ""
    desc = (getattr(tool, "description", "") or "").strip()
    input_schema = getattr(tool, "inputSchema", None)
    output_schema = getattr(tool, "outputSchema", None)

    lines: list[str] = []
    lines.append(_bold(_cyan(f"Tool: {name}")))
    if desc:
        lines.append("")
        lines.append(_bold(_magenta("What it does:")))
        lines.append(f"  {desc}")

    # Inputs
    props: dict[str, Any] = {}
    required: set[str] = set()
    if isinstance(input_schema, dict):
        if isinstance(input_schema.get("properties"), dict):
            props = dict(input_schema["properties"])
        req = input_schema.get("required")
        if isinstance(req, list):
            required = {str(x) for x in req}

    lines.append("")
    lines.append(_bold(_magenta("Inputs:")))
    if not props:
        lines.append(_dim("  (none)"))
    else:
        for k in sorted(props.keys()):
            s = props.get(k)
            t = _schema_type(s)
            nullable = "null" in {p.strip() for p in t.split("|")}
            default = s.get("default") if isinstance(s, dict) else None
            # FastMCP sometimes marks fields as "required" even when a default exists.
            # For UX, treat "has default" as optional-with-default.
            is_req = (k in required) and (default is None)
            suffix_parts: list[str] = []
            if is_req:
                suffix_parts.append(_green("required"))
                if nullable:
                    suffix_parts.append(_dim("nullable"))
            else:
                suffix_parts.append(_yellow("optional"))
            if default is not None:
                suffix_parts.append(f"default={default!r}")
            suffix = ", ".join(suffix_parts)
            lines.append(f"  - {_bold(k)}: {_cyan(t)} ({suffix})")

    # Output
    lines.append("")
    lines.append(_bold(_magenta("Output:")))
    if isinstance(output_schema, dict):
        lines.append(f"  schema_type: {_cyan(_schema_type(output_schema))}")
    else:
        lines.append(f"  schema_type: {_cyan('unknown')}")

    # Example call stub
    example_obj: dict[str, Any] = {}
    for k in sorted(props.keys()):
        s = props.get(k)
        default = s.get("default") if isinstance(s, dict) else None
        t = _schema_type(s)
        nullable = "null" in {p.strip() for p in t.split("|")}

        # Only include "required-like" keys in the example. If FastMCP marked it required
        # but the schema provides a default, users can omit it.
        if k in required and default is None:
            # Prefer a default if present (even though required-set said required).
            if default is not None:
                example_obj[k] = default
                continue

            # Put simple placeholders for required fields
            schema = props.get(k)
            if k == "targets":
                example_obj[k] = ["127.0.0.1"]
            elif k == "url":
                example_obj[k] = "https://example.com"
            elif k == "domain":
                example_obj[k] = "example.com"
            elif k == "ports":
                # Common for scanners that accept N-M.
                example_obj[k] = "1-1024" if not nullable else "1-1024"
            elif t == "boolean":
                example_obj[k] = True
            elif nullable:
                # If the schema says it's required but allows null, use null as the safest default.
                example_obj[k] = None
            elif t in {"integer", "number"}:
                # Use a non-zero default-ish value for common scanner knobs.
                example_obj[k] = 1
            elif t.startswith("array"):
                example_obj[k] = []
            else:
                example_obj[k] = ""

    lines.append("")
    lines.append(_bold(_magenta("How to call:")))
    lines.append(_cyan(f"  call {name} {json.dumps(example_obj, separators=(',', ':'))}"))
    lines.append("")
    lines.append(_bold(_magenta("Notes:")))
    lines.append("  - Some servers mark many fields as 'required' even when they allow null; prefer null for nullable inputs unless you need them.")
    lines.append("")
    lines.append(_bold(_magenta("Raw schema (if you need it):")))
    lines.append(_cyan(f"  describe-json {name}"))
    return "\n".join(lines)


def _format_describe_with_name(tool: Any, *, display_name: str) -> str:
    """
    Same as _format_describe, but override the tool name shown to users (e.g. server.tool).
    """
    # Lightweight approach: clone the object surface by monkeying a few attrs
    # without depending on the exact mcp.types.Tool class.
    class _Wrap:
        def __init__(self, inner: Any, name: str):
            self._inner = inner
            self.name = name

        def __getattr__(self, item: str) -> Any:
            return getattr(self._inner, item)

    return _format_describe(_Wrap(tool, display_name))


def _read_json_arg(token: str) -> dict[str, Any]:
    t = (token or "").strip()
    if not t:
        return {}
    if t.startswith("@"):
        p = Path(t[1:]).expanduser()
        data = safe_json_loads(p.read_text(encoding="utf-8"))
    else:
        data = safe_json_loads(t)
    if data is None:
        return {}
    if not isinstance(data, dict):
        raise ValueError("tool arguments must be a JSON object")
    return data


@dataclass
class ActiveConnection:
    name: str
    cfg: McpServerConfig
    session: ClientSession
    close_fn: Any
    tools_by_name: dict[str, Any]


class PentestCliRepl:
    def __init__(
        self,
        *,
        config_path: str,
        auto_connect: str | None = None,
        default_save_mongo: bool = True,
        autoload_all: bool = True,
    ):
        self.config_path = config_path
        self.servers: dict[str, McpServerConfig] = load_mcp_json(config_path)
        self.conn: ActiveConnection | None = None
        self.conns: dict[str, ActiveConnection] = {}
        self.auto_connect = (auto_connect or "").strip() or None
        self.default_save_mongo = bool(default_save_mongo)
        self.autoload_all = bool(autoload_all)
        self._history_path = os.path.expanduser(os.getenv("PENTEST_CLI_HISTORY", "~/.pentest_cli_history"))
        self._history_ready = False
        self.mongo_db_default = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
        self.mongo_collection_default = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    def _dotenv_init(self) -> None:
        """
        Load Standalone_Build/.env (if present) so CLI commands (notably Mongo queries)
        see the same configuration as the MCP servers started via run-mcp-stdio.sh.
        """
        if os.getenv("PENTEST_CLI_NO_DOTENV") is not None:
            return
        try:
            # Prefer a .env next to the config file (Standalone_Build/.env)
            base = Path(self.config_path).resolve().parent
            load_dotenv_file(str(base / ".env"), override=False)
        except Exception:
            return

    def _history_init(self) -> None:
        """
        Enable readline history so arrow keys can recall commands.
        On macOS this is typically backed by libedit; importing readline is enough
        for up/down history in most terminals.
        """
        if self._history_ready:
            return
        try:
            import readline  # noqa: F401

            # Best-effort load existing history
            try:
                if os.path.exists(self._history_path):
                    readline.read_history_file(self._history_path)
            except Exception:
                pass
            try:
                readline.set_history_length(5000)
            except Exception:
                pass
            self._history_ready = True
        except Exception:
            # If readline isn't available, we silently proceed (no history).
            self._history_ready = False

    def _history_save(self) -> None:
        if not self._history_ready:
            return
        try:
            import readline

            readline.write_history_file(self._history_path)
        except Exception:
            pass

    async def _input(self, prompt: str) -> str:
        return await anyio.to_thread.run_sync(input, prompt)

    def _print(self, s: str = "") -> None:
        print(s, flush=True)

    def _help(self) -> None:
        self._print(
            "\n".join(
                [
                    "Commands:",
                    "  help                              Show this help",
                    "  reload                            Reload mcp.json",
                    "  servers                           List configured servers",
                    "  connect <server>                  Start and connect to a server (stdio)",
                    "  disconnect                        Disconnect current server",
                    "  status                            Show current connection",
                    "  tools [filter]                    List tools across all servers (qualified as server.tool)",
                    "  describe <server.tool>            Show a human-friendly description + how to call it",
                    "  describe-json <server.tool>       Show the raw MCP JSON schema for a tool",
                    "  call <server.tool> <json|@file>   Call a tool (servers are autoloaded by default)",
                    "  call-json <server.tool> <json|@file> Call a tool and print the full MCP JSON response",
                    "  mongo-use <db> <collection>       Set default Mongo db/collection for queries",
                    "  mongo-find-one <json|@file>       pymongo find_one(filter) on default db/collection",
                    "  mongo-find <json|@file> [limit=N] pymongo find(filter).limit(N) on default db/collection",
                    "  quit | exit                       Exit",
                    "",
                    f"Config: {self.config_path}",
                    _dim("Tip: this CLI prefers qualified tool names like: portscan.naabu_scan  or  shodan.shodan_search"),
                ]
            )
        )

    def _require_conn(self) -> ActiveConnection:
        if not self.conn:
            raise RuntimeError("not connected (use: connect <server>)")
        return self.conn

    def _split_qualified_tool(self, name: str) -> tuple[str | None, str]:
        """
        Parse "server.tool" into ("server", "tool"). If no dot, returns (None, name).
        """
        s = (name or "").strip()
        if "." not in s:
            return None, s
        server, tool = s.split(".", 1)
        server = server.strip()
        tool = tool.strip()
        if not server or not tool:
            return None, s
        return server, tool

    async def _open_connection(self, server_name: str) -> ActiveConnection:
        name = (server_name or "").strip()
        if not name:
            raise ValueError("server name is required")
        cfg = self.servers.get(name)
        if not cfg:
            raise ValueError(f"unknown server: {name}")

        # Make config portable: allow relative command paths in mcp.json
        # and resolve them relative to the config file location.
        cmd = cfg.command
        try:
            if cmd and (not os.path.isabs(cmd)) and (cmd.startswith(".") or ("/" in cmd)):
                base = Path(self.config_path).resolve().parent
                cmd = str((base / cmd).resolve())
        except Exception:
            cmd = cfg.command

        # Merge env: base process env + config env (config overrides).
        env = os.environ.copy()
        env.update(cfg.env)

        params = StdioServerParameters(command=cmd, args=cfg.args, env=env)
        cm = stdio_client(params)
        read_stream, write_stream = await cm.__aenter__()  # type: ignore[misc]

        sess_cm = ClientSession(read_stream, write_stream)
        session = await sess_cm.__aenter__()  # type: ignore[misc]
        try:
            await session.initialize()
        except Exception:
            await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            await cm.__aexit__(None, None, None)  # type: ignore[misc]
            raise

        # Cache tools (used to know whether a tool accepts `save`)
        tools_by_name: dict[str, Any] = {}
        try:
            tool_list = await session.list_tools()
            for t in (tool_list.tools or []):
                n = getattr(t, "name", None)
                if isinstance(n, str) and n:
                    tools_by_name[n] = t
        except Exception:
            tools_by_name = {}

        async def _close() -> None:
            try:
                await sess_cm.__aexit__(None, None, None)  # type: ignore[misc]
            finally:
                await cm.__aexit__(None, None, None)  # type: ignore[misc]

        return ActiveConnection(name=name, cfg=cfg, session=session, close_fn=_close, tools_by_name=tools_by_name)

    @contextlib.asynccontextmanager
    async def _temp_connection(self, server_name: str):
        """
        Open a one-off connection to a server for a single command, then close it.
        """
        conn = await self._open_connection(server_name)
        try:
            yield conn
        finally:
            try:
                await conn.close_fn()
            except Exception:
                pass

    async def cmd_reload(self) -> None:
        self.servers = load_mcp_json(self.config_path)
        self._print(f"Reloaded {len(self.servers)} servers from {self.config_path}")

    async def cmd_servers(self) -> None:
        if not self.servers:
            self._print("No servers found in config.")
            return
        self._print("Servers:")
        for k in sorted(self.servers):
            cfg = self.servers[k]
            self._print(f"  - {k}: {cfg.command} {' '.join(cfg.args)}")

    async def cmd_status(self) -> None:
        if not self.conn:
            self._print("Not connected.")
            return
        self._print(f"Connected: {self.conn.name}")
        self._print(f"Command:   {self.conn.cfg.command} {' '.join(self.conn.cfg.args)}")

    async def cmd_disconnect(self) -> None:
        if not self.conn:
            return
        try:
            try:
                await self.conn.close_fn()
            except BaseException:
                # Closing stdio transports can raise cancellation-related exceptions; ignore on shutdown.
                pass
        finally:
            self.conn = None
        self._print("Disconnected.")

    async def cmd_disconnect_all(self) -> None:
        """
        Disconnect all autoloaded servers (and the current connection, if any).
        """
        # Close current connection if it's also in the pool.
        if self.conn:
            try:
                await self.conn.close_fn()
            except BaseException:
                pass
            self.conn = None

        for name in list(self.conns.keys()):
            c = self.conns.pop(name, None)
            if not c:
                continue
            try:
                await c.close_fn()
            except BaseException:
                pass

    async def cmd_autoload_all(self) -> None:
        """
        Start and connect to all configured servers up-front for fast, global tool access.
        """
        loaded: list[str] = []
        failed: dict[str, str] = {}
        for name in sorted(self.servers.keys()):
            if name in self.conns:
                loaded.append(name)
                continue
            try:
                self.conns[name] = await self._open_connection(name)
                loaded.append(name)
            except Exception as e:
                failed[name] = f"{type(e).__name__}: {e}"
        self._print(_dim(f"Autoloaded servers ({len(loaded)}/{len(self.servers)}): {', '.join(loaded) if loaded else '(none)'}"))
        if failed:
            self._print(_bold(_yellow("Some servers failed to load:")))
            for k in sorted(failed.keys()):
                self._print(f"  - {k}: {failed[k]}")

    def _mongo_client(self):
        """
        Create a MongoClient from env MONGO_URI (loaded via .env when available).
        """
        uri = (os.getenv("MONGO_URI", "") or "").strip()
        if not uri:
            raise RuntimeError("MONGO_URI is not set (set it in Standalone_Build/.env)")
        try:
            from pymongo import MongoClient

            return MongoClient(uri, serverSelectionTimeoutMS=3000)
        except Exception as e:
            raise RuntimeError(f"failed to create MongoClient: {e}") from e

    def _jsonable(self, obj: Any) -> Any:
        """
        Convert pymongo/bson types (ObjectId, datetime, etc.) into JSON-friendly values.
        """
        try:
            from bson import ObjectId  # type: ignore
        except Exception:
            ObjectId = None  # type: ignore

        if ObjectId is not None and isinstance(obj, ObjectId):  # type: ignore[arg-type]
            return str(obj)
        if isinstance(obj, dict):
            return {k: self._jsonable(v) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._jsonable(v) for v in obj]
        return obj

    async def cmd_mongo_use(self, db: str, collection: str) -> None:
        d = (db or "").strip()
        c = (collection or "").strip()
        if not d or not c:
            raise ValueError("usage: mongo-use <db> <collection>")
        self.mongo_db_default = d
        self.mongo_collection_default = c
        self._print(f"Mongo default: {self.mongo_db_default}.{self.mongo_collection_default}")

    async def cmd_mongo_find_one(self, raw_filter: str) -> None:
        filt = _read_json_arg(raw_filter)
        client = self._mongo_client()
        doc = client[self.mongo_db_default][self.mongo_collection_default].find_one(filt)
        if doc is None:
            self._print("(no match)")
            return
        self._print(json.dumps(self._jsonable(doc), indent=2, default=str))

    async def cmd_mongo_find(self, raw_filter: str, *, limit: int = 20) -> None:
        filt = _read_json_arg(raw_filter)
        try:
            limit = int(limit)
        except Exception:
            limit = 20
        limit = max(1, min(limit, 500))
        client = self._mongo_client()
        cur = client[self.mongo_db_default][self.mongo_collection_default].find(filt).limit(limit)
        docs = list(cur)
        if not docs:
            self._print("(no matches)")
            return
        self._print(json.dumps([self._jsonable(d) for d in docs], indent=2, default=str))

    async def cmd_connect(self, server_name: str) -> None:
        # Disconnect existing connection first.
        await self.cmd_disconnect()
        name = (server_name or "").strip()
        if not name:
            raise ValueError("usage: connect <server>")
        self.conn = await self._open_connection(name)
        self._print(f"Connected to {name}.")

    def _maybe_inject_save_mongo(self, conn: ActiveConnection, tool_name: str, args: dict[str, Any]) -> dict[str, Any]:
        """
        If enabled, inject save={"type":"mongo"} for tools that accept a `save` parameter,
        unless the caller explicitly provided a non-null save value.
        """
        if not self.default_save_mongo:
            return args

        tool = conn.tools_by_name.get(tool_name)
        input_schema = getattr(tool, "inputSchema", None) if tool is not None else None
        props = input_schema.get("properties") if isinstance(input_schema, dict) else None
        supports_save = isinstance(props, dict) and ("save" in props)

        if not supports_save:
            return args

        if "save" in args and args.get("save") not in (None, {}):
            # Caller explicitly set a save mode; respect it.
            return args

        out = dict(args)
        out["save"] = {"type": "mongo"}
        return out

    async def cmd_tools(self, filt: str | None = None) -> None:
        q = (filt or "").strip().lower()

        # Prefer the autoloaded pool; fall back to on-demand if autoload is disabled.
        servers_to_scan: list[str]
        if q and q in self.servers:
            servers_to_scan = [q]
        else:
            servers_to_scan = sorted(self.servers.keys())

        hidden_tool_names = {"list_tools", "describe_tool"}
        items: list[tuple[str, Any]] = []
        for s in servers_to_scan:
            pooled = self.conns.get(s)
            if pooled is not None:
                res = await pooled.session.list_tools()
                for t in (res.tools or []):
                    if getattr(t, "name", None) in hidden_tool_names:
                        continue
                    items.append((s, t))
                continue
            async with self._temp_connection(s) as conn:
                res = await conn.session.list_tools()
                for t in (res.tools or []):
                    if getattr(t, "name", None) in hidden_tool_names:
                        continue
                    items.append((s, t))

        # Apply substring filter across qualified name + description.
        if q:
            filtered: list[tuple[str, Any]] = []
            for s, t in items:
                name2 = f"{s}.{getattr(t, 'name', '') or ''}".lower()
                desc2 = (getattr(t, "description", "") or "").lower()
                if q in name2 or q in desc2:
                    filtered.append((s, t))
            items = filtered

        self._print(f"Tools ({len(items)}):")
        for s, t in items:
            desc = (t.description or "").strip().splitlines()[0] if getattr(t, "description", None) else ""
            qualified = f"{s}.{t.name}"
            qualified_colored = _c(qualified, _color_for_server(s))
            self._print(f"  - {qualified_colored}: {desc}")

    async def cmd_describe(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_format_describe_with_name(tool, display_name=f"{server}.{name}"))
                return

        raise ValueError("usage: describe <server>.<tool>")

    async def cmd_describe_json(self, tool_name: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: describe-json <tool|server.tool>")
        server, name = self._split_qualified_tool(raw)

        if server:
            pooled = self.conns.get(server)
            if pooled is not None:
                res = await pooled.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return
            async with self._temp_connection(server) as conn:
                res = await conn.session.list_tools()
                tool = next((t for t in (res.tools or []) if t.name == name), None)
                if not tool:
                    raise ValueError(f"tool not found: {server}.{name}")
                self._print(_dump(tool))
                return

        raise ValueError("usage: describe-json <server>.<tool>")

    async def cmd_call(self, tool_name: str, json_arg: str) -> None:
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            conn = pooled
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
        else:
            async with self._temp_connection(server) as conn:
                args = _read_json_arg(json_arg)
                args = self._maybe_inject_save_mongo(conn, name, args)
                result = await conn.session.call_tool(name=name, arguments=args)

        # Many of our MCP tools return a structured payload like:
        #   {"ok": false, "error": "...", "details": ...}
        # but do not set MCP-level isError=true. Present these as errors in the CLI.
        sc = getattr(result, "structuredContent", None)
        if isinstance(sc, dict) and sc.get("ok") is False:
            err = str(sc.get("error") or "tool error")
            details = sc.get("details")
            self._print(_bold(_yellow("Tool returned ok=false")))
            self._print(f"  error: {err}")
            if details is not None:
                self._print(f"  details: {json.dumps(details, indent=2, default=str)}")
            # Friendly hint for missing binaries.
            if "not found in PATH" in err:
                missing = err.split(" not found in PATH", 1)[0].strip()
                env_var = f"{missing.upper()}_BIN" if missing else "<TOOL>_BIN"
                self._print("")
                self._print(_bold(_magenta("Fix: install the binary or set an explicit path")))
                if missing:
                    self._print(f"  - Install {missing} so it's available on PATH")
                else:
                    self._print("  - Install the missing tool binary so it's available on PATH")
                self._print(f"  - Or set {env_var} in Standalone_Build/.env to the full executable path")
            return

        # Default UX: print stdout/stderr like a CLI tool would.
        if isinstance(sc, dict) and sc.get("ok") is True:
            payload = sc.get("result")
            meta = sc.get("meta") if isinstance(sc.get("meta"), dict) else None
            if isinstance(payload, dict):
                stdout = payload.get("stdout")
                stderr = payload.get("stderr")
                if isinstance(stdout, str) and stdout.strip():
                    print(stdout, end="" if stdout.endswith("\n") else "\n", flush=True)
                if isinstance(stderr, str) and stderr.strip():
                    self._print(_bold(_yellow("stderr:")))
                    print(stderr, end="" if stderr.endswith("\n") else "\n", flush=True)
                # If we printed anything, stop here.
                if meta and isinstance(meta.get("saved"), dict):
                    saved = meta.get("saved") or {}
                    if isinstance(saved, dict):
                        if saved.get("saved") is True:
                            self._print(_dim(f"saved: mongo ({saved.get('db','')}.{saved.get('collection','')}) id={saved.get('inserted_id','')}"))
                        elif saved:
                            self._print(_dim(f"saved: failed ({saved.get('error','unknown error')})"))
                if (isinstance(stdout, str) and stdout.strip()) or (isinstance(stderr, str) and stderr.strip()):
                    return

        # Fallback: show the full MCP response object
        self._print(_dump(result))

    async def cmd_call_json(self, tool_name: str, json_arg: str) -> None:
        """
        Call a tool, but always print the full MCP response (structuredContent/meta).
        """
        raw = (tool_name or "").strip()
        if not raw:
            raise ValueError("usage: call-json <tool|server.tool> <json|@file>")
        server, name = self._split_qualified_tool(raw)

        if not server:
            raise ValueError("usage: call-json <server>.<tool> <json|@file>")

        pooled = self.conns.get(server)
        if pooled is not None:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(pooled, name, args)
            result = await pooled.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))
            return

        async with self._temp_connection(server) as conn:
            args = _read_json_arg(json_arg)
            args = self._maybe_inject_save_mongo(conn, name, args)
            result = await conn.session.call_tool(name=name, arguments=args)
            self._print(_dump(result))

    async def run(self) -> int:
        self._dotenv_init()
        self._history_init()
        self._print(_dim("Type 'help' for commands."))
        self._print(_dim(f"Config: {self.config_path} (loaded {len(self.servers)} servers)"))
        if self.autoload_all and self.servers:
            await self.cmd_autoload_all()
        if not self.servers:
            self._print(
                _dim(
                    "No servers loaded. Set --config /path/to/mcp.json "
                    "or export PENTEST_CLI_CONFIG=/path/to/mcp.json."
                )
            )
        if self.auto_connect:
            if self.auto_connect in self.servers:
                try:
                    await self.cmd_connect(self.auto_connect)
                except Exception as e:
                    self._print(f"Auto-connect failed ({self.auto_connect}): {type(e).__name__}: {e}")
            else:
                self._print(f"Auto-connect skipped: unknown server '{self.auto_connect}' (try: servers)")
        while True:
            try:
                # Prompt framing (dim rule above/below) + simple prompt text.
                self._print(_hr())
                line = (await self._input("pentest> ")).strip()
                self._print(_hr())
            except (EOFError, KeyboardInterrupt):
                self._print()
                break

            if not line:
                continue

            # Special-case: `call <tool> <json...>` should not be parsed via shlex because
            # shlex will strip quotes inside JSON, breaking valid JSON like {"k":"v"}.
            # Instead, parse the raw remainder and treat it as a JSON blob or @file.
            m_call = re.match(r"^\s*call\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call:
                tool = m_call.group(1)
                raw_arg = m_call.group(2)
                try:
                    await self.cmd_call(tool, raw_arg)
                except Exception as e:
                    # Provide a more actionable error for common JSON quoting problems.
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: paste JSON exactly (as you did), or use @file.json.\n"
                            "  If your JSON contains spaces/newlines, wrap it in single quotes:\n"
                            "    call <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_call_json = re.match(r"^\s*call-json\s+(\S+)\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_call_json:
                tool = m_call_json.group(1)
                raw_arg = m_call_json.group(2)
                try:
                    await self.cmd_call_json(tool, raw_arg)
                except Exception as e:
                    if isinstance(e, json.JSONDecodeError):
                        self._print(
                            "Error: invalid JSON.\n"
                            "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                            "    call-json <tool> '{\"k\":\"v\"}'"
                        )
                    else:
                        self._print(f"Error: {type(e).__name__}: {e}")
                continue

            # Mongo query commands accept raw JSON after the command (same reasoning as `call`).
            m_mf1 = re.match(r"^\s*mongo-find-one\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf1:
                try:
                    await self.cmd_mongo_find_one(m_mf1.group(1))
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            m_mf = re.match(r"^\s*mongo-find\s+(.+?)\s*$", line, flags=re.IGNORECASE)
            if m_mf:
                raw = m_mf.group(1).strip()
                # Allow trailing " limit=N" convenience.
                limit = 20
                m_lim = re.search(r"\s+limit=(\d+)\s*$", raw)
                if m_lim:
                    try:
                        limit = int(m_lim.group(1))
                    except Exception:
                        limit = 20
                    raw = re.sub(r"\s+limit=\d+\s*$", "", raw).strip()
                try:
                    await self.cmd_mongo_find(raw, limit=limit)
                except Exception as e:
                    self._print(f"Error: {type(e).__name__}: {e}")
                continue

            try:
                parts = shlex.split(line)
            except ValueError as e:
                self._print(f"Parse error: {e}")
                continue

            cmd = parts[0].lower()
            args = parts[1:]

            try:
                if cmd in {"quit", "exit"}:
                    break
                if cmd in {"help", "?"}:
                    self._help()
                elif cmd == "reload":
                    await self.cmd_reload()
                elif cmd == "servers":
                    await self.cmd_servers()
                elif cmd == "connect":
                    await self.cmd_connect(args[0] if args else "")
                elif cmd == "disconnect":
                    await self.cmd_disconnect()
                elif cmd == "status":
                    await self.cmd_status()
                elif cmd == "tools":
                    await self.cmd_tools(args[0] if args else None)
                elif cmd == "describe":
                    await self.cmd_describe(args[0] if args else "")
                elif cmd in {"describe-json", "describe_json"}:
                    await self.cmd_describe_json(args[0] if args else "")
                elif cmd == "mongo-use":
                    if len(args) < 2:
                        raise ValueError("usage: mongo-use <db> <collection>")
                    await self.cmd_mongo_use(args[0], args[1])
                elif cmd == "call":
                    if len(args) < 2:
                        raise ValueError("usage: call <tool> <json|@file>")
                    await self.cmd_call(args[0], args[1])
                elif cmd in {"call-json", "call_json"}:
                    if len(args) < 2:
                        raise ValueError("usage: call-json <tool> <json|@file>")
                    await self.cmd_call_json(args[0], args[1])
                else:
                    self._print(f"Unknown command: {cmd} (type 'help')")
            # NOTE: mcp.types.ErrorData is a data model, not an Exception.
            # MCP client failures surface as regular Exceptions (e.g., McpError).
            except Exception as e:
                if isinstance(e, json.JSONDecodeError):
                    self._print(
                        "Error: invalid JSON.\n"
                        "  Tip: use @file.json, or wrap inline JSON in single quotes:\n"
                        "    call <tool> '{\"k\":\"v\"}'"
                    )
                    continue
                self._print(f"Error: {type(e).__name__}: {e}")

        await self.cmd_disconnect()
        await self.cmd_disconnect_all()
        self._history_save()
        return 0



```

```jsonc
{
  "mcpServers": {
    "portscan": {
      "command": "./run-mcp-stdio.sh",
      "args": ["pentest_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "pdtm": {
      "command": "./run-mcp-stdio.sh",
      "args": ["pdtm_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "shodan": {
      "command": "./run-mcp-stdio.sh",
      "args": ["shodan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searchsploit": {
      "command": "./run-mcp-stdio.sh",
      "args": ["searchsploit_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searx": {
      "command": "./run-mcp-stdio.sh",
      "args": ["searx_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "theharvester": {
      "command": "./run-mcp-stdio.sh",
      "args": ["theharvester_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "wpscan": {
      "command": "./run-mcp-stdio.sh",
      "args": ["wpscan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "mongo": {
      "command": "./run-mcp-stdio.sh",
      "args": ["mongo_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    }
  }
}



```

### Added packaging + install docs/files
- **`Standalone_Build/INSTALLATION.md`**: step-by-step setup for **macOS + Linux**, including `.env` layout, venv creation, installing deps, running `pentest-cli`, and an offline/airgapped wheel workflow.
- **`Standalone_Build/requirements.txt`**: pinned third‑party Python requirements for the shared `Standalone_Build/.venv`.

### Made the setup portable across systems
To make this easy to “zip up and move”:
- **`Standalone_Build/mcp.json`** now uses `./run-mcp-stdio.sh` (relative), instead of hard-coded absolute paths.
- `pentest-cli` now **resolves relative command paths relative to the `mcp.json` location**, so it works even if you run the CLI from outside the folder.

### Verified
I smoke-tested launching `pentest-cli` from outside `Standalone_Build/` while pointing it at the config, and it successfully autoloaded servers and listed `portscan.*` tools.

---

**User**

Using https://github.com/epi052/feroxbuster  and https://epi052.github.io/feroxbuster-docs/overview/ , along with https://github.com/OJ/gobuster and using the wordlists from https://gitlab.com/kalilinux/packages/wordlists  to create an MCP server for web directory scanning - please call the server "dirscan" and create functions to perform a scan of a web server with either feroxbuster or gobuster, also provide a function for the "dirscan" server that will list the wordlists that are on the server. When presenting the user with the wordlists - please do no include the full directory where they are located, within the "dirscan" server, have a variable for the full base path for the root of the wordlists and allow the user to just identify the subdirectory (if applicable) for the wordlist they would like to use. For the "rockyou.txt.gz" please store that as a GZIP file and only decompress it when the user requests it to be used. Please provide warning to the user and an estimated progress meter for decompressing rockyou.txt.gz as it will slow the requested scan. Once you have decompressed the rockyou.txt, leave it unencrypted until the end of the session (store in memory if possible or if needed to store on disk, delete the uncompressed version once the program is exited - or just allow it to be lost when the MCP server stops.

---

**Cursor**

Plan: I’ll add a new standalone MCP server package under `Standalone_Build/dirscan-mcp-server` with tools for `feroxbuster` and `gobuster`, plus a `wordlists_list` tool. Then I’ll wire it into `Standalone_Build/mcp.json` (as `dirscan`) and update `INSTALLATION.md` with macOS/Linux prerequisites (binaries + wordlists path + rockyou behavior).

```plaintext
[project]
name = "dirscan-mcp-server"
version = "0.1.0"
description = "Standalone FastMCP server for web directory scanning (feroxbuster / gobuster) with wordlist management"
requires-python = ">=3.11"
dependencies = [
  "fastmcp>=2.0.0",
  "pymongo>=4.7.0",
]

[project.scripts]
dirscan-mcp-server = "dirscan_mcp_server.server:main"

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]


```

```markdown
# dirscan-mcp-server (Standalone, stdio-first)

Standalone MCP server for **web directory scanning** using:

- **feroxbuster** (Rust) — see [epi052/feroxbuster](https://github.com/epi052/feroxbuster) and the docs at `https://epi052.github.io/feroxbuster-docs/overview/`
- **gobuster** (Go) — see `https://github.com/OJ/gobuster`

It also exposes a wordlist browser intended to work with the Kali **wordlists** package (usually installed under `/usr/share/wordlists`).

## Tools

- `wordlists_list`: list available wordlists (returns *relative* paths, not full paths)
- `feroxbuster_scan`: run a scan using feroxbuster
- `gobuster_scan`: run a scan using gobuster

## Wordlists root

The server uses an environment variable:

- `WORDLISTS_ROOT` (default: `/usr/share/wordlists`)

When calling a scan, pass the wordlist as a path **relative** to `WORDLISTS_ROOT`, e.g.:

- `dirb/common.txt`
- `rockyou.txt.gz`

## rockyou handling

`rockyou.txt.gz` is kept compressed on disk.

When you select `rockyou.txt.gz` as the wordlist, the server will:

- warn that decompression can be slow
- emit a basic progress/ETA line during decompression
- create a temporary uncompressed copy for the duration of the server process
- delete the temporary uncompressed file on server exit

## Run (stdio)

From `Standalone_Build/`:

```bash
./run-mcp-stdio.sh dirscan_mcp_server.server
```

## Call from `pentest-cli`

```text
pentest> call dirscan.wordlists_list {}
pentest> call dirscan.feroxbuster_scan {"url":"https://example.com","wordlist":"dirb/common.txt","threads":50}
pentest> call dirscan.gobuster_scan {"url":"https://example.com","wordlist":"dirb/common.txt","threads":50}
```


```

```python
__all__ = []


```

```python
from __future__ import annotations

import json
import os
from datetime import datetime, timezone
from typing import Any

from pymongo import MongoClient


def save_to_mongo_result(*, tool_name: str, tool_commandline: Any, scan_target: str, data: Any) -> dict[str, Any]:
    uri = os.getenv("MONGO_URI", "").strip()
    if not uri:
        return {"saved": False, "error": "MONGO_URI is not set"}

    db_name = (os.getenv("MONGO_DB", "") or "mcp_db").strip() or "mcp_db"
    coll_name = (os.getenv("MONGO_COLLECTION", "") or "results").strip() or "results"

    doc = {
        "tool_name": (tool_name or "").strip().lower(),
        "date_run": datetime.now(timezone.utc).isoformat(),
        "tool_commandline": json.dumps(tool_commandline, default=str),
        "scan_target": (scan_target or "").strip(),
        "data": data,
    }

    client = MongoClient(uri, serverSelectionTimeoutMS=3000)
    res = client[db_name][coll_name].insert_one(doc)
    return {"saved": True, "type": "mongo", "db": db_name, "collection": coll_name, "inserted_id": str(res.inserted_id)}


```

```python
from __future__ import annotations

import os
import subprocess
from dataclasses import dataclass
from typing import Sequence


class BinaryNotFoundError(RuntimeError):
    pass


@dataclass
class RunResult:
    command: list[str]
    returncode: int
    stdout: str
    stderr: str


def _resolve_bin(env_var: str, fallback: str) -> str:
    p = (os.getenv(env_var, "") or "").strip()
    return p or fallback


def run_cmd(*, argv: Sequence[str], timeout_seconds: int | None = None) -> RunResult:
    cmd = [str(x) for x in argv]
    try:
        cp = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout_seconds,
            check=False,
        )
    except FileNotFoundError:
        raise BinaryNotFoundError(f"{cmd[0]} not found in PATH")
    return RunResult(command=cmd, returncode=int(cp.returncode), stdout=cp.stdout or "", stderr=cp.stderr or "")


def run_feroxbuster(*, args: list[str], timeout_seconds: int | None = None) -> RunResult:
    ferox = _resolve_bin("FEROXBUSTER_BIN", "feroxbuster")
    return run_cmd(argv=[ferox, *args], timeout_seconds=timeout_seconds)


def run_gobuster(*, args: list[str], timeout_seconds: int | None = None) -> RunResult:
    gobuster = _resolve_bin("GOBUSTER_BIN", "gobuster")
    return run_cmd(argv=[gobuster, *args], timeout_seconds=timeout_seconds)


```

```python
from __future__ import annotations

import atexit
import gzip
import os
import time
from pathlib import Path
from typing import Any


class WordlistError(RuntimeError):
    pass


_ROCKYOU_TMP_PATH: Path | None = None


def wordlists_root() -> Path:
    root = (os.getenv("WORDLISTS_ROOT", "") or "/usr/share/wordlists").strip()
    return Path(root).expanduser()


def _ensure_under_root(root: Path, rel: str) -> Path:
    # Disallow absolute paths (we only accept relative identifiers)
    if os.path.isabs(rel):
        raise WordlistError("wordlist must be a relative path under WORDLISTS_ROOT")
    rel2 = rel.strip().lstrip("/").replace("\\", "/")
    if not rel2 or rel2.startswith("..") or "/.." in rel2:
        raise WordlistError("invalid wordlist path")
    p = (root / rel2).resolve()
    root_res = root.resolve()
    if root_res not in p.parents and p != root_res:
        raise WordlistError("wordlist path escapes WORDLISTS_ROOT")
    return p


def list_wordlists(*, subdir: str | None = None, limit: int = 5000, include_sizes: bool = False) -> dict[str, Any]:
    root = wordlists_root()
    if not root.exists():
        raise WordlistError(f"WORDLISTS_ROOT does not exist: {root}")
    base = root
    if subdir:
        base = _ensure_under_root(root, subdir)
        if not base.exists() or not base.is_dir():
            raise WordlistError(f"subdir not found: {subdir}")

    items: list[dict[str, Any]] = []
    count = 0
    for p in sorted(base.rglob("*")):
        if not p.is_file():
            continue
        rel = str(p.relative_to(root)).replace("\\", "/")
        # Do NOT list an uncompressed rockyou temp file if it exists
        if rel.endswith("rockyou.txt"):
            continue
        d: dict[str, Any] = {"name": rel}
        if include_sizes:
            try:
                d["bytes"] = int(p.stat().st_size)
            except Exception:
                d["bytes"] = None
        items.append(d)
        count += 1
        if count >= limit:
            break
    return {"root": str(root), "count": len(items), "items": items, "truncated": (count >= limit)}


def _cleanup_tmp() -> None:
    global _ROCKYOU_TMP_PATH
    p = _ROCKYOU_TMP_PATH
    _ROCKYOU_TMP_PATH = None
    if p and p.exists():
        try:
            p.unlink()
        except Exception:
            pass


atexit.register(_cleanup_tmp)


def resolve_wordlist_for_use(rel_wordlist: str) -> tuple[Path, list[str]]:
    """
    Return a concrete file path to use for scanning.
    If the wordlist is rockyou.txt.gz, decompress to a temp file for this server session.
    Returns (path_to_use, progress_lines)
    """
    root = wordlists_root()
    wl = rel_wordlist.strip()
    if not wl:
        raise WordlistError("wordlist is required")

    src = _ensure_under_root(root, wl)
    if not src.exists() or not src.is_file():
        raise WordlistError(f"wordlist not found: {wl}")

    progress: list[str] = []

    if src.name.lower() == "rockyou.txt.gz":
        global _ROCKYOU_TMP_PATH
        if _ROCKYOU_TMP_PATH and _ROCKYOU_TMP_PATH.exists():
            return _ROCKYOU_TMP_PATH, progress

        progress.append("WARNING: rockyou.txt.gz decompression can be slow and will delay the scan.")
        progress.append("Decompressing rockyou.txt.gz (this happens once per server session)...")

        tmp_dir = Path(os.getenv("DIRSCAN_TMP_DIR", "") or (Path("/tmp") / "dirscan")).expanduser()
        tmp_dir.mkdir(parents=True, exist_ok=True)
        tmp_path = (tmp_dir / "rockyou.txt").resolve()

        gz_size = None
        try:
            gz_size = int(src.stat().st_size)
        except Exception:
            gz_size = None

        start = time.time()
        last_emit = start
        read_bytes = 0
        with gzip.open(src, "rb") as fin, open(tmp_path, "wb") as fout:
            while True:
                chunk = fin.read(1024 * 1024)  # 1MiB
                if not chunk:
                    break
                fout.write(chunk)
                if gz_size is not None:
                    # gzip doesn't expose compressed bytes read; best-effort approximation:
                    # use min(uncompressed_written, gz_size) as a monotonically increasing proxy.
                    read_bytes = min(read_bytes + len(chunk), gz_size)
                now = time.time()
                if now - last_emit >= 2.0:
                    last_emit = now
                    if gz_size:
                        pct = max(0.0, min(100.0, (read_bytes / gz_size) * 100.0))
                        elapsed = max(0.001, now - start)
                        rate = max(1e-9, read_bytes / elapsed)
                        remaining = max(0.0, gz_size - read_bytes)
                        eta = remaining / rate if rate > 0 else None
                        eta_s = f"{int(eta)}s" if eta is not None else "?"
                        progress.append(f"rockyou decompress: ~{pct:0.1f}% (eta ~{eta_s})")
                    else:
                        progress.append("rockyou decompress: working...")

        _ROCKYOU_TMP_PATH = tmp_path
        progress.append("Decompression complete: rockyou.txt is available for this session (will be deleted on server exit).")
        return tmp_path, progress

    return src, progress


```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .mongo_store import save_to_mongo_result
from .runners import BinaryNotFoundError, run_feroxbuster, run_gobuster
from .wordlists import WordlistError, list_wordlists, resolve_wordlist_for_use, wordlists_root


mcp = FastMCP(name="dirscan")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


def _norm_url(url: str) -> str:
    u = (url or "").strip()
    if not u:
        raise ValueError("url is required")
    if not (u.startswith("http://") or u.startswith("https://")):
        raise ValueError("url must start with http:// or https://")
    return u


def _clamp_int(x: int, *, min_value: int, max_value: int, name: str) -> int:
    try:
        v = int(x)
    except Exception:
        raise ValueError(f"{name} must be an integer")
    if v < min_value or v > max_value:
        raise ValueError(f"{name} must be between {min_value} and {max_value}")
    return v


@mcp.tool()
@register_tool
def wordlists_list(
    subdir: str | None = None,
    limit: int = 5000,
    include_sizes: bool = False,
) -> dict[str, Any]:
    """
    List wordlists under WORDLISTS_ROOT (default: /usr/share/wordlists).

    - Returns only relative names (no full paths).
    - `subdir` is also relative to WORDLISTS_ROOT.
    - `rockyou.txt` is not listed (if a temp copy exists); `rockyou.txt.gz` is listed.
    """
    try:
        limit = _clamp_int(limit, min_value=1, max_value=200000, name="limit")
        return _tool_ok(list_wordlists(subdir=subdir, limit=limit, include_sizes=include_sizes), meta={"wordlists_root": str(wordlists_root())})
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})


@mcp.tool()
@register_tool
def feroxbuster_scan(
    url: str,
    wordlist: str,
    extensions: list[str] | None = None,
    threads: int = 50,
    depth: int | None = None,
    timeout_seconds: int | None = 900,
    json_output: bool = False,
    extra_args: list[str] | None = None,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run feroxbuster against a target URL using a wordlist under WORDLISTS_ROOT.

    `wordlist` must be a relative path under WORDLISTS_ROOT, e.g. `dirb/common.txt` or `rockyou.txt.gz`.
    If `wordlist` is `rockyou.txt.gz`, it will be decompressed once per server session (warning + progress).
    """
    try:
        u = _norm_url(url)
        threads2 = _clamp_int(threads, min_value=1, max_value=2000, name="threads")
        if depth is not None:
            depth = _clamp_int(depth, min_value=0, max_value=50, name="depth")
    except ValueError as e:
        return _tool_error(str(e))

    try:
        wl_path, progress = resolve_wordlist_for_use(wordlist)
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})

    args: list[str] = ["-u", u, "-w", str(wl_path), "-t", str(threads2)]
    if depth is not None:
        args.extend(["--depth", str(depth)])
    if extensions:
        exts = [x.strip().lstrip(".") for x in extensions if (x or "").strip()]
        if exts:
            args.extend(["-x", ",".join(exts)])
    if json_output:
        args.append("--json")
    if extra_args:
        # safe wrapper: we don't allow obvious file-write flags here
        blocked = {"-o", "--output", "--config", "--stdin"}
        if any(a in blocked for a in extra_args):
            return _tool_error("extra_args contains blocked flags (use feroxbuster_scan_raw with i_acknowledge_risk=true)")
        args.extend(extra_args)

    try:
        rr = run_feroxbuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install feroxbuster or set FEROXBUSTER_BIN"})

    stdout = rr.stdout
    if progress:
        stdout = "\n".join(progress) + "\n\n" + stdout

    payload: dict[str, Any] = {"stdout": stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command, "wordlists_root": str(wordlists_root()), "wordlist_used": str(wl_path)}

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(
                tool_name="feroxbuster",
                tool_commandline=rr.command,
                scan_target=u,
                data={"result": payload, "meta": meta},
            )
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def gobuster_scan(
    url: str,
    wordlist: str,
    extensions: list[str] | None = None,
    threads: int = 50,
    timeout_seconds: int | None = 900,
    extra_args: list[str] | None = None,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run gobuster dir against a target URL using a wordlist under WORDLISTS_ROOT.

    `wordlist` must be a relative path under WORDLISTS_ROOT, e.g. `dirb/common.txt` or `rockyou.txt.gz`.
    If `wordlist` is `rockyou.txt.gz`, it will be decompressed once per server session (warning + progress).
    """
    try:
        u = _norm_url(url)
        threads2 = _clamp_int(threads, min_value=1, max_value=2000, name="threads")
    except ValueError as e:
        return _tool_error(str(e))

    try:
        wl_path, progress = resolve_wordlist_for_use(wordlist)
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})

    args: list[str] = ["dir", "-u", u, "-w", str(wl_path), "-t", str(threads2)]
    if extensions:
        exts = [x.strip().lstrip(".") for x in extensions if (x or "").strip()]
        if exts:
            args.extend(["-x", ",".join(exts)])
    if extra_args:
        blocked = {"-o", "--output", "--no-color"}  # keep output on stdout; allow colors via cli if desired
        if any(a in blocked for a in extra_args):
            return _tool_error("extra_args contains blocked flags (use gobuster_scan_raw with i_acknowledge_risk=true)")
        args.extend(extra_args)

    try:
        rr = run_gobuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install gobuster or set GOBUSTER_BIN"})

    stdout = rr.stdout
    if progress:
        stdout = "\n".join(progress) + "\n\n" + stdout

    payload: dict[str, Any] = {"stdout": stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command, "wordlists_root": str(wordlists_root()), "wordlist_used": str(wl_path)}

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(
                tool_name="gobuster",
                tool_commandline=rr.command,
                scan_target=u,
                data={"result": payload, "meta": meta},
            )
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def feroxbuster_scan_raw(
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run feroxbuster with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    try:
        rr = run_feroxbuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install feroxbuster or set FEROXBUSTER_BIN"})
    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(tool_name="feroxbuster", tool_commandline=rr.command, scan_target="", data={"result": payload, "meta": meta})
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}
    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def gobuster_scan_raw(
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run gobuster with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    try:
        rr = run_gobuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install gobuster or set GOBUSTER_BIN"})
    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(tool_name="gobuster", tool_commandline=rr.command, scan_target="", data={"result": payload, "meta": meta})
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}
    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    if transport == "stdio":
        mcp.run(transport="stdio")
        return
    # Optional HTTP transports
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port = int(os.getenv("MCP_PORT", "4605"))
    path = os.getenv("MCP_PATH", "").strip() or None
    mcp.run(transport=transport, host=host, port=port, path=path)


if __name__ == "__main__":
    main()


```

```jsonc
{
  "mcpServers": {
    "portscan": {
      "command": "./run-mcp-stdio.sh",
      "args": ["pentest_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "pdtm": {
      "command": "./run-mcp-stdio.sh",
      "args": ["pdtm_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "shodan": {
      "command": "./run-mcp-stdio.sh",
      "args": ["shodan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searchsploit": {
      "command": "./run-mcp-stdio.sh",
      "args": ["searchsploit_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "searx": {
      "command": "./run-mcp-stdio.sh",
      "args": ["searx_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "theharvester": {
      "command": "./run-mcp-stdio.sh",
      "args": ["theharvester_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "wpscan": {
      "command": "./run-mcp-stdio.sh",
      "args": ["wpscan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "mongo": {
      "command": "./run-mcp-stdio.sh",
      "args": ["mongo_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    },
    "dirscan": {
      "command": "./run-mcp-stdio.sh",
      "args": ["dirscan_mcp_server.server"],
      "env": { "MCP_TRANSPORT": "stdio" }
    }
  }
}



```

```markdown
# Installation / Packaging (Standalone_Build)

This document explains how to install and package the **Standalone_Build** MCP toolchain so it runs on:

- **macOS**
- **Linux**

The goal is: run `pentest-cli`, which autoloads the MCP servers from `Standalone_Build/mcp.json`, and then call tools as:

- `portscan.nmap_scan`
- `shodan.shodan_search`
- etc.

---

## What you move between systems

Copy this whole directory:

- `Standalone_Build/` (everything inside)

You typically **do not** copy:

- `Standalone_Build/.venv/` (recreate it per-machine; faster + more reliable)
- `Standalone_Build/logs/` (optional; regenerated)

---

## 0) Prereqs (both macOS + Linux)

- **Python 3.11+** (recommended)
- `git`
- A working C toolchain (needed by some Python deps on some systems)
- External binaries you want to use (see per-platform sections below)

---

## 1) Configure environment (`Standalone_Build/.env`)

Create `Standalone_Build/.env` on the target machine (do not commit secrets). Typical variables:

```bash
# Mongo (optional but recommended)
MONGO_URI="mongodb://127.0.0.1:27017/mcp_db"
MONGO_DB="mcp_db"
MONGO_COLLECTION="results"

# API tokens (optional, per server)
SHODAN_API_KEY="..."
WPSCAN_API_TOKEN="..."

# Optional: override binary paths if not in PATH
# NMAP_BIN="/usr/bin/nmap"
# NAABU_BIN="/usr/local/bin/naabu"
# RUSTSCAN_BIN="/usr/local/bin/rustscan"
```

Notes:
- `run-mcp-stdio.sh` loads this `.env` before launching servers.
- `pentest-cli` also auto-loads `Standalone_Build/.env` by default (set `PENTEST_CLI_NO_DOTENV=1` to disable).

---

## 2) macOS install

### System packages

Using Homebrew:

```bash
brew install python@3.11 git
brew install nmap
```

Optional scanners:

```bash
brew install rustscan
brew install naabu
brew install feroxbuster
brew install gobuster
```

Other tool servers (optional):

```bash
brew install exploitdb    # provides searchsploit + exploit db
brew install mongosh      # optional client
```

WPScan and theHarvester are often easiest via their own installers / language ecosystems; if you don’t install them, the MCP wrappers still run but tool calls will fail with “binary not found”.

### Create venv + install Python deps + local packages

From your copied `Standalone_Build/`:

```bash
cd "Standalone_Build"
python3.11 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip

# Install pinned 3rd-party deps
pip install -r requirements.txt

# Install all local MCP packages + CLI
pip install -e ./pentest-cli \
            -e ./pentest-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### Run

```bash
pentest-cli
```

---

## 3) Linux install

### System packages (Debian/Ubuntu example)

```bash
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv python3-pip git ca-certificates
sudo apt-get install -y nmap
```

Optional scanners:

```bash
# rustscan: see https://github.com/RustScan/RustScan releases
# naabu: see https://github.com/projectdiscovery/naabu releases
# feroxbuster: see https://github.com/epi052/feroxbuster
# gobuster: see https://github.com/OJ/gobuster
```

Searchsploit:

```bash
sudo apt-get install -y exploitdb
```

Wordlists (Kali / Debian-based):

```bash
sudo apt-get install -y wordlists
```

### Create venv + install Python deps + local packages

```bash
cd "Standalone_Build"
python3.11 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip
pip install -r requirements.txt

pip install -e ./pentest-cli \
            -e ./pentest-mcp-server \
            -e ./dirscan-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### Run

```bash
./.venv/bin/pentest-cli
```

---

## 4) How the CLI finds/launches servers (portable config)

- `pentest-cli` reads server definitions from: `Standalone_Build/mcp.json`
- Each entry points to `./run-mcp-stdio.sh <python_module>`
- The CLI resolves `./run-mcp-stdio.sh` **relative to the config file**, so you can move `Standalone_Build/` without editing paths.

Server logs (stderr) are written to:

- `Standalone_Build/logs/<module>.stderr.log`

---

## 5) Packaging / moving to other machines

### Recommended approach (rebuild venv per machine)

1. Copy `Standalone_Build/` to the new machine
2. Install host binaries you need (nmap, rustscan, etc.)
3. Create `Standalone_Build/.env`
4. Recreate `.venv` and install:
   - `pip install -r requirements.txt`
   - `pip install -e ...` local packages

### Offline / airgapped installs (optional)

On a machine with internet:

```bash
cd Standalone_Build
source .venv/bin/activate
mkdir -p wheels
pip download -r requirements.txt -d wheels
```

Copy `Standalone_Build/` (including `wheels/`) to the offline machine, then:

```bash
cd Standalone_Build
python3.11 -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install --no-index --find-links wheels -r requirements.txt
pip install -e ./pentest-cli -e ./pentest-mcp-server -e ./pdtm-mcp-server -e ./shodan-mcp-server -e ./searchsploit-mcp-server -e ./searx-mcp-server -e ./theharvester-mcp-server -e ./wpscan-mcp-server -e ./mongo-mcp-server
```

---

## 6) Quick validation checklist

Inside the CLI:

```text
pentest> tools portscan
pentest> describe portscan.nmap_scan
pentest> call portscan.nmap_scan {"targets":["127.0.0.1"],"args":["-p","1-10","-sT"],"force_unprivileged":true}
```

If Mongo is configured:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

## 7) Dir scanning (dirscan server)

The `dirscan` MCP server wraps:

- feroxbuster ([repo](https://github.com/epi052/feroxbuster), [docs](https://epi052.github.io/feroxbuster-docs/overview/))
- gobuster (`https://github.com/OJ/gobuster`)

It expects wordlists under `WORDLISTS_ROOT` (default `/usr/share/wordlists`), matching the Kali `wordlists` package (`https://gitlab.com/kalilinux/packages/wordlists`).

Examples:

```text
pentest> call dirscan.wordlists_list {}
pentest> call dirscan.feroxbuster_scan {"url":"https://example.com","wordlist":"dirb/common.txt","threads":50}
pentest> call dirscan.gobuster_scan {"url":"https://example.com","wordlist":"dirb/common.txt","threads":50}
```

Note: if you use `rockyou.txt.gz` as the wordlist, the server will warn and show progress while it decompresses it once per server session.



```

```markdown
# Standalone_Build (local / terminal MCP servers)

`Standalone_Build/` is the **local-first** (non-Podman) version of the MCP servers in this repo.

- The original Podman servers (at the repo root) are kept intact as read-only references.
- The standalone copies live here and are safe to modify.
- Default transport is **stdio** so Cursor can launch them as **command MCP servers**.

## Quickstart (recommended)

### 1) Install required host binaries (per tool)

You must install the underlying CLI tools on your host, or set `*_BIN` env vars to point at them.

**Port scanning (coordinator):**
- `rustscan` (or `RUSTSCAN_BIN=/path/to/rustscan`)
- `nmap` (or `NMAP_BIN=/path/to/nmap`)
- `naabu` (or `NAABU_BIN=/path/to/naabu`)

Other standalone servers in this directory have their own host dependencies (WPScan, theHarvester, Searchsploit, etc.).

### 2) Create a single shared Python venv (recommended) and install all servers

Each server directory here is a standalone Python package with a `pyproject.toml`, but you can (and should) run them all from a **single shared venv** to keep Cursor config simple.

Create the shared venv at `Standalone_Build/.venv` and install all servers into it:

```bash
cd "Standalone_Build"
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install -e ./pentest-mcp-server \
            -e ./portscan-mcp-server \
            -e ./dirscan-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server \
            -e ./pentest-cli
```

### 3) Run (recommended: `pentest-cli`)

From inside `Standalone_Build/` (venv active), start the interactive CLI:

```bash
pentest-cli
```

Notes:
- The CLI autoloads all servers from `Standalone_Build/mcp.json` so you can call tools as `server.tool` (for example `portscan.nmap_scan` or `shodan.shodan_search`).
- FastMCP banners/logs are written to `Standalone_Build/logs/*.stderr.log` (so the CLI stays readable).

## Cursor MCP configuration (stdio command server)

Cursor uses stdio “command” MCP servers. A typical `.cursor/mcp.json` entry looks like:

```json
{
  "mcpServers": {
    "portscan": {
      "command": "python",
      "args": ["-m", "pentest_mcp_server.server"],
      "env": {
        "MCP_TRANSPORT": "stdio",
        "LOG_LEVEL": "INFO"
      }
    }
  }
}
```

Notes:
- This assumes `pentest-mcp-server` was installed into the Python environment Cursor will use to launch the command.
- If you prefer, you can set `command` to an absolute path to the venv Python (recommended for reliability).



```

### Added: `dirscan` MCP server (Standalone_Build)
Implemented a new standalone MCP server at `Standalone_Build/dirscan-mcp-server/` and wired it into `Standalone_Build/mcp.json` as **`dirscan`**.

### Tools included (called via `pentest-cli`)
- **`dirscan.wordlists_list`**: lists wordlists under a configurable base path **without showing the full directory** (only relative paths like `dirb/common.txt`, `rockyou.txt.gz`)
- **`dirscan.feroxbuster_scan`**: runs a directory scan using **feroxbuster** ([repo](https://github.com/epi052/feroxbuster), [docs](https://epi052.github.io/feroxbuster-docs/overview/))
- **`dirscan.gobuster_scan`**: runs a directory scan using **gobuster** (`https://github.com/OJ/gobuster`)
- Plus raw-mode variants (require `i_acknowledge_risk=true`): `dirscan.feroxbuster_scan_raw`, `dirscan.gobuster_scan_raw`

### Wordlists base path + rockyou behavior
- The server uses **`WORDLISTS_ROOT`** (default `/usr/share/wordlists`) intended to match Kali’s `wordlists` package (`https://gitlab.com/kalilinux/packages/wordlists`).
- **`rockyou.txt.gz` stays compressed** and is only decompressed when selected as the wordlist:
  - emits a warning + basic progress/ETA lines
  - creates a temporary `rockyou.txt` for the **server session**
  - deletes the uncompressed file **on server exit**

### Docs + packaging updates
- Added **`Standalone_Build/INSTALLATION.md`** section documenting `dirscan` prerequisites and usage.
- Updated `Standalone_Build/README.md` to include installing `-e ./dirscan-mcp-server`.
- Added pinned `Standalone_Build/requirements.txt`.

### Smoke test result
`dirscan` loads correctly (now `mcp.json` shows **9 servers**). On my machine here, `wordlists_list` correctly errors because `/usr/share/wordlists` isn’t present—set `WORDLISTS_ROOT` in `Standalone_Build/.env` (or install the `wordlists` package on Linux) and it will work.

---

**User**

I receive the following error when trying to call dirsca .wordlists_list:

pentest>  call dirscan.wordlists_list {}
──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Tool returned ok=false
  error: WORDLISTS_ROOT does not exist: /usr/share/wordlists
  details: {
  "wordlists_root": "/usr/share/wordlists"
}

---

**Cursor**

Plan: I’ll make `dirscan` more portable by (1) letting it auto-detect a wordlists directory if `/usr/share/wordlists` doesn’t exist (including `Standalone_Build/wordlists`), and (2) making `run-mcp-stdio.sh` `cd` into `Standalone_Build/` so relative paths work reliably. Then you’ll just set `WORDLISTS_ROOT` (or drop wordlists into `Standalone_Build/wordlists`) and restart `pentest-cli`.

```shellscript
#!/usr/bin/env bash
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
ENV_FILE="$SCRIPT_DIR/.env"

if [[ -f "$ENV_FILE" ]]; then
  set -a
  # shellcheck disable=SC1090
  source "$ENV_FILE"
  set +a
fi

# Ensure any relative paths in env vars (e.g., WORDLISTS_ROOT=wordlists) are
# resolved consistently, regardless of where the CLI is launched from.
cd "$SCRIPT_DIR"

PY="$SCRIPT_DIR/.venv/bin/python"
if [[ ! -x "$PY" ]]; then
  echo "Missing shared venv python at: $PY" >&2
  echo "Create it with: cd $SCRIPT_DIR && python -m venv .venv && ./.venv/bin/pip install -e <servers>" >&2
  exit 2
fi

if [[ $# -lt 1 ]]; then
  echo "Usage: $0 <python_module> [args...]" >&2
  echo "Example: $0 pentest_mcp_server.server" >&2
  exit 2
fi

MODULE="$1"
shift

LOG_DIR="$SCRIPT_DIR/logs"
mkdir -p "$LOG_DIR"
LOG_FILE="$LOG_DIR/${MODULE//./_}.stderr.log"

# MCP protocol is on stdout; FastMCP logs/banners go to stderr. We keep stderr out of
# the CLI UI by redirecting it to a per-module log file.
exec "$PY" -m "$MODULE" "$@" 2>>"$LOG_FILE"

```

```python
from __future__ import annotations

import atexit
import gzip
import os
import time
from pathlib import Path
from typing import Any


class WordlistError(RuntimeError):
    pass


_ROCKYOU_TMP_PATH: Path | None = None


def wordlists_root() -> Path:
    # Explicit override (recommended)
    env_root = (os.getenv("WORDLISTS_ROOT", "") or "").strip()
    if env_root:
        return Path(env_root).expanduser()

    # Auto-detect common locations
    candidates = [
        "/usr/share/wordlists",  # Debian/Kali wordlists package
        "/usr/local/share/wordlists",
        "/opt/homebrew/share/wordlists",  # possible Homebrew layout
        "/opt/homebrew/share/seclists",  # common on macOS if using SecLists via Homebrew
        str(Path.cwd() / "wordlists"),  # Standalone_Build/wordlists when launched via run-mcp-stdio.sh
    ]
    for c in candidates:
        p = Path(c).expanduser()
        if p.exists() and p.is_dir():
            return p

    # Default fallback (what the user sees in errors)
    return Path("/usr/share/wordlists")


def _ensure_under_root(root: Path, rel: str) -> Path:
    # Disallow absolute paths (we only accept relative identifiers)
    if os.path.isabs(rel):
        raise WordlistError("wordlist must be a relative path under WORDLISTS_ROOT")
    rel2 = rel.strip().lstrip("/").replace("\\", "/")
    if not rel2 or rel2.startswith("..") or "/.." in rel2:
        raise WordlistError("invalid wordlist path")
    p = (root / rel2).resolve()
    root_res = root.resolve()
    if root_res not in p.parents and p != root_res:
        raise WordlistError("wordlist path escapes WORDLISTS_ROOT")
    return p


def list_wordlists(*, subdir: str | None = None, limit: int = 5000, include_sizes: bool = False) -> dict[str, Any]:
    root = wordlists_root()
    if not root.exists():
        raise WordlistError(f"WORDLISTS_ROOT does not exist: {root}")
    base = root
    if subdir:
        base = _ensure_under_root(root, subdir)
        if not base.exists() or not base.is_dir():
            raise WordlistError(f"subdir not found: {subdir}")

    items: list[dict[str, Any]] = []
    count = 0
    for p in sorted(base.rglob("*")):
        if not p.is_file():
            continue
        rel = str(p.relative_to(root)).replace("\\", "/")
        # Do NOT list an uncompressed rockyou temp file if it exists
        if rel.endswith("rockyou.txt"):
            continue
        d: dict[str, Any] = {"name": rel}
        if include_sizes:
            try:
                d["bytes"] = int(p.stat().st_size)
            except Exception:
                d["bytes"] = None
        items.append(d)
        count += 1
        if count >= limit:
            break
    return {"root": str(root), "count": len(items), "items": items, "truncated": (count >= limit)}


def _cleanup_tmp() -> None:
    global _ROCKYOU_TMP_PATH
    p = _ROCKYOU_TMP_PATH
    _ROCKYOU_TMP_PATH = None
    if p and p.exists():
        try:
            p.unlink()
        except Exception:
            pass


atexit.register(_cleanup_tmp)


def resolve_wordlist_for_use(rel_wordlist: str) -> tuple[Path, list[str]]:
    """
    Return a concrete file path to use for scanning.
    If the wordlist is rockyou.txt.gz, decompress to a temp file for this server session.
    Returns (path_to_use, progress_lines)
    """
    root = wordlists_root()
    wl = rel_wordlist.strip()
    if not wl:
        raise WordlistError("wordlist is required")

    src = _ensure_under_root(root, wl)
    if not src.exists() or not src.is_file():
        raise WordlistError(f"wordlist not found: {wl}")

    progress: list[str] = []

    if src.name.lower() == "rockyou.txt.gz":
        global _ROCKYOU_TMP_PATH
        if _ROCKYOU_TMP_PATH and _ROCKYOU_TMP_PATH.exists():
            return _ROCKYOU_TMP_PATH, progress

        progress.append("WARNING: rockyou.txt.gz decompression can be slow and will delay the scan.")
        progress.append("Decompressing rockyou.txt.gz (this happens once per server session)...")

        tmp_dir = Path(os.getenv("DIRSCAN_TMP_DIR", "") or (Path("/tmp") / "dirscan")).expanduser()
        tmp_dir.mkdir(parents=True, exist_ok=True)
        tmp_path = (tmp_dir / "rockyou.txt").resolve()

        gz_size = None
        try:
            gz_size = int(src.stat().st_size)
        except Exception:
            gz_size = None

        start = time.time()
        last_emit = start
        read_bytes = 0
        with gzip.open(src, "rb") as fin, open(tmp_path, "wb") as fout:
            while True:
                chunk = fin.read(1024 * 1024)  # 1MiB
                if not chunk:
                    break
                fout.write(chunk)
                if gz_size is not None:
                    # gzip doesn't expose compressed bytes read; best-effort approximation:
                    # use min(uncompressed_written, gz_size) as a monotonically increasing proxy.
                    read_bytes = min(read_bytes + len(chunk), gz_size)
                now = time.time()
                if now - last_emit >= 2.0:
                    last_emit = now
                    if gz_size:
                        pct = max(0.0, min(100.0, (read_bytes / gz_size) * 100.0))
                        elapsed = max(0.001, now - start)
                        rate = max(1e-9, read_bytes / elapsed)
                        remaining = max(0.0, gz_size - read_bytes)
                        eta = remaining / rate if rate > 0 else None
                        eta_s = f"{int(eta)}s" if eta is not None else "?"
                        progress.append(f"rockyou decompress: ~{pct:0.1f}% (eta ~{eta_s})")
                    else:
                        progress.append("rockyou decompress: working...")

        _ROCKYOU_TMP_PATH = tmp_path
        progress.append("Decompression complete: rockyou.txt is available for this session (will be deleted on server exit).")
        return tmp_path, progress

    return src, progress



```

```markdown
# Installation / Packaging (Standalone_Build)

This document explains how to install and package the **Standalone_Build** MCP toolchain so it runs on:

- **macOS**
- **Linux**

The goal is: run `pentest-cli`, which autoloads the MCP servers from `Standalone_Build/mcp.json`, and then call tools as:

- `portscan.nmap_scan`
- `shodan.shodan_search`
- etc.

---

## What you move between systems

Copy this whole directory:

- `Standalone_Build/` (everything inside)

You typically **do not** copy:

- `Standalone_Build/.venv/` (recreate it per-machine; faster + more reliable)
- `Standalone_Build/logs/` (optional; regenerated)

---

## 0) Prereqs (both macOS + Linux)

- **Python 3.11+** (recommended)
- `git`
- A working C toolchain (needed by some Python deps on some systems)
- External binaries you want to use (see per-platform sections below)

---

## 1) Configure environment (`Standalone_Build/.env`)

Create `Standalone_Build/.env` on the target machine (do not commit secrets). Typical variables:

```bash
# Mongo (optional but recommended)
MONGO_URI="mongodb://127.0.0.1:27017/mcp_db"
MONGO_DB="mcp_db"
MONGO_COLLECTION="results"

# API tokens (optional, per server)
SHODAN_API_KEY="..."
WPSCAN_API_TOKEN="..."

# Optional: override binary paths if not in PATH
# NMAP_BIN="/usr/bin/nmap"
# NAABU_BIN="/usr/local/bin/naabu"
# RUSTSCAN_BIN="/usr/local/bin/rustscan"

# Dir scanning wordlists root (recommended)
# - Linux/Kali typically: /usr/share/wordlists
# - You can also place wordlists under Standalone_Build/wordlists and set:
# WORDLISTS_ROOT="/absolute/path/to/Standalone_Build/wordlists"
```

Notes:
- `run-mcp-stdio.sh` loads this `.env` before launching servers.
- `pentest-cli` also auto-loads `Standalone_Build/.env` by default (set `PENTEST_CLI_NO_DOTENV=1` to disable).

---

## 2) macOS install

### System packages

Using Homebrew:

```bash
brew install python@3.11 git
brew install nmap
```

Optional scanners:

```bash
brew install rustscan
brew install naabu
brew install feroxbuster
brew install gobuster
```

Other tool servers (optional):

```bash
brew install exploitdb    # provides searchsploit + exploit db
brew install mongosh      # optional client
```

WPScan and theHarvester are often easiest via their own installers / language ecosystems; if you don’t install them, the MCP wrappers still run but tool calls will fail with “binary not found”.

### Create venv + install Python deps + local packages

From your copied `Standalone_Build/`:

```bash
cd "Standalone_Build"
python3.11 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip

# Install pinned 3rd-party deps
pip install -r requirements.txt

# Install all local MCP packages + CLI
pip install -e ./pentest-cli \
            -e ./pentest-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### Run

```bash
pentest-cli
```

---

## 3) Linux install

### System packages (Debian/Ubuntu example)

```bash
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv python3-pip git ca-certificates
sudo apt-get install -y nmap
```

Optional scanners:

```bash
# rustscan: see https://github.com/RustScan/RustScan releases
# naabu: see https://github.com/projectdiscovery/naabu releases
# feroxbuster: see https://github.com/epi052/feroxbuster
# gobuster: see https://github.com/OJ/gobuster
```

Searchsploit:

```bash
sudo apt-get install -y exploitdb
```

Wordlists (Kali / Debian-based):

```bash
sudo apt-get install -y wordlists
```

### Create venv + install Python deps + local packages

```bash
cd "Standalone_Build"
python3.11 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip
pip install -r requirements.txt

pip install -e ./pentest-cli \
            -e ./pentest-mcp-server \
            -e ./dirscan-mcp-server \
            -e ./pdtm-mcp-server \
            -e ./shodan-mcp-server \
            -e ./searchsploit-mcp-server \
            -e ./searx-mcp-server \
            -e ./theharvester-mcp-server \
            -e ./wpscan-mcp-server \
            -e ./mongo-mcp-server
```

### Run

```bash
./.venv/bin/pentest-cli
```

---

## 4) How the CLI finds/launches servers (portable config)

- `pentest-cli` reads server definitions from: `Standalone_Build/mcp.json`
- Each entry points to `./run-mcp-stdio.sh <python_module>`
- The CLI resolves `./run-mcp-stdio.sh` **relative to the config file**, so you can move `Standalone_Build/` without editing paths.

Server logs (stderr) are written to:

- `Standalone_Build/logs/<module>.stderr.log`

---

## 5) Packaging / moving to other machines

### Recommended approach (rebuild venv per machine)

1. Copy `Standalone_Build/` to the new machine
2. Install host binaries you need (nmap, rustscan, etc.)
3. Create `Standalone_Build/.env`
4. Recreate `.venv` and install:
   - `pip install -r requirements.txt`
   - `pip install -e ...` local packages

### Offline / airgapped installs (optional)

On a machine with internet:

```bash
cd Standalone_Build
source .venv/bin/activate
mkdir -p wheels
pip download -r requirements.txt -d wheels
```

Copy `Standalone_Build/` (including `wheels/`) to the offline machine, then:

```bash
cd Standalone_Build
python3.11 -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install --no-index --find-links wheels -r requirements.txt
pip install -e ./pentest-cli -e ./pentest-mcp-server -e ./pdtm-mcp-server -e ./shodan-mcp-server -e ./searchsploit-mcp-server -e ./searx-mcp-server -e ./theharvester-mcp-server -e ./wpscan-mcp-server -e ./mongo-mcp-server
```

---

## 6) Quick validation checklist

Inside the CLI:

```text
pentest> tools portscan
pentest> describe portscan.nmap_scan
pentest> call portscan.nmap_scan {"targets":["127.0.0.1"],"args":["-p","1-10","-sT"],"force_unprivileged":true}
```

If Mongo is configured:

```text
pentest> mongo-find-one {"tool_name":"nmap"}
```

## 7) Dir scanning (dirscan server)

The `dirscan` MCP server wraps:

- feroxbuster ([repo](https://github.com/epi052/feroxbuster), [docs](https://epi052.github.io/feroxbuster-docs/overview/))
- gobuster (`https://github.com/OJ/gobuster`)

It expects wordlists under `WORDLISTS_ROOT` (default `/usr/share/wordlists`), matching the Kali `wordlists` package (`https://gitlab.com/kalilinux/packages/wordlists`).

Examples:

```text
pentest> call dirscan.wordlists_list {}
pentest> call dirscan.feroxbuster_scan {"url":"https://example.com","wordlist":"dirb/common.txt","threads":50}
pentest> call dirscan.gobuster_scan {"url":"https://example.com","wordlist":"dirb/common.txt","threads":50}
```

Note: if you use `rockyou.txt.gz` as the wordlist, the server will warn and show progress while it decompresses it once per server session.



```

That error means your system doesn’t have the Kali/Debian `wordlists` directory at the default location (`/usr/share/wordlists`). This is expected on macOS, and on many non-Kali Linux installs.

### Fix options

#### Option A (Linux/Kali): install the wordlists package
On Debian/Kali/Ubuntu:

```bash
sudo apt-get update
sudo apt-get install -y wordlists
```

That typically creates `/usr/share/wordlists` (including `rockyou.txt.gz`), and `dirscan.wordlists_list` will work with no config changes.

#### Option B (macOS / any OS): set `WORDLISTS_ROOT` to where your wordlists live
1) Put your wordlists somewhere (recommended: inside this repo so it’s portable):

- Create: `Standalone_Build/wordlists/`
- Copy wordlists into it (e.g. `dirb/common.txt`, `rockyou.txt.gz`, etc.)

2) Set `WORDLISTS_ROOT` in `Standalone_Build/.env` to an **absolute path**, e.g.:

```bash
WORDLISTS_ROOT="/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/wordlists"
```

3) **Restart `pentest-cli`** (important). Since it autoloads servers at startup, environment changes won’t apply until restart.

### Improvements I made (so this is easier going forward)
- `dirscan` now **auto-detects** common wordlists locations (including `Standalone_Build/wordlists`).
- `run-mcp-stdio.sh` now `cd`s into `Standalone_Build/`, so relative paths like `WORDLISTS_ROOT=wordlists` behave consistently.

If you tell me where you want to store wordlists on your Mac, I can recommend the cleanest path (portable vs system-wide).

```shellscript
sudo apt-get update
sudo apt-get install -y wordlists
```

```shellscript
WORDLISTS_ROOT="/Users/pkincaid/Documents/bin/joesgarage.ai - AI Projects/MCP_Servers/Standalone_Build/wordlists"
```

---

**User**

the dirscan.wordlists_list is printing out in JSON, can you please have it print out just the paths and names of the wordlists?

---

**Cursor**

Plan: I’ll change `dirscan.wordlists_list` to return a normal `{stdout, stderr}` payload (like the scan tools), where `stdout` is just newline-separated wordlist relative paths. Then `pentest-cli` will print it as plain text instead of dumping JSON.

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .mongo_store import save_to_mongo_result
from .runners import BinaryNotFoundError, run_feroxbuster, run_gobuster
from .wordlists import WordlistError, list_wordlists, resolve_wordlist_for_use, wordlists_root


mcp = FastMCP(name="dirscan")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


def _norm_url(url: str) -> str:
    u = (url or "").strip()
    if not u:
        raise ValueError("url is required")
    if not (u.startswith("http://") or u.startswith("https://")):
        raise ValueError("url must start with http:// or https://")
    return u


def _clamp_int(x: int, *, min_value: int, max_value: int, name: str) -> int:
    try:
        v = int(x)
    except Exception:
        raise ValueError(f"{name} must be an integer")
    if v < min_value or v > max_value:
        raise ValueError(f"{name} must be between {min_value} and {max_value}")
    return v


@mcp.tool()
@register_tool
def wordlists_list(
    subdir: str | None = None,
    limit: int = 5000,
    include_sizes: bool = False,
) -> dict[str, Any]:
    """
    List wordlists under WORDLISTS_ROOT (default: /usr/share/wordlists).

    - Returns only relative names (no full paths).
    - `subdir` is also relative to WORDLISTS_ROOT.
    - `rockyou.txt` is not listed (if a temp copy exists); `rockyou.txt.gz` is listed.
    """
    try:
        limit = _clamp_int(limit, min_value=1, max_value=200000, name="limit")
        listing = list_wordlists(subdir=subdir, limit=limit, include_sizes=include_sizes)
        lines: list[str] = []
        for item in (listing.get("items") or []):
            if not isinstance(item, dict):
                continue
            name = item.get("name")
            if not isinstance(name, str) or not name.strip():
                continue
            if include_sizes and ("bytes" in item):
                b = item.get("bytes")
                if isinstance(b, int):
                    lines.append(f"{name} ({b} bytes)")
                else:
                    lines.append(name)
            else:
                lines.append(name)

        payload = {"stdout": "\n".join(lines) + ("\n" if lines else ""), "stderr": ""}
        return _tool_ok(
            payload,
            meta={
                "wordlists_root": str(wordlists_root()),
                "count": listing.get("count"),
                "truncated": listing.get("truncated"),
            },
        )
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})


@mcp.tool()
@register_tool
def feroxbuster_scan(
    url: str,
    wordlist: str,
    extensions: list[str] | None = None,
    threads: int = 50,
    depth: int | None = None,
    timeout_seconds: int | None = 900,
    json_output: bool = False,
    extra_args: list[str] | None = None,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run feroxbuster against a target URL using a wordlist under WORDLISTS_ROOT.

    `wordlist` must be a relative path under WORDLISTS_ROOT, e.g. `dirb/common.txt` or `rockyou.txt.gz`.
    If `wordlist` is `rockyou.txt.gz`, it will be decompressed once per server session (warning + progress).
    """
    try:
        u = _norm_url(url)
        threads2 = _clamp_int(threads, min_value=1, max_value=2000, name="threads")
        if depth is not None:
            depth = _clamp_int(depth, min_value=0, max_value=50, name="depth")
    except ValueError as e:
        return _tool_error(str(e))

    try:
        wl_path, progress = resolve_wordlist_for_use(wordlist)
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})

    args: list[str] = ["-u", u, "-w", str(wl_path), "-t", str(threads2)]
    if depth is not None:
        args.extend(["--depth", str(depth)])
    if extensions:
        exts = [x.strip().lstrip(".") for x in extensions if (x or "").strip()]
        if exts:
            args.extend(["-x", ",".join(exts)])
    if json_output:
        args.append("--json")
    if extra_args:
        # safe wrapper: we don't allow obvious file-write flags here
        blocked = {"-o", "--output", "--config", "--stdin"}
        if any(a in blocked for a in extra_args):
            return _tool_error("extra_args contains blocked flags (use feroxbuster_scan_raw with i_acknowledge_risk=true)")
        args.extend(extra_args)

    try:
        rr = run_feroxbuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install feroxbuster or set FEROXBUSTER_BIN"})

    stdout = rr.stdout
    if progress:
        stdout = "\n".join(progress) + "\n\n" + stdout

    payload: dict[str, Any] = {"stdout": stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command, "wordlists_root": str(wordlists_root()), "wordlist_used": str(wl_path)}

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(
                tool_name="feroxbuster",
                tool_commandline=rr.command,
                scan_target=u,
                data={"result": payload, "meta": meta},
            )
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def gobuster_scan(
    url: str,
    wordlist: str,
    extensions: list[str] | None = None,
    threads: int = 50,
    timeout_seconds: int | None = 900,
    extra_args: list[str] | None = None,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run gobuster dir against a target URL using a wordlist under WORDLISTS_ROOT.

    `wordlist` must be a relative path under WORDLISTS_ROOT, e.g. `dirb/common.txt` or `rockyou.txt.gz`.
    If `wordlist` is `rockyou.txt.gz`, it will be decompressed once per server session (warning + progress).
    """
    try:
        u = _norm_url(url)
        threads2 = _clamp_int(threads, min_value=1, max_value=2000, name="threads")
    except ValueError as e:
        return _tool_error(str(e))

    try:
        wl_path, progress = resolve_wordlist_for_use(wordlist)
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})

    args: list[str] = ["dir", "-u", u, "-w", str(wl_path), "-t", str(threads2)]
    if extensions:
        exts = [x.strip().lstrip(".") for x in extensions if (x or "").strip()]
        if exts:
            args.extend(["-x", ",".join(exts)])
    if extra_args:
        blocked = {"-o", "--output", "--no-color"}  # keep output on stdout; allow colors via cli if desired
        if any(a in blocked for a in extra_args):
            return _tool_error("extra_args contains blocked flags (use gobuster_scan_raw with i_acknowledge_risk=true)")
        args.extend(extra_args)

    try:
        rr = run_gobuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install gobuster or set GOBUSTER_BIN"})

    stdout = rr.stdout
    if progress:
        stdout = "\n".join(progress) + "\n\n" + stdout

    payload: dict[str, Any] = {"stdout": stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command, "wordlists_root": str(wordlists_root()), "wordlist_used": str(wl_path)}

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(
                tool_name="gobuster",
                tool_commandline=rr.command,
                scan_target=u,
                data={"result": payload, "meta": meta},
            )
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def feroxbuster_scan_raw(
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run feroxbuster with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    try:
        rr = run_feroxbuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install feroxbuster or set FEROXBUSTER_BIN"})
    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(tool_name="feroxbuster", tool_commandline=rr.command, scan_target="", data={"result": payload, "meta": meta})
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}
    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def gobuster_scan_raw(
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run gobuster with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    try:
        rr = run_gobuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install gobuster or set GOBUSTER_BIN"})
    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(tool_name="gobuster", tool_commandline=rr.command, scan_target="", data={"result": payload, "meta": meta})
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}
    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    if transport == "stdio":
        mcp.run(transport="stdio")
        return
    # Optional HTTP transports
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port = int(os.getenv("MCP_PORT", "4605"))
    path = os.getenv("MCP_PATH", "").strip() or None
    mcp.run(transport=transport, host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

Done — `dirscan.wordlists_list` now returns `{stdout, stderr}` and **`pentest-cli` prints only the wordlist names/paths (one per line)** instead of dumping JSON.

If you want it to show *only* “real” wordlists (and not things like `.git/...` when `WORDLISTS_ROOT` points at the wrong place), tell me what you set `WORDLISTS_ROOT` to and I’ll add a filter/guard (e.g., require `.txt` / `.gz` extensions, or require it to contain known wordlist subdirs like `dirb/`, `wfuzz/`, etc.).

---

**User**

The dirscan.wordlists_list shows a lot of the wordlists when running the wordlists_list, can you first list the first level subdirectories, such as Ai, Discovery, Fuzzing, etc in a menu type of option, so the user can select the directory to list the full wordlists

---

**Cursor**

Plan: I’ll update `dirscan.wordlists_list` so that when `subdir` is omitted it behaves like a “menu”: it prints the **top-level categories (first-level directories)** under `WORDLISTS_ROOT` (plus any root files like `rockyou.txt.gz`), and shows the exact follow-up command to list a specific category. When `subdir` is provided, it will list the wordlists inside that category like it does today.

```python
from __future__ import annotations

import atexit
import gzip
import os
import time
from pathlib import Path
from typing import Any


class WordlistError(RuntimeError):
    pass


_ROCKYOU_TMP_PATH: Path | None = None


def wordlists_root() -> Path:
    # Explicit override (recommended)
    env_root = (os.getenv("WORDLISTS_ROOT", "") or "").strip()
    if env_root:
        return Path(env_root).expanduser()

    # Auto-detect common locations
    candidates = [
        "/usr/share/wordlists",  # Debian/Kali wordlists package
        "/usr/local/share/wordlists",
        "/opt/homebrew/share/wordlists",  # possible Homebrew layout
        "/opt/homebrew/share/seclists",  # common on macOS if using SecLists via Homebrew
        str(Path.cwd() / "wordlists"),  # Standalone_Build/wordlists when launched via run-mcp-stdio.sh
    ]
    for c in candidates:
        p = Path(c).expanduser()
        if p.exists() and p.is_dir():
            return p

    # Default fallback (what the user sees in errors)
    return Path("/usr/share/wordlists")


def _ensure_under_root(root: Path, rel: str) -> Path:
    # Disallow absolute paths (we only accept relative identifiers)
    if os.path.isabs(rel):
        raise WordlistError("wordlist must be a relative path under WORDLISTS_ROOT")
    rel2 = rel.strip().lstrip("/").replace("\\", "/")
    if not rel2 or rel2.startswith("..") or "/.." in rel2:
        raise WordlistError("invalid wordlist path")
    p = (root / rel2).resolve()
    root_res = root.resolve()
    if root_res not in p.parents and p != root_res:
        raise WordlistError("wordlist path escapes WORDLISTS_ROOT")
    return p


def list_wordlists(*, subdir: str | None = None, limit: int = 5000, include_sizes: bool = False) -> dict[str, Any]:
    root = wordlists_root()
    if not root.exists():
        raise WordlistError(f"WORDLISTS_ROOT does not exist: {root}")
    base = root
    if subdir:
        base = _ensure_under_root(root, subdir)
        if not base.exists() or not base.is_dir():
            raise WordlistError(f"subdir not found: {subdir}")

    items: list[dict[str, Any]] = []
    count = 0
    for p in sorted(base.rglob("*")):
        if not p.is_file():
            continue
        rel = str(p.relative_to(root)).replace("\\", "/")
        # Do NOT list an uncompressed rockyou temp file if it exists
        if rel.endswith("rockyou.txt"):
            continue
        d: dict[str, Any] = {"name": rel}
        if include_sizes:
            try:
                d["bytes"] = int(p.stat().st_size)
            except Exception:
                d["bytes"] = None
        items.append(d)
        count += 1
        if count >= limit:
            break
    return {"root": str(root), "count": len(items), "items": items, "truncated": (count >= limit)}


def list_top_level(*, limit: int = 5000) -> dict[str, Any]:
    """
    List first-level directories and files under WORDLISTS_ROOT.
    Returns relative names only (no full paths).
    """
    root = wordlists_root()
    if not root.exists():
        raise WordlistError(f"WORDLISTS_ROOT does not exist: {root}")

    dirs: list[str] = []
    files: list[str] = []
    for p in sorted(root.iterdir(), key=lambda x: x.name.lower()):
        name = p.name
        if not name or name.startswith("."):
            continue
        try:
            if p.is_dir():
                dirs.append(name)
            elif p.is_file():
                files.append(name)
        except Exception:
            continue

    # Soft cap; if there are absurdly many top-level entries, truncate.
    lim = max(1, min(int(limit), 200000))
    dirs = dirs[:lim]
    files = files[:lim]
    return {"root": str(root), "dirs": dirs, "files": files, "truncated": (len(dirs) >= lim or len(files) >= lim)}


def _cleanup_tmp() -> None:
    global _ROCKYOU_TMP_PATH
    p = _ROCKYOU_TMP_PATH
    _ROCKYOU_TMP_PATH = None
    if p and p.exists():
        try:
            p.unlink()
        except Exception:
            pass


atexit.register(_cleanup_tmp)


def resolve_wordlist_for_use(rel_wordlist: str) -> tuple[Path, list[str]]:
    """
    Return a concrete file path to use for scanning.
    If the wordlist is rockyou.txt.gz, decompress to a temp file for this server session.
    Returns (path_to_use, progress_lines)
    """
    root = wordlists_root()
    wl = rel_wordlist.strip()
    if not wl:
        raise WordlistError("wordlist is required")

    src = _ensure_under_root(root, wl)
    if not src.exists() or not src.is_file():
        raise WordlistError(f"wordlist not found: {wl}")

    progress: list[str] = []

    if src.name.lower() == "rockyou.txt.gz":
        global _ROCKYOU_TMP_PATH
        if _ROCKYOU_TMP_PATH and _ROCKYOU_TMP_PATH.exists():
            return _ROCKYOU_TMP_PATH, progress

        progress.append("WARNING: rockyou.txt.gz decompression can be slow and will delay the scan.")
        progress.append("Decompressing rockyou.txt.gz (this happens once per server session)...")

        tmp_dir = Path(os.getenv("DIRSCAN_TMP_DIR", "") or (Path("/tmp") / "dirscan")).expanduser()
        tmp_dir.mkdir(parents=True, exist_ok=True)
        tmp_path = (tmp_dir / "rockyou.txt").resolve()

        gz_size = None
        try:
            gz_size = int(src.stat().st_size)
        except Exception:
            gz_size = None

        start = time.time()
        last_emit = start
        read_bytes = 0
        with gzip.open(src, "rb") as fin, open(tmp_path, "wb") as fout:
            while True:
                chunk = fin.read(1024 * 1024)  # 1MiB
                if not chunk:
                    break
                fout.write(chunk)
                if gz_size is not None:
                    # gzip doesn't expose compressed bytes read; best-effort approximation:
                    # use min(uncompressed_written, gz_size) as a monotonically increasing proxy.
                    read_bytes = min(read_bytes + len(chunk), gz_size)
                now = time.time()
                if now - last_emit >= 2.0:
                    last_emit = now
                    if gz_size:
                        pct = max(0.0, min(100.0, (read_bytes / gz_size) * 100.0))
                        elapsed = max(0.001, now - start)
                        rate = max(1e-9, read_bytes / elapsed)
                        remaining = max(0.0, gz_size - read_bytes)
                        eta = remaining / rate if rate > 0 else None
                        eta_s = f"{int(eta)}s" if eta is not None else "?"
                        progress.append(f"rockyou decompress: ~{pct:0.1f}% (eta ~{eta_s})")
                    else:
                        progress.append("rockyou decompress: working...")

        _ROCKYOU_TMP_PATH = tmp_path
        progress.append("Decompression complete: rockyou.txt is available for this session (will be deleted on server exit).")
        return tmp_path, progress

    return src, progress



```

```python
from __future__ import annotations

import inspect
import json
import os
import re
from typing import Any

from fastmcp import FastMCP

from .mongo_store import save_to_mongo_result
from .runners import BinaryNotFoundError, run_feroxbuster, run_gobuster
from .wordlists import WordlistError, list_top_level, list_wordlists, resolve_wordlist_for_use, wordlists_root


mcp = FastMCP(name="dirscan")

_TOOL_NAME_RE = re.compile(r"^[A-Za-z_][A-Za-z0-9_]{0,127}$")
_TOOL_REGISTRY: dict[str, dict[str, Any]] = {}


def _type_repr(t: Any) -> str | None:
    if t is inspect._empty:
        return None
    try:
        name = getattr(t, "__name__", None)
        if isinstance(name, str) and name:
            return name
    except Exception:
        pass
    return str(t)


def _jsonable_default(v: Any) -> Any:
    if v is inspect._empty:
        return None
    try:
        json.dumps(v, default=str)
        return v
    except TypeError:
        return repr(v)


def register_tool(fn):
    doc = inspect.getdoc(fn) or ""
    sig = inspect.signature(fn)
    try:
        from typing import get_type_hints

        hints = get_type_hints(fn, include_extras=True)
    except Exception:
        hints = {}

    params: list[dict[str, Any]] = []
    for param_name, p in sig.parameters.items():
        ann = hints.get(param_name, p.annotation)
        required = p.default is inspect._empty and p.kind not in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        )
        params.append(
            {
                "name": param_name,
                "type": _type_repr(ann),
                "required": required,
                "default": _jsonable_default(p.default) if p.default is not inspect._empty else None,
                "kind": str(p.kind).split(".")[-1],
            }
        )

    ret_ann = hints.get("return", sig.return_annotation)
    _TOOL_REGISTRY[fn.__name__] = {
        "name": fn.__name__,
        "description": doc,
        "params": params,
        "return_type": _type_repr(ret_ann),
    }
    return fn


def _tool_error(message: str, *, details: Any | None = None) -> dict[str, Any]:
    return {"ok": False, "error": message, "details": details}


def _tool_ok(result: Any, *, meta: Any | None = None) -> dict[str, Any]:
    return {"ok": True, "result": result, "meta": meta or {}}


def _require_ack(i_acknowledge_risk: bool) -> tuple[bool, dict[str, Any] | None]:
    if not i_acknowledge_risk:
        return False, _tool_error(
            "raw mode requires i_acknowledge_risk=true",
            details={
                "reason": "raw flags can perform aggressive scanning, file writes, and script execution",
            },
        )
    return True, None


def _norm_url(url: str) -> str:
    u = (url or "").strip()
    if not u:
        raise ValueError("url is required")
    if not (u.startswith("http://") or u.startswith("https://")):
        raise ValueError("url must start with http:// or https://")
    return u


def _clamp_int(x: int, *, min_value: int, max_value: int, name: str) -> int:
    try:
        v = int(x)
    except Exception:
        raise ValueError(f"{name} must be an integer")
    if v < min_value or v > max_value:
        raise ValueError(f"{name} must be between {min_value} and {max_value}")
    return v


@mcp.tool()
@register_tool
def wordlists_list(
    subdir: str | None = None,
    limit: int = 5000,
    include_sizes: bool = False,
) -> dict[str, Any]:
    """
    List wordlists under WORDLISTS_ROOT (default: /usr/share/wordlists).

    - Returns only relative names (no full paths).
    - `subdir` is also relative to WORDLISTS_ROOT.
    - `rockyou.txt` is not listed (if a temp copy exists); `rockyou.txt.gz` is listed.
    """
    try:
        limit = _clamp_int(limit, min_value=1, max_value=200000, name="limit")
        # Menu view: no subdir => show first-level categories and root files
        if not subdir:
            top = list_top_level(limit=limit)
            dirs = top.get("dirs") or []
            files = top.get("files") or []
            lines: list[str] = []
            lines.append("Wordlist categories (first-level directories):")
            if not dirs:
                lines.append("  (none)")
            else:
                for i, d in enumerate(dirs, 1):
                    lines.append(f"  {i:>2}. {d}/")
            if files:
                lines.append("")
                lines.append("Wordlists at root:")
                for f in files:
                    lines.append(f"  - {f}")
            lines.append("")
            lines.append("To list a category:")
            lines.append('  call dirscan.wordlists_list {"subdir":"<category>","limit":5000}')

            payload = {"stdout": "\n".join(lines) + "\n", "stderr": ""}
            return _tool_ok(
                payload,
                meta={
                    "wordlists_root": str(wordlists_root()),
                    "dirs_count": len(dirs),
                    "files_count": len(files),
                    "truncated": top.get("truncated"),
                },
            )

        listing = list_wordlists(subdir=subdir, limit=limit, include_sizes=include_sizes)
        lines: list[str] = []
        for item in (listing.get("items") or []):
            if not isinstance(item, dict):
                continue
            name = item.get("name")
            if not isinstance(name, str) or not name.strip():
                continue
            if include_sizes and ("bytes" in item):
                b = item.get("bytes")
                if isinstance(b, int):
                    lines.append(f"{name} ({b} bytes)")
                else:
                    lines.append(name)
            else:
                lines.append(name)

        payload = {"stdout": "\n".join(lines) + ("\n" if lines else ""), "stderr": ""}
        return _tool_ok(
            payload,
            meta={
                "wordlists_root": str(wordlists_root()),
                "subdir": subdir,
                "count": listing.get("count"),
                "truncated": listing.get("truncated"),
            },
        )
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})


@mcp.tool()
@register_tool
def feroxbuster_scan(
    url: str,
    wordlist: str,
    extensions: list[str] | None = None,
    threads: int = 50,
    depth: int | None = None,
    timeout_seconds: int | None = 900,
    json_output: bool = False,
    extra_args: list[str] | None = None,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run feroxbuster against a target URL using a wordlist under WORDLISTS_ROOT.

    `wordlist` must be a relative path under WORDLISTS_ROOT, e.g. `dirb/common.txt` or `rockyou.txt.gz`.
    If `wordlist` is `rockyou.txt.gz`, it will be decompressed once per server session (warning + progress).
    """
    try:
        u = _norm_url(url)
        threads2 = _clamp_int(threads, min_value=1, max_value=2000, name="threads")
        if depth is not None:
            depth = _clamp_int(depth, min_value=0, max_value=50, name="depth")
    except ValueError as e:
        return _tool_error(str(e))

    try:
        wl_path, progress = resolve_wordlist_for_use(wordlist)
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})

    args: list[str] = ["-u", u, "-w", str(wl_path), "-t", str(threads2)]
    if depth is not None:
        args.extend(["--depth", str(depth)])
    if extensions:
        exts = [x.strip().lstrip(".") for x in extensions if (x or "").strip()]
        if exts:
            args.extend(["-x", ",".join(exts)])
    if json_output:
        args.append("--json")
    if extra_args:
        # safe wrapper: we don't allow obvious file-write flags here
        blocked = {"-o", "--output", "--config", "--stdin"}
        if any(a in blocked for a in extra_args):
            return _tool_error("extra_args contains blocked flags (use feroxbuster_scan_raw with i_acknowledge_risk=true)")
        args.extend(extra_args)

    try:
        rr = run_feroxbuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install feroxbuster or set FEROXBUSTER_BIN"})

    stdout = rr.stdout
    if progress:
        stdout = "\n".join(progress) + "\n\n" + stdout

    payload: dict[str, Any] = {"stdout": stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command, "wordlists_root": str(wordlists_root()), "wordlist_used": str(wl_path)}

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(
                tool_name="feroxbuster",
                tool_commandline=rr.command,
                scan_target=u,
                data={"result": payload, "meta": meta},
            )
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def gobuster_scan(
    url: str,
    wordlist: str,
    extensions: list[str] | None = None,
    threads: int = 50,
    timeout_seconds: int | None = 900,
    extra_args: list[str] | None = None,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """
    Run gobuster dir against a target URL using a wordlist under WORDLISTS_ROOT.

    `wordlist` must be a relative path under WORDLISTS_ROOT, e.g. `dirb/common.txt` or `rockyou.txt.gz`.
    If `wordlist` is `rockyou.txt.gz`, it will be decompressed once per server session (warning + progress).
    """
    try:
        u = _norm_url(url)
        threads2 = _clamp_int(threads, min_value=1, max_value=2000, name="threads")
    except ValueError as e:
        return _tool_error(str(e))

    try:
        wl_path, progress = resolve_wordlist_for_use(wordlist)
    except WordlistError as e:
        return _tool_error(str(e), details={"wordlists_root": str(wordlists_root())})

    args: list[str] = ["dir", "-u", u, "-w", str(wl_path), "-t", str(threads2)]
    if extensions:
        exts = [x.strip().lstrip(".") for x in extensions if (x or "").strip()]
        if exts:
            args.extend(["-x", ",".join(exts)])
    if extra_args:
        blocked = {"-o", "--output", "--no-color"}  # keep output on stdout; allow colors via cli if desired
        if any(a in blocked for a in extra_args):
            return _tool_error("extra_args contains blocked flags (use gobuster_scan_raw with i_acknowledge_risk=true)")
        args.extend(extra_args)

    try:
        rr = run_gobuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install gobuster or set GOBUSTER_BIN"})

    stdout = rr.stdout
    if progress:
        stdout = "\n".join(progress) + "\n\n" + stdout

    payload: dict[str, Any] = {"stdout": stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command, "wordlists_root": str(wordlists_root()), "wordlist_used": str(wl_path)}

    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(
                tool_name="gobuster",
                tool_commandline=rr.command,
                scan_target=u,
                data={"result": payload, "meta": meta},
            )
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}

    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def feroxbuster_scan_raw(
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run feroxbuster with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    try:
        rr = run_feroxbuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install feroxbuster or set FEROXBUSTER_BIN"})
    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(tool_name="feroxbuster", tool_commandline=rr.command, scan_target="", data={"result": payload, "meta": meta})
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}
    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def gobuster_scan_raw(
    args: list[str],
    i_acknowledge_risk: bool = False,
    timeout_seconds: int | None = 900,
    save: dict[str, Any] | None = None,
) -> dict[str, Any]:
    """Run gobuster with arbitrary CLI args (no shell). Requires `i_acknowledge_risk=true`."""
    ok, err = _require_ack(i_acknowledge_risk)
    if not ok:
        return err  # type: ignore[return-value]
    try:
        rr = run_gobuster(args=args, timeout_seconds=timeout_seconds)
    except BinaryNotFoundError as e:
        return _tool_error(str(e), details={"hint": "install gobuster or set GOBUSTER_BIN"})
    payload = {"stdout": rr.stdout, "stderr": rr.stderr}
    meta: dict[str, Any] = {"returncode": rr.returncode, "command": rr.command}
    if save and (save.get("type") or "").strip().lower() == "mongo":
        try:
            meta["saved"] = save_to_mongo_result(tool_name="gobuster", tool_commandline=rr.command, scan_target="", data={"result": payload, "meta": meta})
        except Exception as e:
            meta["saved"] = {"saved": False, "error": str(e)}
    return _tool_ok(payload, meta=meta)


@mcp.tool()
@register_tool
def list_tools() -> dict[str, Any]:
    """List tool names, docstrings, and parameter metadata exposed by this MCP server."""
    tools = [_TOOL_REGISTRY[k] for k in sorted(_TOOL_REGISTRY)]
    return _tool_ok(tools, meta={"count": len(tools)})


@mcp.tool()
@register_tool
def describe_tool(name: str) -> dict[str, Any]:
    """Return detailed metadata for a single tool by its function name."""
    tool_name = (name or "").strip()
    if not tool_name:
        return _tool_error("name is required")
    if not _TOOL_NAME_RE.match(tool_name):
        return _tool_error("invalid tool name")
    tool = _TOOL_REGISTRY.get(tool_name)
    if not tool:
        return _tool_error("unknown tool", details={"known_tools": sorted(_TOOL_REGISTRY)[:200]})
    return _tool_ok(tool)


def main() -> None:
    transport = os.getenv("MCP_TRANSPORT", "stdio").strip().lower()
    if transport == "stdio":
        mcp.run(transport="stdio")
        return
    # Optional HTTP transports
    host = os.getenv("MCP_HOST", "0.0.0.0")
    port = int(os.getenv("MCP_PORT", "4605"))
    path = os.getenv("MCP_PATH", "").strip() or None
    mcp.run(transport=transport, host=host, port=port, path=path)


if __name__ == "__main__":
    main()



```

Updated `dirscan.wordlists_list` to behave like a **menu**:

- **If `subdir` is omitted**: it prints the **first-level directories** under `WORDLISTS_ROOT` (e.g., `Ai/`, `Discovery/`, `Fuzzing/`, …) plus any **root files** like `rockyou.txt.gz`.
- **If `subdir` is provided**: it prints the full list of wordlists inside that category (one per line), as before.

Example usage:

```text
pentest> call dirscan.wordlists_list {}
pentest> call dirscan.wordlists_list {"subdir":"Discovery","limit":5000}
```

```plaintext
pentest> call dirscan.wordlists_list {}
pentest> call dirscan.wordlists_list {"subdir":"Discovery","limit":5000}
```

---

**User**

Why is the @Standalone_Build/wordlists/RECOMMENDED.md file ignored from the @Standalone_Build/.gitignore  likely through the `wordlists/*` entry, but the rest of the items in the @Standalone_Build/wordlists directory are not ignored

